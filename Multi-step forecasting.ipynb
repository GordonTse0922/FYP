{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b615d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score, mean_squared_error,mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM,Dropout, BatchNormalization, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.optimizer_v2.rmsprop import RMSprop\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18dfe5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5490, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data for the SPY ETF by specifying the stock ticker, start date, and end date\n",
    "historical_data = yf.download('0005.hk')\n",
    "historical_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dba75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = historical_data[1:5000], historical_data[5000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e702544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_19578/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n"
     ]
    }
   ],
   "source": [
    "train = train_df\n",
    "scalers={}\n",
    "for i in train_df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+ i] = scaler\n",
    "    train[i]=s_s\n",
    "test = test_df\n",
    "for i in train_df.columns:\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+i] = scaler\n",
    "    test[i]=s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2fcd50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "  #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "    # slicing the past and future parts of the window\n",
    "#         print(series)\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "#         print(future)\n",
    "        y.append(future)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd57ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 10\n",
    "n_future = 5 \n",
    "n_features = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfda6edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4985, 5, 1)\n",
      "(476, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = split_series(train.values,n_past, n_future)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))[:,:,3]\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))[:,:,3]\n",
    "y_test=y_test.reshape(y_test.shape[0],y_test.shape[1],1)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed7933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def build_model():\n",
    "\t# prepare data\n",
    "# \ttrain_x, train_y = to_supervised(train, n_input)\n",
    "\t# define parameters\n",
    "\tverbose, epochs, batch_size = 0, 500, 4\n",
    "\tn_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(1, activation='relu', input_shape=(n_past, n_features)))\n",
    "# \tmodel.add(Dense(100, activation='relu'))\n",
    "# \tmodel.add(Dense(n_outputs))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit network\n",
    "\tmodel.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\treturn model\n",
    " \n",
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "\t# flatten data\n",
    "\tdata = array(history)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, 0]\n",
    "\t# reshape into [1, n_input, 1]\n",
    "\tinput_x = input_x.reshape((1, len(input_x), 1))\n",
    "\t# forecast the next week\n",
    "\tyhat = model.predict(input_x, verbose=0)\n",
    "\t# we only want the vector forecast\n",
    "\tyhat = yhat[0]\n",
    "\treturn yhat\n",
    " \n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_input)\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2c2658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 17:08:17.384572: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-14 17:08:17.384699: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 6)]      0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 100),        42800       ['input_1[0][0]']                \n",
      "                                 (None, 100),                                                     \n",
      "                                 (None, 100)]                                                     \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVector)   (None, 5, 100)       0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 5, 100)       80400       ['repeat_vector[0][0]',          \n",
      "                                                                  'lstm[0][1]',                   \n",
      "                                                                  'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 5, 6)        606         ['lstm_1[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 123,806\n",
      "Trainable params: 123,806\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l1)\n",
    "\n",
    "#\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "\n",
    "#\n",
    "model_e1d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ec385c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 17:08:17.607459: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-14 17:08:18.290539: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 17:08:18.498395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 17:08:18.551939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 17:08:18.652425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/156 [>.............................] - ETA: 2s - loss: 0.0569 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 17:08:18.719305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - ETA: 0s - loss: 0.0054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 17:08:21.358794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 17:08:21.433662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 17:08:21.465307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 4s 18ms/step - loss: 0.0054 - val_loss: 7.0204e-04 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "156/156 [==============================] - 3s 17ms/step - loss: 9.9219e-04 - val_loss: 6.6892e-04 - lr: 9.0000e-04\n",
      "Epoch 3/25\n",
      "156/156 [==============================] - 3s 16ms/step - loss: 8.8371e-04 - val_loss: 0.0021 - lr: 8.1000e-04\n",
      "Epoch 4/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 9.4721e-04 - val_loss: 0.0032 - lr: 7.2900e-04\n",
      "Epoch 5/25\n",
      "156/156 [==============================] - 3s 16ms/step - loss: 8.4266e-04 - val_loss: 5.3121e-04 - lr: 6.5610e-04\n",
      "Epoch 6/25\n",
      "156/156 [==============================] - 3s 16ms/step - loss: 8.3923e-04 - val_loss: 5.4110e-04 - lr: 5.9049e-04\n",
      "Epoch 7/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 8.3021e-04 - val_loss: 7.4553e-04 - lr: 5.3144e-04\n",
      "Epoch 8/25\n",
      "156/156 [==============================] - 3s 16ms/step - loss: 8.5859e-04 - val_loss: 6.8639e-04 - lr: 4.7830e-04\n",
      "Epoch 9/25\n",
      "156/156 [==============================] - 3s 16ms/step - loss: 8.2007e-04 - val_loss: 0.0013 - lr: 4.3047e-04\n",
      "Epoch 10/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 8.1508e-04 - val_loss: 6.2241e-04 - lr: 3.8742e-04\n",
      "Epoch 11/25\n",
      "156/156 [==============================] - 3s 17ms/step - loss: 8.1846e-04 - val_loss: 8.0707e-04 - lr: 3.4868e-04\n",
      "Epoch 12/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 8.1782e-04 - val_loss: 5.7858e-04 - lr: 3.1381e-04\n",
      "Epoch 13/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 7.8887e-04 - val_loss: 3.9647e-04 - lr: 2.8243e-04\n",
      "Epoch 14/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 7.7703e-04 - val_loss: 0.0016 - lr: 2.5419e-04\n",
      "Epoch 15/25\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 8.0567e-04 - val_loss: 4.2833e-04 - lr: 2.2877e-04\n",
      "Epoch 16/25\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 7.7699e-04 - val_loss: 4.1676e-04 - lr: 2.0589e-04\n",
      "Epoch 17/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 7.6889e-04 - val_loss: 3.5640e-04 - lr: 1.8530e-04\n",
      "Epoch 18/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 7.7231e-04 - val_loss: 8.0780e-04 - lr: 1.6677e-04\n",
      "Epoch 19/25\n",
      "156/156 [==============================] - 3s 19ms/step - loss: 7.7991e-04 - val_loss: 3.9753e-04 - lr: 1.5009e-04\n",
      "Epoch 20/25\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 7.6220e-04 - val_loss: 4.3228e-04 - lr: 1.3509e-04\n",
      "Epoch 21/25\n",
      "156/156 [==============================] - 3s 18ms/step - loss: 7.5603e-04 - val_loss: 9.1039e-04 - lr: 1.2158e-04\n",
      "Epoch 22/25\n",
      "156/156 [==============================] - 2s 16ms/step - loss: 7.6076e-04 - val_loss: 6.2935e-04 - lr: 1.0942e-04\n",
      "Epoch 23/25\n",
      "156/156 [==============================] - 3s 19ms/step - loss: 7.4396e-04 - val_loss: 4.0343e-04 - lr: 9.8477e-05\n",
      "Epoch 24/25\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 7.3892e-04 - val_loss: 4.1304e-04 - lr: 8.8629e-05\n",
      "Epoch 25/25\n",
      "156/156 [==============================] - 3s 21ms/step - loss: 7.3729e-04 - val_loss: 5.3047e-04 - lr: 7.9766e-05\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=1,callbacks=[reduce_lr])\n",
    "# model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "# history_e2d2=model_e2d2.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b57291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 17:09:25.498302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 17:09:25.588511: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 17:09:25.629849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(476, 5, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_e1d1=model_e1d1.predict(X_test)\n",
    "pred_e1d1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ffcb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    scaler = scalers['scaler_'+'Close']\n",
    "#     pred1_xe1d1[:,:,index]=scaler.inverse_transform(pred1_e1d1[:,:,index])\n",
    "    pred_e1d1[:,:,0]=scaler.inverse_transform(pred_e1d1[:,:,0])\n",
    "#     pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\n",
    "#     pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    y_train[:,:,0]=scaler.inverse_transform(y_train[:,:,0])\n",
    "    y_test[:,:,0]=scaler.inverse_transform(y_test[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f6fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day  0 :\n",
      "MAE-E1D1 :  1.517189725507207, \n",
      "Day  1 :\n",
      "MAE-E1D1 :  1.517189725507207, \n",
      "Day  2 :\n",
      "MAE-E1D1 :  1.517189725507207, \n",
      "Day  3 :\n",
      "MAE-E1D1 :  1.517189725507207, \n",
      "Day  4 :\n",
      "MAE-E1D1 :  1.517189725507207, \n",
      "Day  5 :\n",
      "MAE-E1D1 :  1.517189725507207, \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "for j in range(0,6):\n",
    "    print(\"Day \",j,\":\")\n",
    "    print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,:,0],pred_e1d1[:,:,0]),end=\", \")\n",
    "#         print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred1_e2d2[:,j-1,index]))\n",
    "    print()\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1583d7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.283524, 60.070297, 59.91407 , 59.897537, 59.945637],\n",
       "       [60.052162, 59.84348 , 59.69194 , 59.680466, 59.733456],\n",
       "       [59.51294 , 59.24235 , 59.069927, 59.056587, 59.11564 ],\n",
       "       ...,\n",
       "       [44.92573 , 44.776684, 44.983494, 45.364304, 45.782223],\n",
       "       [45.190926, 45.05243 , 45.254967, 45.627384, 46.036568],\n",
       "       [45.696526, 45.630978, 45.859108, 46.23417 , 46.63684 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_e1d1[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32d90c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59.90000153, 59.29999924, 59.84999847, 59.84999847, 59.95000076],\n",
       "       [59.29999924, 59.84999847, 59.84999847, 59.95000076, 59.75      ],\n",
       "       [59.84999847, 59.84999847, 59.95000076, 59.75      , 59.79999924],\n",
       "       ...,\n",
       "       [44.84999847, 45.65000153, 45.5       , 45.29999924, 45.20000076],\n",
       "       [45.65000153, 45.5       , 45.29999924, 45.20000076, 45.09999847],\n",
       "       [45.5       , 45.29999924, 45.20000076, 45.09999847, 44.5       ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "432bf30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8940007428641907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(pred_e1d1[:,:,0],y_test[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "864666af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                 Open       High        Low      Close  Adj Close    Volume\n",
      "Date                                                                       \n",
      "2021-12-08  45.950001  45.950001  45.099998  45.500000  45.500000   8590654\n",
      "2021-12-09  45.450001  45.900002  45.150002  45.299999  45.299999   6908033\n",
      "2021-12-10  45.099998  45.400002  44.950001  45.200001  45.200001   6090109\n",
      "2021-12-13  45.200001  45.250000  44.500000  45.099998  45.099998  10861423\n",
      "2021-12-14  44.150002  44.599998  44.150002  44.500000  44.500000   7998591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([45.5       , 45.29999924, 45.20000076, 45.09999847, 44.5       ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData = yf.download('0005.hk')\n",
    "print(newData.tail())\n",
    "newData[-5:]['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2867743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.696526, 45.630978, 45.859108, 46.23417 , 46.63684 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_e1d1[:,:,0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e89b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
