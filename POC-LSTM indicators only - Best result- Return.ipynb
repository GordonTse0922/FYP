{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efc3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score, mean_squared_error,mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM,Dropout, BatchNormalization, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.optimizer_v2.rmsprop import RMSprop\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b8c4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-28</th>\n",
       "      <td>1.47</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>1.47</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.68</td>\n",
       "      <td>5182471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>1.68</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.71</td>\n",
       "      <td>5341000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-06</th>\n",
       "      <td>1.71</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1975189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close  Adj Close   Volume\n",
       "Date                                                   \n",
       "2017-09-28  1.47  1.50  1.47   1.49       1.49   400000\n",
       "2017-09-29  1.47  1.53  1.47   1.50       1.50   929000\n",
       "2017-10-03  1.60  1.68  1.58   1.68       1.68  5182471\n",
       "2017-10-04  1.68  1.72  1.68   1.71       1.71  5341000\n",
       "2017-10-06  1.71  1.71  1.64   1.69       1.69  1975189"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = yf.download('0500.hk',\"2017-09-28\",\"2021-09-24\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5323eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>1.47</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.49</td>\n",
       "      <td>400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>1.47</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>929000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.68</td>\n",
       "      <td>5182471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-06</th>\n",
       "      <td>1.68</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.71</td>\n",
       "      <td>5341000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>1.66</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>18453282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>1.72</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2604942.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>1.67</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2440023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2675080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>1.62</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>6251010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close  Adj Close      Volume\n",
       "Date                                                      \n",
       "2017-09-28   NaN   NaN   NaN    NaN        NaN         NaN\n",
       "2017-09-29  1.47  1.50  1.47   1.49       1.49    400000.0\n",
       "2017-10-03  1.47  1.53  1.47   1.50       1.50    929000.0\n",
       "2017-10-04  1.60  1.68  1.58   1.68       1.68   5182471.0\n",
       "2017-10-06  1.68  1.72  1.68   1.71       1.71   5341000.0\n",
       "...          ...   ...   ...    ...        ...         ...\n",
       "2018-02-01  1.66  1.79  1.63   1.72       1.72  18453282.0\n",
       "2018-02-02  1.72  1.72  1.65   1.69       1.69   2604942.0\n",
       "2018-02-05  1.67  1.69  1.61   1.62       1.62   2440023.0\n",
       "2018-02-06  1.60  1.64  1.59   1.63       1.63   2675080.0\n",
       "2018-02-07  1.62  1.63  1.50   1.53       1.53   6251010.0\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shift(1).head(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699c7659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'H-L', 'O-C',\n",
       "       '% Change', '3day MA', '10day MA', '30day MA', 'Std_dev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['H-L'] = data['High'] - data['Low']\n",
    "data['O-C'] = data['Close'] - data['Open']\n",
    "# data=pd.merge(data,data[\"Close\"].pct_change(),left_index=True,right_index=True)\n",
    "data[\"% Change\"]=data[\"Close\"].shift(1).pct_change()\n",
    "data['3day MA'] = data['Close'].shift(1).rolling(window = 3).mean()\n",
    "data['10day MA'] = data['Close'].shift(1).rolling(window = 10).mean()\n",
    "data['30day MA'] = data['Close'].shift(1).rolling(window = 30).mean()\n",
    "data['Std_dev']= data['Close'].shift(1).rolling(5).std()\n",
    "# data['RSI'] = talib.RSI(data['Close'].values, timeperiod = 9)\n",
    "# data['Williams %R'] = talib.WILLR(data['High'].values, data['Low'].values, data['Close'].values, 7)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ae5d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date (D/M/Y)', ' Call Volume', ' Put Volume', ' Put/Call Ratio'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_options = pd.read_csv(\"Put_Call_Ratio.csv\",skiprows=1)\n",
    "data_options.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72bdd11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Call Volume', ' Put Volume', ' Put/Call Ratio'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_options['Date (D/M/Y)']=pd.to_datetime(data_options['Date (D/M/Y)'], format=\"%d/%m/%Y\")\n",
    "data_options.set_index('Date (D/M/Y)',inplace=True)\n",
    "data_options.sort_index(ascending=True,inplace=True)\n",
    "data_options.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91480345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=pd.merge(data,data_options[\" Put/Call Ratio\"], left_index=True,right_index=True)\n",
    "data=data\n",
    "# data.drop([\"Volume\",\"Adj Close\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fc4542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "H-L          0\n",
       "O-C          0\n",
       "% Change     0\n",
       "3day MA      0\n",
       "10day MA     0\n",
       "30day MA     0\n",
       "Std_dev      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1933fe76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>H-L</th>\n",
       "      <th>O-C</th>\n",
       "      <th>% Change</th>\n",
       "      <th>3day MA</th>\n",
       "      <th>10day MA</th>\n",
       "      <th>30day MA</th>\n",
       "      <th>Std_dev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-13</th>\n",
       "      <td>1.47</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2505282</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.050955</td>\n",
       "      <td>1.556667</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.617000</td>\n",
       "      <td>0.060992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-14</th>\n",
       "      <td>1.44</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2236000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.033557</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.605</td>\n",
       "      <td>1.615333</td>\n",
       "      <td>0.080747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-15</th>\n",
       "      <td>1.39</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3077000</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.034722</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>1.577</td>\n",
       "      <td>1.611667</td>\n",
       "      <td>0.090554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16</th>\n",
       "      <td>1.30</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2694753</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.071942</td>\n",
       "      <td>1.373333</td>\n",
       "      <td>1.537</td>\n",
       "      <td>1.598667</td>\n",
       "      <td>0.105262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>1.29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.32</td>\n",
       "      <td>836376</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>1.316667</td>\n",
       "      <td>1.499</td>\n",
       "      <td>1.584000</td>\n",
       "      <td>0.094763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close  Adj Close   Volume   H-L   O-C  % Change  \\\n",
       "Date                                                                            \n",
       "2017-11-13  1.47  1.49  1.43   1.44       1.44  2505282  0.06 -0.03 -0.050955   \n",
       "2017-11-14  1.44  1.48  1.39   1.39       1.39  2236000  0.09 -0.05 -0.033557   \n",
       "2017-11-15  1.39  1.39  1.28   1.29       1.29  3077000  0.11 -0.10 -0.034722   \n",
       "2017-11-16  1.30  1.32  1.24   1.27       1.27  2694753  0.08 -0.03 -0.071942   \n",
       "2017-11-17  1.29  1.34  1.28   1.32       1.32   836376  0.06  0.03 -0.015504   \n",
       "\n",
       "             3day MA  10day MA  30day MA   Std_dev  \n",
       "Date                                                \n",
       "2017-11-13  1.556667     1.625  1.617000  0.060992  \n",
       "2017-11-14  1.500000     1.605  1.615333  0.080747  \n",
       "2017-11-15  1.440000     1.577  1.611667  0.090554  \n",
       "2017-11-16  1.373333     1.537  1.598667  0.105262  \n",
       "2017-11-17  1.316667     1.499  1.584000  0.094763  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c41be28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train--Test size 762 191\n",
      "Length of inputs 752\n",
      "length of time-series - inputs (752, 10, 6)\n",
      "length of time-series - outputs (752,)\n",
      "Length of inputs 181\n",
      "length of time-series - inputs (181, 10, 6)\n",
      "length of time-series - outputs (181,)\n",
      "Batch trimmed size (752, 10, 6) (752,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/FYP/lib/python3.9/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def trim_dataset(mat, batch_size):\n",
    "    \n",
    "    #trims dataset to a size that's divisible by BATCH_SIZE\n",
    "    no_of_rows_drop = mat.shape[0] % batch_size\n",
    "\n",
    "    if no_of_rows_drop > 0:\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat\n",
    "    \n",
    "def build_timeseries(mat, y_col_index):\n",
    "    \n",
    "    dim_0 = mat.shape[0] - TIME_STEPS\n",
    "    dim_1 = mat.shape[1]\n",
    "\n",
    "    x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "    y = np.zeros((dim_0,))\n",
    "\n",
    "    print(\"Length of inputs\", dim_0)\n",
    "\n",
    "    for i in range(dim_0):\n",
    "        x[i] = mat[i:TIME_STEPS+i]\n",
    "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "\n",
    "    print(\"length of time-series - inputs\", x.shape)\n",
    "    print(\"length of time-series - outputs\", y.shape)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "train_cols = [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"]\n",
    "params = {\n",
    "    \"batch_size\": 4,  # 20<16<10, 25 was a bust\n",
    "    \"epochs\": 1000,\n",
    "    \"lr\": 0.00010000,\n",
    "    \"time_steps\": 10\n",
    "}\n",
    "TIME_STEPS = params[\"time_steps\"]\n",
    "BATCH_SIZE = params[\"batch_size\"]\n",
    "df_train, df_test = train_test_split(data, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "print(\"Train--Test size\", len(df_train), len(df_test))\n",
    "x = df_train.loc[:,train_cols].values\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train = min_max_scaler.fit_transform(x)\n",
    "X_test = min_max_scaler.transform(df_test.loc[:,train_cols])\n",
    "X_train, y_train = build_timeseries(x_train, 3)\n",
    "X_train = trim_dataset(X_train, BATCH_SIZE)\n",
    "y_train = trim_dataset(y_train, BATCH_SIZE)\n",
    "x_temp, y_temp = build_timeseries(X_test, 3)\n",
    "x_val, x_test_t = np.split(trim_dataset(x_temp, BATCH_SIZE),2)\n",
    "y_val, y_test_t = np.split(trim_dataset(y_temp, BATCH_SIZE),2)\n",
    "# print(x_test.shape)\n",
    "print(\"Batch trimmed size\", X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d361965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:28:43.882870: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-14 15:28:43.883058: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (4, 10, 100)              42800     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (4, 1)                    408       \n",
      "                                                                 \n",
      " dense (Dense)               (4, 1)                    2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,210\n",
      "Trainable params: 43,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/FYP/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_model():\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(100, batch_input_shape=(BATCH_SIZE, TIME_STEPS, X_train.shape[2]),\n",
    "                        dropout=0.0, recurrent_dropout=0.0,\n",
    "                        stateful=True, return_sequences=True,\n",
    "                        kernel_initializer='random_uniform'))\n",
    "#     lstm_model.add(Dropout(0.2))\n",
    "\n",
    "    lstm_model.add(LSTM(1, dropout=0.0))\n",
    "#     lstm_model.add(Dropout(0.2))\n",
    "    \n",
    "#     lstm_model.add(Dense(32))\n",
    "    lstm_model.add(Dense(1))\n",
    "        \n",
    "    #compile the model\n",
    "    optimizer = Adam(lr=params[\"lr\"])\n",
    "    lstm_model.compile(loss=\"MSE\", optimizer=optimizer)\n",
    "  \n",
    "    return lstm_model\n",
    "\n",
    "lstm_model = None\n",
    "lstm_model = create_lstm_model()\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c4e605e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:28:44.741199: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:28:45.905347: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 15:28:46.182316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 15:28:46.828022: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 15:28:47.951129: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 15:28:49.666388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/188 [============================>.] - ETA: 0s - loss: 0.1271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 15:28:54.965181: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 15:28:55.120078: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 15:28:55.178363: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 11s 27ms/step - loss: 0.1258 - val_loss: 0.0044\n",
      "Epoch 2/1000\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0128 - val_loss: 0.0051\n",
      "Epoch 3/1000\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0210 - val_loss: 0.0053\n",
      "Epoch 4/1000\n",
      "188/188 [==============================] - 4s 24ms/step - loss: 0.0224 - val_loss: 0.0055\n",
      "Epoch 5/1000\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0234 - val_loss: 0.0054\n",
      "Epoch 6/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0225 - val_loss: 0.0051\n",
      "Epoch 7/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0211 - val_loss: 0.0049\n",
      "Epoch 8/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0196 - val_loss: 0.0047\n",
      "Epoch 9/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0183 - val_loss: 0.0045\n",
      "Epoch 10/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0171 - val_loss: 0.0043\n",
      "Epoch 11/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0159 - val_loss: 0.0041\n",
      "Epoch 12/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0145 - val_loss: 0.0038\n",
      "Epoch 13/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0131 - val_loss: 0.0036\n",
      "Epoch 14/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0115 - val_loss: 0.0034\n",
      "Epoch 15/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0101 - val_loss: 0.0031\n",
      "Epoch 16/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0086 - val_loss: 0.0029\n",
      "Epoch 17/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 18/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0062 - val_loss: 0.0026\n",
      "Epoch 19/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 20/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 21/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 22/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 23/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 24/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 25/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 26/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 27/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 28/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 29/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 30/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 31/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 32/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 33/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 34/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 35/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 36/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 37/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 38/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 39/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 40/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 41/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 42/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 43/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 44/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 45/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 46/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 47/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 48/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 49/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 50/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 51/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 52/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 53/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 54/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 55/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 56/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 57/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 58/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 59/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 60/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 61/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - val_loss: 0.0054\n",
      "Epoch 62/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - val_loss: 0.0062\n",
      "Epoch 63/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0071\n",
      "Epoch 64/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0074\n",
      "Epoch 65/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 66/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - val_loss: 0.0073\n",
      "Epoch 67/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 68/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 69/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - val_loss: 0.0049\n",
      "Epoch 70/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 71/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 72/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 73/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 74/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 75/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 76/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 77/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 78/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0030 - val_loss: 0.0074\n",
      "Epoch 79/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0044 - val_loss: 0.0048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 81/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 7.5345e-04\n",
      "Epoch 82/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 7.7808e-04\n",
      "Epoch 83/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 7.8600e-04\n",
      "Epoch 84/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 7.8564e-04\n",
      "Epoch 85/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 7.8573e-04\n",
      "Epoch 86/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 7.9058e-04\n",
      "Epoch 87/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 8.0211e-04\n",
      "Epoch 88/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 8.2188e-04\n",
      "Epoch 89/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 8.5154e-04\n",
      "Epoch 90/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 8.9268e-04\n",
      "Epoch 91/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0011 - val_loss: 9.4691e-04\n",
      "Epoch 92/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 93/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 94/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 95/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 96/1000\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 97/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 98/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 99/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 100/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 101/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 102/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 103/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0027 - val_loss: 0.0318\n",
      "Epoch 104/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 105/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0036 - val_loss: 0.0096\n",
      "Epoch 106/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 107/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0027 - val_loss: 0.0088\n",
      "Epoch 108/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0031 - val_loss: 0.0120\n",
      "Epoch 109/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 110/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 111/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 112/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 113/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 114/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 115/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 116/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 117/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0031 - val_loss: 0.0094\n",
      "Epoch 118/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 119/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0021 - val_loss: 0.0054\n",
      "Epoch 120/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 121/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 122/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 123/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 124/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 125/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 126/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 127/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 128/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0022 - val_loss: 0.0084\n",
      "Epoch 129/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 130/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 131/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 132/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0059\n",
      "Epoch 133/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0052\n",
      "Epoch 134/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 135/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 136/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 137/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 138/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 139/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 140/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 141/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 142/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - val_loss: 0.0064\n",
      "Epoch 143/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - val_loss: 0.0087\n",
      "Epoch 144/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 145/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0066 - val_loss: 0.0135\n",
      "Epoch 146/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0074 - val_loss: 0.0032\n",
      "Epoch 147/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 148/1000\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0030 - val_loss: 0.0062\n",
      "Epoch 149/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0025 - val_loss: 0.0081\n",
      "Epoch 150/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - val_loss: 0.0079\n",
      "Epoch 151/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 152/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0040\n",
      "Epoch 153/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - val_loss: 0.0048\n",
      "Epoch 154/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 155/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0025 - val_loss: 0.0080\n",
      "Epoch 156/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0034 - val_loss: 0.0092\n",
      "Epoch 157/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0053 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 159/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 160/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0024 - val_loss: 0.0056\n",
      "Epoch 161/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 162/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0019 - val_loss: 0.0053\n",
      "Epoch 163/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 164/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 165/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0054\n",
      "Epoch 166/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 167/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 168/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0066\n",
      "Epoch 169/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 170/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0083\n",
      "Epoch 171/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0067\n",
      "Epoch 172/1000\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0013 - val_loss: 0.0120\n",
      "Epoch 173/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0018 - val_loss: 0.0104\n",
      "Epoch 174/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0082\n",
      "Epoch 175/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0066\n",
      "Epoch 176/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0056\n",
      "Epoch 177/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0046\n",
      "Epoch 178/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0071\n",
      "Epoch 179/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 180/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0047\n",
      "Epoch 181/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 182/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.9140e-04 - val_loss: 0.0038\n",
      "Epoch 183/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 184/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 185/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 186/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0037\n",
      "Epoch 187/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 188/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - val_loss: 0.0033\n",
      "Epoch 189/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0014 - val_loss: 0.0039\n",
      "Epoch 190/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 191/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 192/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0019 - val_loss: 0.0057\n",
      "Epoch 193/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - val_loss: 0.0043\n",
      "Epoch 194/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0022 - val_loss: 0.0077\n",
      "Epoch 195/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - val_loss: 0.0052\n",
      "Epoch 196/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0067\n",
      "Epoch 197/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 198/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - val_loss: 0.0055\n",
      "Epoch 199/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 200/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 201/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 202/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 203/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 204/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 205/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 206/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 207/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - val_loss: 0.0110\n",
      "Epoch 208/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 209/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 210/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0114\n",
      "Epoch 211/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 212/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0060\n",
      "Epoch 213/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Epoch 214/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 215/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0048\n",
      "Epoch 216/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 217/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 218/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 219/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0019 - val_loss: 0.0039\n",
      "Epoch 220/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 221/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 222/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 223/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 224/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 225/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 226/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 227/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 228/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 229/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 230/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 231/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 232/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.4177e-04 - val_loss: 0.0042\n",
      "Epoch 233/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 234/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 235/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - val_loss: 0.0040\n",
      "Epoch 237/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 238/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - val_loss: 0.0070\n",
      "Epoch 239/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0076\n",
      "Epoch 240/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 241/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 242/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 243/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 244/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 245/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 246/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - val_loss: 0.0048\n",
      "Epoch 247/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - val_loss: 0.0043\n",
      "Epoch 248/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0019 - val_loss: 0.0051\n",
      "Epoch 249/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 250/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - val_loss: 0.0053\n",
      "Epoch 251/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0020 - val_loss: 0.0047\n",
      "Epoch 252/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - val_loss: 0.0068\n",
      "Epoch 253/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 254/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 255/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 256/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 257/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0057\n",
      "Epoch 258/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0069\n",
      "Epoch 259/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 260/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0023 - val_loss: 0.0094\n",
      "Epoch 261/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 262/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0015 - val_loss: 0.0038\n",
      "Epoch 263/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - val_loss: 0.0038\n",
      "Epoch 264/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 265/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 266/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0021 - val_loss: 0.0091\n",
      "Epoch 267/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 268/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 269/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 270/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 271/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 272/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.0451e-04 - val_loss: 0.0028\n",
      "Epoch 273/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 274/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 275/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 276/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.8144e-04 - val_loss: 0.0016\n",
      "Epoch 277/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 8.2385e-04 - val_loss: 0.0026\n",
      "Epoch 278/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.9548e-04 - val_loss: 0.0026\n",
      "Epoch 279/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.2270e-04 - val_loss: 0.0032\n",
      "Epoch 280/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.0938e-04 - val_loss: 0.0042\n",
      "Epoch 281/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 282/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.9598e-04 - val_loss: 0.0048\n",
      "Epoch 283/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 284/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - val_loss: 0.0049\n",
      "Epoch 285/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.9489e-04 - val_loss: 0.0030\n",
      "Epoch 286/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0091\n",
      "Epoch 287/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0090\n",
      "Epoch 288/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - val_loss: 0.0035\n",
      "Epoch 290/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 291/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0042\n",
      "Epoch 292/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 293/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 294/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 295/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0030 - val_loss: 0.0055\n",
      "Epoch 296/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 297/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 298/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 299/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 300/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 301/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 302/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 303/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 304/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 305/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 306/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0017 - val_loss: 0.0054\n",
      "Epoch 307/1000\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 308/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 309/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 310/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 311/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6485e-04 - val_loss: 0.0022\n",
      "Epoch 312/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.4834e-04 - val_loss: 0.0022\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6405e-04 - val_loss: 0.0026\n",
      "Epoch 314/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.4511e-04 - val_loss: 0.0027\n",
      "Epoch 315/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 7.2685e-04 - val_loss: 0.0028\n",
      "Epoch 316/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.1258e-04 - val_loss: 0.0024\n",
      "Epoch 317/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.5323e-04 - val_loss: 0.0042\n",
      "Epoch 318/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 319/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0022 - val_loss: 0.0044\n",
      "Epoch 320/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 321/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 322/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 323/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 324/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 325/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 326/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 327/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 328/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0046\n",
      "Epoch 329/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0034\n",
      "Epoch 330/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.7337e-04 - val_loss: 0.0028\n",
      "Epoch 331/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.7909e-04 - val_loss: 0.0044\n",
      "Epoch 332/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0039\n",
      "Epoch 333/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8122e-04 - val_loss: 0.0046\n",
      "Epoch 334/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.0576e-04 - val_loss: 0.0027\n",
      "Epoch 335/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.2422e-04 - val_loss: 0.0032\n",
      "Epoch 336/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 337/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 338/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 339/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0080\n",
      "Epoch 340/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 341/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 342/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - val_loss: 0.0056\n",
      "Epoch 343/1000\n",
      "188/188 [==============================] - 5s 28ms/step - loss: 0.0015 - val_loss: 0.0045\n",
      "Epoch 344/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 345/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 346/1000\n",
      "188/188 [==============================] - 7s 38ms/step - loss: 9.8105e-04 - val_loss: 0.0047\n",
      "Epoch 347/1000\n",
      "188/188 [==============================] - 7s 39ms/step - loss: 0.0011 - val_loss: 0.0026\n",
      "Epoch 348/1000\n",
      "188/188 [==============================] - 8s 42ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 349/1000\n",
      "188/188 [==============================] - 7s 40ms/step - loss: 0.0011 - val_loss: 0.0024\n",
      "Epoch 350/1000\n",
      "188/188 [==============================] - 9s 48ms/step - loss: 9.7320e-04 - val_loss: 0.0022\n",
      "Epoch 351/1000\n",
      "188/188 [==============================] - 8s 40ms/step - loss: 9.3789e-04 - val_loss: 0.0033\n",
      "Epoch 352/1000\n",
      "188/188 [==============================] - 5s 27ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 353/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 354/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 355/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 356/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 9.9431e-04 - val_loss: 0.0048\n",
      "Epoch 357/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 358/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 359/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 360/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 361/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 8.1883e-04 - val_loss: 0.0019\n",
      "Epoch 362/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 8.1628e-04 - val_loss: 0.0028\n",
      "Epoch 363/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 9.1220e-04 - val_loss: 0.0031\n",
      "Epoch 364/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 365/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 0.0033\n",
      "Epoch 366/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 367/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0012 - val_loss: 0.0029\n",
      "Epoch 368/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 369/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.3555e-04 - val_loss: 0.0030\n",
      "Epoch 370/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 8.4947e-04 - val_loss: 0.0027\n",
      "Epoch 371/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.8251e-04 - val_loss: 0.0016\n",
      "Epoch 372/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0033\n",
      "Epoch 373/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 374/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 375/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 376/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.1772e-04 - val_loss: 0.0030\n",
      "Epoch 377/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 378/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0033\n",
      "Epoch 379/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0083\n",
      "Epoch 380/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - val_loss: 0.0095\n",
      "Epoch 381/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6907e-04 - val_loss: 0.0094\n",
      "Epoch 382/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.6358e-04 - val_loss: 0.0086\n",
      "Epoch 383/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9824e-04 - val_loss: 0.0095\n",
      "Epoch 384/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.9802e-04 - val_loss: 0.0067\n",
      "Epoch 385/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0058\n",
      "Epoch 386/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 387/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.6667e-04 - val_loss: 0.0017\n",
      "Epoch 388/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.2027e-04 - val_loss: 0.0018\n",
      "Epoch 389/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.6931e-04 - val_loss: 0.0024\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 14ms/step - loss: 7.3406e-04 - val_loss: 0.0046\n",
      "Epoch 391/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2485e-04 - val_loss: 0.0017\n",
      "Epoch 392/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0073\n",
      "Epoch 393/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 394/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 395/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 396/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0045\n",
      "Epoch 397/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8940e-04 - val_loss: 0.0037\n",
      "Epoch 398/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.4491e-04 - val_loss: 0.0029\n",
      "Epoch 399/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.4407e-04 - val_loss: 0.0017\n",
      "Epoch 400/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8002e-04 - val_loss: 0.0016\n",
      "Epoch 401/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6653e-04 - val_loss: 0.0011\n",
      "Epoch 402/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.0219e-04 - val_loss: 0.0015\n",
      "Epoch 403/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 404/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8990e-04 - val_loss: 0.0012\n",
      "Epoch 405/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8330e-04 - val_loss: 9.7370e-04\n",
      "Epoch 406/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 407/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 408/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 409/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0071\n",
      "Epoch 410/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 411/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 412/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8241e-04 - val_loss: 0.0027\n",
      "Epoch 413/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.1325e-04 - val_loss: 0.0028\n",
      "Epoch 414/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 415/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 416/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 417/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.3809e-04 - val_loss: 0.0019\n",
      "Epoch 418/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.1703e-04 - val_loss: 0.0015\n",
      "Epoch 419/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.0113e-04 - val_loss: 0.0012\n",
      "Epoch 420/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 421/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 422/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0033\n",
      "Epoch 423/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.0949e-04 - val_loss: 0.0023\n",
      "Epoch 424/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.2910e-04 - val_loss: 0.0021\n",
      "Epoch 425/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.7441e-04 - val_loss: 0.0018\n",
      "Epoch 426/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.9408e-04 - val_loss: 0.0028\n",
      "Epoch 427/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 428/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 429/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0031\n",
      "Epoch 430/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.8253e-04 - val_loss: 0.0020\n",
      "Epoch 431/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.1767e-04 - val_loss: 0.0013\n",
      "Epoch 432/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.2708e-04 - val_loss: 0.0018\n",
      "Epoch 433/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.3107e-04 - val_loss: 0.0018\n",
      "Epoch 434/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0044\n",
      "Epoch 435/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 436/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 437/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 438/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.0397e-04 - val_loss: 0.0019\n",
      "Epoch 439/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 440/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 441/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 442/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.3979e-04 - val_loss: 0.0022\n",
      "Epoch 443/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4749e-04 - val_loss: 0.0025\n",
      "Epoch 444/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7415e-04 - val_loss: 0.0019\n",
      "Epoch 445/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8387e-04 - val_loss: 0.0018\n",
      "Epoch 446/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7661e-04 - val_loss: 0.0023\n",
      "Epoch 447/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.8950e-04 - val_loss: 0.0012\n",
      "Epoch 448/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.1171e-04 - val_loss: 0.0011\n",
      "Epoch 449/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 450/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.9138e-04 - val_loss: 0.0020\n",
      "Epoch 451/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.5097e-04 - val_loss: 0.0028\n",
      "Epoch 452/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0201e-04 - val_loss: 0.0022\n",
      "Epoch 453/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.9233e-04 - val_loss: 0.0017\n",
      "Epoch 454/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.2795e-04 - val_loss: 0.0019\n",
      "Epoch 455/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.8264e-04 - val_loss: 0.0022\n",
      "Epoch 456/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.6274e-04 - val_loss: 0.0020\n",
      "Epoch 457/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.9298e-04 - val_loss: 0.0018\n",
      "Epoch 458/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 7.6786e-04 - val_loss: 0.0019\n",
      "Epoch 459/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 0.0029\n",
      "Epoch 460/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.8280e-04 - val_loss: 0.0016\n",
      "Epoch 461/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.3372e-04 - val_loss: 0.0014\n",
      "Epoch 462/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 7.9694e-04 - val_loss: 0.0020\n",
      "Epoch 463/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.2330e-04 - val_loss: 0.0019\n",
      "Epoch 464/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0414e-04 - val_loss: 0.0016\n",
      "Epoch 465/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 7.6656e-04 - val_loss: 0.0020\n",
      "Epoch 466/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 7.9605e-04 - val_loss: 0.0018\n",
      "Epoch 467/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.8545e-04 - val_loss: 0.0017\n",
      "Epoch 468/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 469/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.9941e-04 - val_loss: 0.0013\n",
      "Epoch 470/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 471/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 472/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 473/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 474/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.4593e-04 - val_loss: 0.0019\n",
      "Epoch 475/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.2562e-04 - val_loss: 0.0013\n",
      "Epoch 476/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0024\n",
      "Epoch 477/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 478/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 479/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 480/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Epoch 481/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 482/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 483/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.1276e-04 - val_loss: 0.0016\n",
      "Epoch 484/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4698e-04 - val_loss: 0.0021\n",
      "Epoch 485/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.1605e-04 - val_loss: 0.0016\n",
      "Epoch 486/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 6.6911e-04 - val_loss: 7.2686e-04\n",
      "Epoch 487/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 6.3142e-04 - val_loss: 0.0012\n",
      "Epoch 488/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 6.8281e-04 - val_loss: 0.0017\n",
      "Epoch 489/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.9110e-04 - val_loss: 0.0016\n",
      "Epoch 490/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 6.1017e-04 - val_loss: 8.2291e-04\n",
      "Epoch 491/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 6.2452e-04 - val_loss: 7.2120e-04\n",
      "Epoch 492/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 5.3578e-04 - val_loss: 0.0013\n",
      "Epoch 493/1000\n",
      "188/188 [==============================] - 4s 22ms/step - loss: 6.6997e-04 - val_loss: 0.0019\n",
      "Epoch 494/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.2125e-04 - val_loss: 0.0019\n",
      "Epoch 495/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 7.8368e-04 - val_loss: 0.0039\n",
      "Epoch 496/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 6.2838e-04 - val_loss: 0.0013\n",
      "Epoch 497/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 6.9036e-04 - val_loss: 0.0030\n",
      "Epoch 498/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.2540e-04 - val_loss: 0.0014\n",
      "Epoch 499/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.9351e-04 - val_loss: 0.0022\n",
      "Epoch 500/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4029e-04 - val_loss: 0.0019\n",
      "Epoch 501/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 9.6941e-04 - val_loss: 0.0015\n",
      "Epoch 502/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 503/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 504/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 505/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - val_loss: 0.0031\n",
      "Epoch 506/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 507/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 508/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 509/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Epoch 510/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 511/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 9.7219e-04 - val_loss: 0.0022\n",
      "Epoch 512/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.8394e-04 - val_loss: 0.0022\n",
      "Epoch 513/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 9.2954e-04 - val_loss: 0.0018\n",
      "Epoch 514/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 515/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.5077e-04 - val_loss: 0.0026\n",
      "Epoch 516/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.1411e-04 - val_loss: 0.0024\n",
      "Epoch 517/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.8611e-04 - val_loss: 0.0017\n",
      "Epoch 518/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6043e-04 - val_loss: 0.0016\n",
      "Epoch 519/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.9155e-04 - val_loss: 0.0037\n",
      "Epoch 520/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 521/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.4766e-04 - val_loss: 0.0025\n",
      "Epoch 522/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.5701e-04 - val_loss: 0.0022\n",
      "Epoch 523/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.8877e-04 - val_loss: 0.0023\n",
      "Epoch 524/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.1594e-04 - val_loss: 0.0022\n",
      "Epoch 525/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.7433e-04 - val_loss: 0.0021\n",
      "Epoch 526/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 527/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 528/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.5342e-04 - val_loss: 0.0020\n",
      "Epoch 529/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 530/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.8956e-04 - val_loss: 0.0022\n",
      "Epoch 531/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7976e-04 - val_loss: 0.0023\n",
      "Epoch 532/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.5776e-04 - val_loss: 0.0027\n",
      "Epoch 533/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 534/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 535/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0038\n",
      "Epoch 536/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 9.3467e-04\n",
      "Epoch 537/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8002e-04 - val_loss: 0.0018\n",
      "Epoch 538/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.8712e-04 - val_loss: 0.0017\n",
      "Epoch 539/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4486e-04 - val_loss: 0.0012\n",
      "Epoch 540/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 541/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.4114e-04 - val_loss: 0.0017\n",
      "Epoch 542/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 543/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 544/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9328e-04 - val_loss: 0.0019\n",
      "Epoch 545/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.4728e-04 - val_loss: 0.0020\n",
      "Epoch 546/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.3229e-04 - val_loss: 0.0019\n",
      "Epoch 547/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6236e-04 - val_loss: 0.0019\n",
      "Epoch 548/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9611e-04 - val_loss: 0.0018\n",
      "Epoch 549/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.1799e-04 - val_loss: 0.0022\n",
      "Epoch 550/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6031e-04 - val_loss: 0.0024\n",
      "Epoch 551/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 552/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 553/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 554/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 555/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 556/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 557/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 558/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 559/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.7430e-04 - val_loss: 0.0013\n",
      "Epoch 560/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.2529e-04 - val_loss: 0.0029\n",
      "Epoch 561/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.7483e-04 - val_loss: 0.0024\n",
      "Epoch 562/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.5905e-04 - val_loss: 0.0019\n",
      "Epoch 563/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.3417e-04 - val_loss: 0.0030\n",
      "Epoch 564/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.7529e-04 - val_loss: 0.0026\n",
      "Epoch 565/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.8751e-04 - val_loss: 0.0042\n",
      "Epoch 566/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.2441e-04 - val_loss: 0.0028\n",
      "Epoch 567/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 8.6644e-04 - val_loss: 0.0032\n",
      "Epoch 568/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.1737e-04 - val_loss: 0.0028\n",
      "Epoch 569/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 6.4503e-04 - val_loss: 0.0035\n",
      "Epoch 570/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.2265e-04 - val_loss: 0.0032\n",
      "Epoch 571/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.2238e-04 - val_loss: 0.0027\n",
      "Epoch 572/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 9.4261e-04 - val_loss: 0.0018\n",
      "Epoch 573/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.3482e-04 - val_loss: 0.0023\n",
      "Epoch 574/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.1757e-04 - val_loss: 0.0023\n",
      "Epoch 575/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 576/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0036\n",
      "Epoch 577/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 578/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.8788e-04 - val_loss: 0.0029\n",
      "Epoch 579/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0032\n",
      "Epoch 580/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 581/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.7581e-04 - val_loss: 0.0017\n",
      "Epoch 582/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 583/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.7993e-04 - val_loss: 0.0023\n",
      "Epoch 584/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 585/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.5066e-04 - val_loss: 0.0049\n",
      "Epoch 586/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 587/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.3424e-04 - val_loss: 0.0016\n",
      "Epoch 588/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6393e-04 - val_loss: 0.0026\n",
      "Epoch 589/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4613e-04 - val_loss: 0.0027\n",
      "Epoch 590/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4036e-04 - val_loss: 0.0026\n",
      "Epoch 591/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.5093e-04 - val_loss: 0.0021\n",
      "Epoch 592/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.4393e-04 - val_loss: 0.0024\n",
      "Epoch 593/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9308e-04 - val_loss: 0.0023\n",
      "Epoch 594/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.5771e-04 - val_loss: 0.0020\n",
      "Epoch 595/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.5284e-04 - val_loss: 0.0020\n",
      "Epoch 596/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.4244e-04 - val_loss: 0.0014\n",
      "Epoch 597/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6001e-04 - val_loss: 0.0022\n",
      "Epoch 598/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.9573e-04 - val_loss: 0.0018\n",
      "Epoch 599/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 8.8996e-04 - val_loss: 0.0021\n",
      "Epoch 600/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.6340e-04 - val_loss: 0.0017\n",
      "Epoch 601/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 602/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6375e-04 - val_loss: 0.0019\n",
      "Epoch 603/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.8799e-04 - val_loss: 0.0024\n",
      "Epoch 604/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 605/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 606/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 607/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 608/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 7.4317e-04 - val_loss: 0.0014\n",
      "Epoch 609/1000\n",
      "188/188 [==============================] - 4s 19ms/step - loss: 7.9363e-04 - val_loss: 0.0018\n",
      "Epoch 610/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 8.3829e-04 - val_loss: 0.0018\n",
      "Epoch 611/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.4624e-04 - val_loss: 0.0015\n",
      "Epoch 612/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7570e-04 - val_loss: 0.0013\n",
      "Epoch 613/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6514e-04 - val_loss: 0.0017\n",
      "Epoch 614/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.5612e-04 - val_loss: 0.0020\n",
      "Epoch 615/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.5935e-04 - val_loss: 0.0024\n",
      "Epoch 616/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 7.8337e-04 - val_loss: 0.0018\n",
      "Epoch 617/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.1152e-04 - val_loss: 0.0024\n",
      "Epoch 618/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 16ms/step - loss: 6.3802e-04 - val_loss: 0.0017\n",
      "Epoch 619/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.2483e-04 - val_loss: 0.0016\n",
      "Epoch 620/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 6.0793e-04 - val_loss: 0.0018\n",
      "Epoch 621/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 5.8250e-04 - val_loss: 0.0015\n",
      "Epoch 622/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 5.8953e-04 - val_loss: 0.0017\n",
      "Epoch 623/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 5.7931e-04 - val_loss: 0.0016\n",
      "Epoch 624/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.0274e-04 - val_loss: 0.0014\n",
      "Epoch 625/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 5.7803e-04 - val_loss: 0.0016\n",
      "Epoch 626/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 6.0719e-04 - val_loss: 0.0030\n",
      "Epoch 627/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 5.9065e-04 - val_loss: 0.0017\n",
      "Epoch 628/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 5.9424e-04 - val_loss: 0.0019\n",
      "Epoch 629/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 6.5932e-04 - val_loss: 0.0025\n",
      "Epoch 630/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.5086e-04 - val_loss: 0.0025\n",
      "Epoch 631/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.3984e-04 - val_loss: 0.0024\n",
      "Epoch 632/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.4502e-04 - val_loss: 0.0038\n",
      "Epoch 633/1000\n",
      "188/188 [==============================] - 3s 19ms/step - loss: 8.0734e-04 - val_loss: 0.0033\n",
      "Epoch 634/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 6.1834e-04 - val_loss: 0.0021\n",
      "Epoch 635/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 5.8532e-04 - val_loss: 0.0023\n",
      "Epoch 636/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 5.9233e-04 - val_loss: 0.0021\n",
      "Epoch 637/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.2438e-04 - val_loss: 0.0018\n",
      "Epoch 638/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4104e-04 - val_loss: 0.0032\n",
      "Epoch 639/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 640/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 641/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 642/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 643/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.1463e-04 - val_loss: 0.0017\n",
      "Epoch 644/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8798e-04 - val_loss: 0.0012\n",
      "Epoch 645/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 646/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 647/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.5770e-04 - val_loss: 0.0015\n",
      "Epoch 648/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 649/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.3737e-04 - val_loss: 0.0016\n",
      "Epoch 650/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.0836e-04 - val_loss: 0.0020\n",
      "Epoch 651/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7674e-04 - val_loss: 0.0015\n",
      "Epoch 652/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9889e-04 - val_loss: 0.0019\n",
      "Epoch 653/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.4960e-04 - val_loss: 0.0016\n",
      "Epoch 654/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 655/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.3161e-04 - val_loss: 0.0018\n",
      "Epoch 656/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.3117e-04 - val_loss: 0.0014\n",
      "Epoch 657/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.4031e-04 - val_loss: 0.0019\n",
      "Epoch 658/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.0680e-04 - val_loss: 0.0031\n",
      "Epoch 659/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.7008e-04 - val_loss: 0.0011\n",
      "Epoch 660/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 661/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 662/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8437e-04 - val_loss: 0.0024\n",
      "Epoch 663/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.6661e-04 - val_loss: 0.0021\n",
      "Epoch 664/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.4773e-04 - val_loss: 0.0019\n",
      "Epoch 665/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.5125e-04 - val_loss: 0.0023\n",
      "Epoch 666/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0028\n",
      "Epoch 667/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 668/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 669/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.1663e-04 - val_loss: 0.0021\n",
      "Epoch 670/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.3676e-04 - val_loss: 0.0023\n",
      "Epoch 671/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 672/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 673/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.6847e-04 - val_loss: 0.0020\n",
      "Epoch 674/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2591e-04 - val_loss: 0.0021\n",
      "Epoch 675/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.8150e-04 - val_loss: 0.0020\n",
      "Epoch 676/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.5157e-04 - val_loss: 0.0018\n",
      "Epoch 677/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.8536e-04 - val_loss: 0.0020\n",
      "Epoch 678/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6697e-04 - val_loss: 0.0030\n",
      "Epoch 679/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 7.4951e-04 - val_loss: 0.0036\n",
      "Epoch 680/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.0257e-04 - val_loss: 0.0018\n",
      "Epoch 681/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.5832e-04 - val_loss: 0.0035\n",
      "Epoch 682/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.2866e-04 - val_loss: 0.0044\n",
      "Epoch 683/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.2364e-04 - val_loss: 0.0042\n",
      "Epoch 684/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.9947e-04 - val_loss: 0.0039\n",
      "Epoch 685/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.2767e-04 - val_loss: 0.0030\n",
      "Epoch 686/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.2845e-04 - val_loss: 0.0033\n",
      "Epoch 687/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7513e-04 - val_loss: 0.0025\n",
      "Epoch 688/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6795e-04 - val_loss: 0.0032\n",
      "Epoch 689/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.6875e-04 - val_loss: 0.0030\n",
      "Epoch 690/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2838e-04 - val_loss: 0.0036\n",
      "Epoch 691/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 692/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 693/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.3926e-04 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 695/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.2564e-04 - val_loss: 0.0027\n",
      "Epoch 696/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 697/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0043\n",
      "Epoch 698/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 699/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 700/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 701/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0054\n",
      "Epoch 702/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2163e-04 - val_loss: 0.0032\n",
      "Epoch 703/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.7626e-04 - val_loss: 0.0037\n",
      "Epoch 704/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0044\n",
      "Epoch 705/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 706/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8776e-04 - val_loss: 0.0018\n",
      "Epoch 707/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7676e-04 - val_loss: 0.0023\n",
      "Epoch 708/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0034\n",
      "Epoch 709/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.8855e-04 - val_loss: 0.0019\n",
      "Epoch 710/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 711/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 712/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 713/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 714/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 715/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 716/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 717/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 718/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0026\n",
      "Epoch 719/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 720/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.9869e-04 - val_loss: 0.0016\n",
      "Epoch 721/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 722/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 723/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 724/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 725/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8099e-04 - val_loss: 0.0027\n",
      "Epoch 726/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 727/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8271e-04 - val_loss: 9.9960e-04\n",
      "Epoch 728/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 729/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9805e-04 - val_loss: 0.0013\n",
      "Epoch 730/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9243e-04 - val_loss: 0.0015\n",
      "Epoch 731/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.4554e-04 - val_loss: 0.0015\n",
      "Epoch 732/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.8896e-04 - val_loss: 0.0017\n",
      "Epoch 733/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.6510e-04 - val_loss: 0.0016\n",
      "Epoch 734/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6566e-04 - val_loss: 0.0012\n",
      "Epoch 735/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.8422e-04 - val_loss: 0.0012\n",
      "Epoch 736/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.3452e-04 - val_loss: 0.0011\n",
      "Epoch 737/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.9882e-04 - val_loss: 0.0010\n",
      "Epoch 738/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 739/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 740/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.5169e-04 - val_loss: 0.0014\n",
      "Epoch 741/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.4207e-04 - val_loss: 0.0013\n",
      "Epoch 742/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.5237e-04 - val_loss: 0.0011\n",
      "Epoch 743/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.3492e-04 - val_loss: 0.0015\n",
      "Epoch 744/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7844e-04 - val_loss: 0.0011\n",
      "Epoch 745/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6926e-04 - val_loss: 0.0015\n",
      "Epoch 746/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.3350e-04 - val_loss: 0.0014\n",
      "Epoch 747/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.8856e-04 - val_loss: 0.0015\n",
      "Epoch 748/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.5201e-04 - val_loss: 0.0020\n",
      "Epoch 749/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 750/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.0885e-04 - val_loss: 0.0011\n",
      "Epoch 751/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 752/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0034\n",
      "Epoch 753/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.6706e-04 - val_loss: 0.0012\n",
      "Epoch 754/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.2780e-04 - val_loss: 0.0013\n",
      "Epoch 755/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.7898e-04 - val_loss: 0.0017\n",
      "Epoch 756/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.6945e-04 - val_loss: 0.0019\n",
      "Epoch 757/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 758/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 8.7114e-04 - val_loss: 0.0015\n",
      "Epoch 759/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.2821e-04 - val_loss: 0.0019\n",
      "Epoch 760/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.7302e-04 - val_loss: 0.0018\n",
      "Epoch 761/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.8613e-04 - val_loss: 0.0017\n",
      "Epoch 762/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 6.8889e-04 - val_loss: 0.0023\n",
      "Epoch 763/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 7.6674e-04 - val_loss: 0.0020\n",
      "Epoch 764/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 6.5267e-04 - val_loss: 0.0014\n",
      "Epoch 765/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 8.5017e-04 - val_loss: 0.0015\n",
      "Epoch 766/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.0712e-04 - val_loss: 0.0030\n",
      "Epoch 767/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 7.9888e-04 - val_loss: 0.0020\n",
      "Epoch 768/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 7.7202e-04 - val_loss: 0.0029\n",
      "Epoch 769/1000\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 7.3911e-04 - val_loss: 0.0027\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 17ms/step - loss: 7.0413e-04 - val_loss: 0.0022\n",
      "Epoch 771/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.1257e-04 - val_loss: 0.0021\n",
      "Epoch 772/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.5550e-04 - val_loss: 0.0022\n",
      "Epoch 773/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 774/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 775/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.3091e-04 - val_loss: 0.0017\n",
      "Epoch 776/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.1209e-04 - val_loss: 0.0010\n",
      "Epoch 777/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.4506e-04 - val_loss: 0.0014\n",
      "Epoch 778/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.8276e-04 - val_loss: 0.0021\n",
      "Epoch 779/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.8278e-04 - val_loss: 0.0020\n",
      "Epoch 780/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.7019e-04 - val_loss: 0.0024\n",
      "Epoch 781/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.0856e-04 - val_loss: 0.0023\n",
      "Epoch 782/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.8753e-04 - val_loss: 0.0028\n",
      "Epoch 783/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 784/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 0.0011 - val_loss: 0.0044\n",
      "Epoch 785/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.1829e-04 - val_loss: 0.0021\n",
      "Epoch 786/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.5946e-04 - val_loss: 0.0013\n",
      "Epoch 787/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 788/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 789/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 9.2240e-04 - val_loss: 0.0015\n",
      "Epoch 790/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6202e-04 - val_loss: 0.0015\n",
      "Epoch 791/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.8412e-04 - val_loss: 0.0014\n",
      "Epoch 792/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.6801e-04 - val_loss: 0.0015\n",
      "Epoch 793/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.4948e-04 - val_loss: 0.0014\n",
      "Epoch 794/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.5468e-04 - val_loss: 0.0015\n",
      "Epoch 795/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.0725e-04 - val_loss: 0.0015\n",
      "Epoch 796/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.4277e-04 - val_loss: 0.0013\n",
      "Epoch 797/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.8278e-04 - val_loss: 0.0015\n",
      "Epoch 798/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.1673e-04 - val_loss: 0.0016\n",
      "Epoch 799/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.3980e-04 - val_loss: 0.0015\n",
      "Epoch 800/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.6973e-04 - val_loss: 0.0017\n",
      "Epoch 801/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.3019e-04 - val_loss: 0.0013\n",
      "Epoch 802/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.4887e-04 - val_loss: 0.0016\n",
      "Epoch 803/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.3578e-04 - val_loss: 0.0013\n",
      "Epoch 804/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.8942e-04 - val_loss: 0.0018\n",
      "Epoch 805/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7456e-04 - val_loss: 0.0013\n",
      "Epoch 806/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.5256e-04 - val_loss: 0.0016\n",
      "Epoch 807/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.0293e-04 - val_loss: 0.0017\n",
      "Epoch 808/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.8183e-04 - val_loss: 0.0020\n",
      "Epoch 809/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0930e-04 - val_loss: 0.0015\n",
      "Epoch 810/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6782e-04 - val_loss: 0.0020\n",
      "Epoch 811/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.5354e-04 - val_loss: 8.4787e-04\n",
      "Epoch 812/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.7616e-04 - val_loss: 0.0010\n",
      "Epoch 813/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.9740e-04 - val_loss: 0.0011\n",
      "Epoch 814/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0291e-04 - val_loss: 0.0016\n",
      "Epoch 815/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7733e-04 - val_loss: 7.6627e-04\n",
      "Epoch 816/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.9292e-04 - val_loss: 0.0016\n",
      "Epoch 817/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.5016e-04 - val_loss: 0.0020\n",
      "Epoch 818/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 7.0421e-04 - val_loss: 0.0016\n",
      "Epoch 819/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6011e-04 - val_loss: 0.0015\n",
      "Epoch 820/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.7364e-04 - val_loss: 0.0015\n",
      "Epoch 821/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.9416e-04 - val_loss: 0.0013\n",
      "Epoch 822/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.0111e-04 - val_loss: 0.0028\n",
      "Epoch 823/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.5422e-04 - val_loss: 0.0012\n",
      "Epoch 824/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.1800e-04 - val_loss: 0.0015\n",
      "Epoch 825/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.5644e-04 - val_loss: 0.0015\n",
      "Epoch 826/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.1740e-04 - val_loss: 0.0012\n",
      "Epoch 827/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.5289e-04 - val_loss: 0.0012\n",
      "Epoch 828/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8995e-04 - val_loss: 0.0016\n",
      "Epoch 829/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.4408e-04 - val_loss: 0.0018\n",
      "Epoch 830/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.4806e-04 - val_loss: 0.0022\n",
      "Epoch 831/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.8987e-04 - val_loss: 0.0016\n",
      "Epoch 832/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 8.1410e-04\n",
      "Epoch 833/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.8329e-04 - val_loss: 0.0013\n",
      "Epoch 834/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.3214e-04 - val_loss: 0.0022\n",
      "Epoch 835/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.5464e-04 - val_loss: 0.0024\n",
      "Epoch 836/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.7285e-04 - val_loss: 0.0025\n",
      "Epoch 837/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.7187e-04 - val_loss: 0.0022\n",
      "Epoch 838/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.5679e-04 - val_loss: 0.0022\n",
      "Epoch 839/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.7722e-04 - val_loss: 0.0020\n",
      "Epoch 840/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.5505e-04 - val_loss: 0.0026\n",
      "Epoch 841/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.8486e-04 - val_loss: 0.0022\n",
      "Epoch 842/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.2229e-04 - val_loss: 0.0020\n",
      "Epoch 843/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0624e-04 - val_loss: 0.0021\n",
      "Epoch 844/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.1404e-04 - val_loss: 0.0026\n",
      "Epoch 845/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 15ms/step - loss: 9.1658e-04 - val_loss: 0.0020\n",
      "Epoch 846/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 9.4618e-04 - val_loss: 0.0025\n",
      "Epoch 847/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 848/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.7020e-04 - val_loss: 0.0046\n",
      "Epoch 849/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.0111e-04 - val_loss: 0.0030\n",
      "Epoch 850/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6185e-04 - val_loss: 0.0034\n",
      "Epoch 851/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7936e-04 - val_loss: 0.0021\n",
      "Epoch 852/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0423e-04 - val_loss: 0.0025\n",
      "Epoch 853/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7358e-04 - val_loss: 0.0025\n",
      "Epoch 854/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6189e-04 - val_loss: 0.0029\n",
      "Epoch 855/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.3153e-04 - val_loss: 0.0016\n",
      "Epoch 856/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.0541e-04 - val_loss: 0.0021\n",
      "Epoch 857/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.2211e-04 - val_loss: 0.0026\n",
      "Epoch 858/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.5695e-04 - val_loss: 0.0030\n",
      "Epoch 859/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.9744e-04 - val_loss: 0.0020\n",
      "Epoch 860/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.2679e-04 - val_loss: 0.0012\n",
      "Epoch 861/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2529e-04 - val_loss: 0.0010\n",
      "Epoch 862/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.2069e-04 - val_loss: 0.0015\n",
      "Epoch 863/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.7442e-04 - val_loss: 0.0017\n",
      "Epoch 864/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 865/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.3820e-04 - val_loss: 0.0020\n",
      "Epoch 866/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.2087e-04 - val_loss: 0.0016\n",
      "Epoch 867/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 8.8391e-04 - val_loss: 0.0014\n",
      "Epoch 868/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.5840e-04 - val_loss: 0.0014\n",
      "Epoch 869/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.8153e-04 - val_loss: 0.0012\n",
      "Epoch 870/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.7577e-04 - val_loss: 8.9270e-04\n",
      "Epoch 871/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0244e-04 - val_loss: 9.4279e-04\n",
      "Epoch 872/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 5.9099e-04 - val_loss: 9.2391e-04\n",
      "Epoch 873/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 5.8828e-04 - val_loss: 5.5900e-04\n",
      "Epoch 874/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.4732e-04 - val_loss: 6.0566e-04\n",
      "Epoch 875/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.6729e-04 - val_loss: 5.9075e-04\n",
      "Epoch 876/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.7819e-04 - val_loss: 7.4545e-04\n",
      "Epoch 877/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.9141e-04 - val_loss: 5.9499e-04\n",
      "Epoch 878/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8791e-04 - val_loss: 6.6241e-04\n",
      "Epoch 879/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.3407e-04 - val_loss: 8.8465e-04\n",
      "Epoch 880/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.3421e-04 - val_loss: 5.8750e-04\n",
      "Epoch 881/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.4564e-04 - val_loss: 7.5763e-04\n",
      "Epoch 882/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0712e-04 - val_loss: 5.8872e-04\n",
      "Epoch 883/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.5450e-04 - val_loss: 5.6130e-04\n",
      "Epoch 884/1000\n",
      "188/188 [==============================] - 3s 16ms/step - loss: 9.4307e-04 - val_loss: 6.4593e-04\n",
      "Epoch 885/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0012 - val_loss: 7.7263e-04\n",
      "Epoch 886/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6650e-04 - val_loss: 6.7342e-04\n",
      "Epoch 887/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9237e-04 - val_loss: 5.0058e-04\n",
      "Epoch 888/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.1378e-04 - val_loss: 6.1450e-04\n",
      "Epoch 889/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.5520e-04 - val_loss: 6.4206e-04\n",
      "Epoch 890/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.0246e-04 - val_loss: 7.7460e-04\n",
      "Epoch 891/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.0213e-04 - val_loss: 8.7057e-04\n",
      "Epoch 892/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2814e-04 - val_loss: 9.4660e-04\n",
      "Epoch 893/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.6241e-04 - val_loss: 0.0022\n",
      "Epoch 894/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.5746e-04 - val_loss: 0.0010\n",
      "Epoch 895/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.1382e-04 - val_loss: 0.0012\n",
      "Epoch 896/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.4538e-04 - val_loss: 7.9703e-04\n",
      "Epoch 897/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.1959e-04 - val_loss: 7.9457e-04\n",
      "Epoch 898/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9012e-04 - val_loss: 0.0012\n",
      "Epoch 899/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7584e-04 - val_loss: 7.7816e-04\n",
      "Epoch 900/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.1102e-04 - val_loss: 0.0011\n",
      "Epoch 901/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 902/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 7.0145e-04\n",
      "Epoch 903/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 904/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6699e-04 - val_loss: 8.8986e-04\n",
      "Epoch 905/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0012 - val_loss: 8.9891e-04\n",
      "Epoch 906/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.9579e-04 - val_loss: 9.2673e-04\n",
      "Epoch 907/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.5265e-04 - val_loss: 0.0022\n",
      "Epoch 908/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.2203e-04 - val_loss: 0.0026\n",
      "Epoch 909/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.8278e-04 - val_loss: 7.0915e-04\n",
      "Epoch 910/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 7.5340e-04\n",
      "Epoch 911/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.9970e-04 - val_loss: 6.5066e-04\n",
      "Epoch 912/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.1509e-04 - val_loss: 6.3583e-04\n",
      "Epoch 913/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.2900e-04 - val_loss: 7.4092e-04\n",
      "Epoch 914/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.1221e-04 - val_loss: 6.2022e-04\n",
      "Epoch 915/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.9162e-04 - val_loss: 6.2237e-04\n",
      "Epoch 916/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.3626e-04 - val_loss: 7.0217e-04\n",
      "Epoch 917/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.4534e-04 - val_loss: 7.5251e-04\n",
      "Epoch 918/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.3062e-04 - val_loss: 7.7180e-04\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 3s 14ms/step - loss: 6.2000e-04 - val_loss: 0.0017\n",
      "Epoch 920/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.4277e-04 - val_loss: 8.0541e-04\n",
      "Epoch 921/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7858e-04 - val_loss: 9.5884e-04\n",
      "Epoch 922/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.8630e-04 - val_loss: 9.3616e-04\n",
      "Epoch 923/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.1105e-04 - val_loss: 8.9878e-04\n",
      "Epoch 924/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.9983e-04 - val_loss: 8.4157e-04\n",
      "Epoch 925/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.8063e-04 - val_loss: 7.0521e-04\n",
      "Epoch 926/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.2390e-04 - val_loss: 8.4407e-04\n",
      "Epoch 927/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.2959e-04 - val_loss: 6.9399e-04\n",
      "Epoch 928/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.6681e-04 - val_loss: 7.2420e-04\n",
      "Epoch 929/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.8133e-04 - val_loss: 0.0010\n",
      "Epoch 930/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.5729e-04 - val_loss: 6.6965e-04\n",
      "Epoch 931/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.2099e-04 - val_loss: 6.8147e-04\n",
      "Epoch 932/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.3907e-04 - val_loss: 7.5736e-04\n",
      "Epoch 933/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7264e-04 - val_loss: 7.9550e-04\n",
      "Epoch 934/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.1717e-04 - val_loss: 0.0016\n",
      "Epoch 935/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.8242e-04 - val_loss: 0.0016\n",
      "Epoch 936/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.6906e-04 - val_loss: 0.0013\n",
      "Epoch 937/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.9988e-04 - val_loss: 0.0014\n",
      "Epoch 938/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.7540e-04 - val_loss: 0.0016\n",
      "Epoch 939/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.5872e-04 - val_loss: 0.0010\n",
      "Epoch 940/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.1169e-04 - val_loss: 0.0014\n",
      "Epoch 941/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7164e-04 - val_loss: 0.0011\n",
      "Epoch 942/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.2817e-04 - val_loss: 0.0016\n",
      "Epoch 943/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7648e-04 - val_loss: 0.0010\n",
      "Epoch 944/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.9000e-04 - val_loss: 8.7321e-04\n",
      "Epoch 945/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.8620e-04 - val_loss: 0.0012\n",
      "Epoch 946/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 5.7849e-04 - val_loss: 9.1567e-04\n",
      "Epoch 947/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 6.3176e-04 - val_loss: 0.0013\n",
      "Epoch 948/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.5558e-04 - val_loss: 0.0011\n",
      "Epoch 949/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.2434e-04 - val_loss: 0.0014\n",
      "Epoch 950/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7834e-04 - val_loss: 7.1064e-04\n",
      "Epoch 951/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.6861e-04 - val_loss: 8.0498e-04\n",
      "Epoch 952/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.8557e-04 - val_loss: 8.9908e-04\n",
      "Epoch 953/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 954/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 955/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.9900e-04 - val_loss: 8.6888e-04\n",
      "Epoch 956/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2839e-04 - val_loss: 8.6088e-04\n",
      "Epoch 957/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2660e-04 - val_loss: 0.0012\n",
      "Epoch 958/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.5426e-04 - val_loss: 0.0014\n",
      "Epoch 959/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.3602e-04 - val_loss: 0.0012\n",
      "Epoch 960/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.3506e-04 - val_loss: 0.0011\n",
      "Epoch 961/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.5668e-04 - val_loss: 0.0013\n",
      "Epoch 962/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.8297e-04 - val_loss: 7.7867e-04\n",
      "Epoch 963/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 9.2420e-04 - val_loss: 0.0016\n",
      "Epoch 964/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.6609e-04 - val_loss: 9.6260e-04\n",
      "Epoch 965/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 8.3171e-04 - val_loss: 0.0015\n",
      "Epoch 966/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7172e-04 - val_loss: 0.0011\n",
      "Epoch 967/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.9454e-04 - val_loss: 0.0018\n",
      "Epoch 968/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.7898e-04 - val_loss: 0.0014\n",
      "Epoch 969/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.3891e-04 - val_loss: 0.0011\n",
      "Epoch 970/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.3498e-04 - val_loss: 0.0015\n",
      "Epoch 971/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.4570e-04 - val_loss: 0.0013\n",
      "Epoch 972/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.0045e-04 - val_loss: 0.0016\n",
      "Epoch 973/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.8313e-04 - val_loss: 6.5831e-04\n",
      "Epoch 974/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.6057e-04 - val_loss: 7.8531e-04\n",
      "Epoch 975/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.6514e-04 - val_loss: 8.3361e-04\n",
      "Epoch 976/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.1268e-04 - val_loss: 0.0011\n",
      "Epoch 977/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 8.4681e-04 - val_loss: 0.0011\n",
      "Epoch 978/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.2122e-04 - val_loss: 7.3727e-04\n",
      "Epoch 979/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.0783e-04 - val_loss: 9.3379e-04\n",
      "Epoch 980/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 7.7290e-04 - val_loss: 8.9915e-04\n",
      "Epoch 981/1000\n",
      "188/188 [==============================] - 3s 15ms/step - loss: 7.0475e-04 - val_loss: 0.0011\n",
      "Epoch 982/1000\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 6.2034e-04 - val_loss: 0.0021\n",
      "Epoch 983/1000\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 7.1949e-04 - val_loss: 0.0021\n",
      "Epoch 984/1000\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 6.0508e-04 - val_loss: 0.0012\n",
      "Epoch 985/1000\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 6.1442e-04 - val_loss: 0.0013\n",
      "Epoch 986/1000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 7.2539e-04 - val_loss: 0.0010\n",
      "Epoch 987/1000\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 5.8796e-04 - val_loss: 0.0012\n",
      "Epoch 988/1000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 6.5911e-04 - val_loss: 0.0015\n",
      "Epoch 989/1000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 6.8363e-04 - val_loss: 0.0014\n",
      "Epoch 990/1000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 7.1758e-04 - val_loss: 0.0019\n",
      "Epoch 991/1000\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 6.5291e-04 - val_loss: 0.0023\n",
      "Epoch 992/1000\n",
      "188/188 [==============================] - 2s 13ms/step - loss: 6.8235e-04 - val_loss: 0.0021\n",
      "Epoch 993/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 2s 13ms/step - loss: 7.7623e-04 - val_loss: 0.0025\n",
      "Epoch 994/1000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 9.5145e-04 - val_loss: 0.0022\n",
      "Epoch 995/1000\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 7.9842e-04 - val_loss: 0.0014\n",
      "Epoch 996/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 6.3276e-04 - val_loss: 0.0030\n",
      "Epoch 997/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 7.0498e-04 - val_loss: 0.0019\n",
      "Epoch 998/1000\n",
      "188/188 [==============================] - 4s 21ms/step - loss: 7.0124e-04 - val_loss: 0.0034\n",
      "Epoch 999/1000\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 7.8705e-04 - val_loss: 0.0034\n",
      "Epoch 1000/1000\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 8.9908e-04 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=40, min_delta=0.0001)\n",
    "history = lstm_model.fit(X_train, y_train, epochs=params[\"epochs\"], batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n",
    "                        trim_dataset(y_val, BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57aef319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 16:16:58.123723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 16:16:58.260744: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-14 16:16:58.354189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 0.0014686385294609755 (88,) (88,)\n",
      "[0.28380027 0.3047194  0.3108907  0.31068984 0.3132493  0.34347388\n",
      " 0.38582274 0.3713802  0.32992896 0.33950943 0.32026696 0.32203707\n",
      " 0.32868063 0.32920122 0.3439246 ]\n",
      "[0.36873156 0.37463126 0.38053096 0.35693217 0.35693217 0.35693217\n",
      " 0.35693217 0.35103243 0.35693217 0.35103243 0.36283187 0.35103243\n",
      " 0.35693217 0.38053096 0.37463126]\n",
      "[0.78604144 0.82149935 0.8319597  0.83161926 0.8359575  0.8871882\n",
      " 0.95896953 0.9344894  0.86422956 0.8804685  0.84785247 0.85085285\n",
      " 0.86211365 0.86299604 0.8879522 ]\n",
      "[0.93000001 0.94       0.94999999 0.91000003 0.91000003 0.91000003\n",
      " 0.91000003 0.89999998 0.91000003 0.89999998 0.92000002 0.89999998\n",
      " 0.91000003 0.94999999 0.94      ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lstm_model.predict(trim_dataset(x_test_t, BATCH_SIZE), batch_size=BATCH_SIZE)\n",
    "y_pred = y_pred.flatten()\n",
    "y_test_t = trim_dataset(y_test_t, BATCH_SIZE)\n",
    "error = mean_squared_error(y_test_t, y_pred)\n",
    "print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "print(y_pred[0:15])\n",
    "print(y_test_t[0:15])\n",
    "\n",
    "# convert the predicted value to range of real data\n",
    "y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "# min_max_scaler.inverse_transform(y_pred)\n",
    "y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "# min_max_scaler.inverse_transform(y_test_t)\n",
    "print(y_pred_org[0:15])\n",
    "print(y_test_t_org[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d5451f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28c230040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtRElEQVR4nO3deXxV1b338c8vJ/NAGBIGGUxUREGtICqW1lqtCtiKvW2ts+3z9FKfq1Xb2hZvba2t91Zra9VqxQlbrEKt2koVlVrBGSUoSpgkMgYICRAyjyfr+WOfkDNBTiCQsPm+Xy9eZw9rn7N2Er5nnbXW3secc4iIiH8l9XQFRETkwFLQi4j4nIJeRMTnFPQiIj6noBcR8bnknq5APHl5ea6goKCnqyEicshYsmTJdudcfrx9vTLoCwoKKCoq6ulqiIgcMsxsw572qetGRMTnFPQiIj6noBcR8ble2UcvItJVLS0tlJaW0tjY2NNVOaDS09MZNmwYKSkpCR+joBcRXygtLSUnJ4eCggLMrKerc0A459ixYwelpaUUFhYmfJy6bkTEFxobGxkwYIBvQx7AzBgwYECXP7Uo6EXEN/wc8u325Rx9FfR/+PcaXv+koqerISLSq/gq6P+48FPeLtne09UQkcPQrl27+OMf/9jl46ZMmcKuXbu6v0JhfBX04A1WiIgcbHsK+mAwuNfj5s2bR9++fQ9QrTy+mnVzGHTPiUgvNX36dD799FNOPvlkUlJSyM7OZsiQISxdupQVK1Zw0UUXsWnTJhobG7nhhhuYNm0a0HHLl9raWiZPnsznPvc53nnnHYYOHcrzzz9PRkbGftfNV0EvIgJw2z+Xs2JLdbc+5+gj+nDrV8bscf8dd9xBcXExS5cuZeHChVxwwQUUFxfvngY5c+ZM+vfvT0NDA6eeeipf+9rXGDBgQMRzrFmzhtmzZ/PII49w8cUX8+yzz3LFFVfsd919F/TquRGR3uC0006LmOt+33338fe//x2ATZs2sWbNmpigLyws5OSTTwbglFNOYf369d1SF18FvXpuRATYa8v7YMnKytq9vHDhQl599VXeffddMjMzOeuss+LOhU9LS9u9HAgEaGho6Ja6JDQYa2aTzGy1mZWY2fQ4+48zs3fNrMnMbgrbPtzMFpjZSjNbbmY3dEut90INehHpCTk5OdTU1MTdV1VVRb9+/cjMzGTVqlUsWrTooNat0xa9mQWAB4BzgVJgsZnNdc6tCCu2E7geuCjq8Fbgh865D8wsB1hiZv+KOrbbHA4XS4hI7zRgwAAmTpzICSecQEZGBoMGDdq9b9KkScyYMYOTTjqJUaNGMWHChINat0S6bk4DSpxzawHMbA4wFdgd1s65cqDczC4IP9A5txXYGlquMbOVwNDwY7ub+uhFpKc89dRTcbenpaXx0ksvxd3X3g+fl5dHcXHx7u033XRT3PL7IpGum6HAprD10tC2LjGzAmAs8N4e9k8zsyIzK6qo2LerW9WeFxGJlUjQx8vPLrWbzSwbeBa40TkXd86Tc+5h59x459z4/Py4X3uYEKdeehGRCIkEfSkwPGx9GLAl0RcwsxS8kH/SOfdc16rXRWrSi4jESCToFwMjzazQzFKBS4C5iTy5eaOjjwErnXN373s1RURkX3U6GOucazWz64BXgAAw0zm33MyuCe2fYWaDgSKgD9BmZjcCo4GTgCuBZWa2NPSU/+2cm9ftZ7K7vgfqmUVEDk0JXTAVCuZ5UdtmhC2X4XXpRHuLg9ihop4bEZFYvrt7pYhIT9jX2xQD3HPPPdTX13dzjTr4Kuh1wZSI9JTeHPS+utcN6H70ItIzwm9TfO655zJw4ECefvppmpqa+OpXv8ptt91GXV0dF198MaWlpQSDQX72s5+xbds2tmzZwhe/+EXy8vJYsGBBt9fNV0GvBr2IAPDSdChb1r3POfhEmHzHHneH36Z4/vz5PPPMM7z//vs457jwwgt54403qKio4IgjjuDFF18EvHvg5Obmcvfdd7NgwQLy8vK6t84hvuq6ERHpDebPn8/8+fMZO3Ys48aNY9WqVaxZs4YTTzyRV199lZ/85Ce8+eab5ObmHpT6+KpFD7p7pYiw15b3weCc4+abb+a73/1uzL4lS5Ywb948br75Zs477zx+/vOfH/D6+KpFr54bEekp4bcpPv/885k5cya1tbUAbN68mfLycrZs2UJmZiZXXHEFN910Ex988EHMsQeC/1r0atKLSA8Iv03x5MmTueyyyzjjjDMAyM7O5i9/+QslJSX86Ec/IikpiZSUFB588EEApk2bxuTJkxkyZMgBGYy13jhLZfz48a6oqKjLx4371b+44MQh/OqiEw5ArUSkN1u5ciXHH398T1fjoIh3rma2xDk3Pl55X3XdgO5eKSISzVdBrz56EZFYvgp6ETm89cau6O62L+fou6A/DH7PIhJHeno6O3bs8HXYO+fYsWMH6enpXTrOV7NudGWsyOFr2LBhlJaWsq9fRXqoSE9PZ9iweDcL3jNfBT3ogimRw1VKSgqFhYU9XY1eyWddN2rSi4hE81nQq49eRCSar4JeffQiIrF8FfQeNelFRML5KujVoBcRieWroBcRkVi+C3oNxoqIRPJV0GswVkQkVkJBb2aTzGy1mZWY2fQ4+48zs3fNrMnMburKsd1NLXoRkUidBr2ZBYAHgMnAaOBSMxsdVWwncD3w2304ttuYhmNFRGIk0qI/DShxzq11zjUDc4Cp4QWcc+XOucVAS1eP7W66H72ISKREgn4osClsvTS0LREJH2tm08ysyMyK9vWmROqjFxGJlUjQx4vPRJvNCR/rnHvYOTfeOTc+Pz8/wacXEZHOJBL0pcDwsPVhwJYEn39/jt0nGowVEYmUSNAvBkaaWaGZpQKXAHMTfP79ObbL1HMjIhKr0/vRO+dazew64BUgAMx0zi03s2tC+2eY2WCgCOgDtJnZjcBo51x1vGMP0Ll49T2QTy4icghK6ItHnHPzgHlR22aELZfhdcskdOyBYhqNFRGJ4asrY0F99CIi0XwX9CIiEsl3Qa8LpkREIvkq6NVFLyISy1dBLyIisfwX9Oq5ERGJ4KugV9eNiEgsXwU9qEEvIhLNV0Gv+9GLiMTyVdADOF0xJSISwVdBrz56EZFYvgp6ERGJ5bugV8eNiEgkXwW9em5ERGL5KuhBd68UEYnmq6DX/ehFRGL5KuhBffQiItF8FfRqz4uIxPJV0IuISCzfBb2ujBURieSvoFffjYhIDH8FPRqMFRGJllDQm9kkM1ttZiVmNj3OfjOz+0L7PzazcWH7vm9my82s2Mxmm1l6d55ARD0O1BOLiBzCOg16MwsADwCTgdHApWY2OqrYZGBk6N804MHQsUOB64HxzrkTgABwSbfVPh416UVEIiTSoj8NKHHOrXXONQNzgKlRZaYCs5xnEdDXzIaE9iUDGWaWDGQCW7qp7jF0wZSISKxEgn4osClsvTS0rdMyzrnNwG+BjcBWoMo5Nz/ei5jZNDMrMrOiioqKROsfw6lJLyISIZGgj9dMjk7TuGXMrB9ea78QOALIMrMr4r2Ic+5h59x459z4/Pz8BKqVWEVFRA53iQR9KTA8bH0Ysd0veyrzJWCdc67COdcCPAd8dt+rKyIiXZVI0C8GRppZoZml4g2mzo0qMxe4KjT7ZgJeF81WvC6bCWaWaV4H+jnAym6sfwxdLyUiEim5swLOuVYzuw54BW/WzEzn3HIzuya0fwYwD5gClAD1wLdD+94zs2eAD4BW4EPg4QNxIqCvEhQRiafToAdwzs3DC/PwbTPClh1w7R6OvRW4dT/q2CVq0YuIRPLVlbGm4VgRkRi+CnrQ9EoRkWi+Cnr10YuIxPJV0IuISCzfBb0GY0VEIvku6EVEJJLvgl4NehGRSL4Ket29UkQklq+CHtRHLyISzVdBr/a8iEgsXwW9R016EZFwvgp6ddGLiMTyVdCLiEgs3wW9BmNFRCL5KujVdSMiEstXQQ8aihURiearoNf96EVEYvkq6AGcOulFRCL4KujVRy8iEstXQS8iIrF8F/TquBERieSroFfPjYhILF8FPeiCKRGRaAkFvZlNMrPVZlZiZtPj7Dczuy+0/2MzGxe2r6+ZPWNmq8xspZmd0Z0nEFWRA/bUIiKHqk6D3swCwAPAZGA0cKmZjY4qNhkYGfo3DXgwbN+9wMvOueOAzwAru6Hee6QGvYhIpERa9KcBJc65tc65ZmAOMDWqzFRglvMsAvqa2RAz6wOcCTwG4Jxrds7t6r7qR1J7XkQkViJBPxTYFLZeGtqWSJmjgArgcTP70MweNbOseC9iZtPMrMjMiioqKhI+ARER2btEgj5eQzm6h2RPZZKBccCDzrmxQB0Q08cP4Jx72Dk33jk3Pj8/P4FqxacrY0VEIiUS9KXA8LD1YcCWBMuUAqXOufdC25/BC/4DQmOxIiKxEgn6xcBIMys0s1TgEmBuVJm5wFWh2TcTgCrn3FbnXBmwycxGhcqdA6zorsqLiEjnkjsr4JxrNbPrgFeAADDTObfczK4J7Z8BzAOmACVAPfDtsKf4HvBk6E1ibdS+bqUGvYhIrE6DHsA5Nw8vzMO3zQhbdsC1ezh2KTB+36vYNeqiFxGJ5KsrY02d9CIiMXwV9ABOl0yJiETwVdCrPS8iEstXQS8iIrF8F/QajBURieSroNdYrIhILF8FPahFLyISzVdBbxqOFRGJ4augB02vFBGJ5q+gV4NeRCSGv4JeRERi+C7oNRgrIhLJV0GvnhsRkVi+CnrQl4OLiETzVdDrgikRkVi+CnpATXoRkSi+CnpdMCUiEstXQS8iIrF8F/S6MlZEJJKvgl6DsSIisXwV9KALpkREovkq6NWiFxGJlVDQm9kkM1ttZiVmNj3OfjOz+0L7PzazcVH7A2b2oZm90F0V3xM16EVEInUa9GYWAB4AJgOjgUvNbHRUscnAyNC/acCDUftvAFbud207oemVIiKxEmnRnwaUOOfWOueagTnA1KgyU4FZzrMI6GtmQwDMbBhwAfBoN9Z7j5w66UVEIiQS9EOBTWHrpaFtiZa5B/gx0LZvVUyc+uhFRGIlEvTx4jO62Ry3jJl9GSh3zi3p9EXMpplZkZkVVVRUJFAtERFJRCJBXwoMD1sfBmxJsMxE4EIzW4/X5XO2mf0l3os45x52zo13zo3Pz89PsPpxnmefjxQR8adEgn4xMNLMCs0sFbgEmBtVZi5wVWj2zQSgyjm31Tl3s3NumHOuIHTca865K7rzBEREZO+SOyvgnGs1s+uAV4AAMNM5t9zMrgntnwHMA6YAJUA98O0DV+XO6ttTrywi0jt1GvQAzrl5eGEevm1G2LIDru3kORYCC7tcwy4wjcaKiMTw1ZWxoD56EZFovgp6tedFRGL5KuhFRCSW/4Jeo7EiIhF8FfQaixURieWroAcNxoqIRPNV0Pdog765Dlqbe7IGIiJx+SrooQe76P/3CHh8Ug+9uIjInvkq6Hv8gqnNnd67TUTkoPNV0AM49dKLiETwVdBr0o2ISCxfBb2IiMTyXdDreikRkUi+CvqeHosVEemNfBX0oBa9iEg0nwW9mvQiItF8FvS6BYKISDRfBb366EVEYvkq6EVEJJbvgt5pNFZEJIKvgt6AVWU13Pzcsp6uiohIr+GroG83+/2NatmLiIT4KuibWtt2L5dVN/ZgTUREeo+Egt7MJpnZajMrMbPpcfabmd0X2v+xmY0LbR9uZgvMbKWZLTezG7r7BMKt214Xd1lE5HDWadCbWQB4AJgMjAYuNbPRUcUmAyND/6YBD4a2twI/dM4dD0wAro1zbLfZuLN+9/L67fV7KSkicvhIpEV/GlDinFvrnGsG5gBTo8pMBWY5zyKgr5kNcc5tdc59AOCcqwFWAkO7sf57tG577cF4GY/GA0SkF0sk6IcCm8LWS4kN607LmFkBMBZ4L96LmNk0Mysys6KKiooEqrVnuRkprDuYLXoFvYj0YokEfbzrTaOTba9lzCwbeBa40TlXHe9FnHMPO+fGO+fG5+fnJ1CtPTt2UDbrdxzEPnrX1nkZEZEekkjQlwLDw9aHAVsSLWNmKXgh/6Rz7rl9r2riRg7KYeOOeoJtB6mlraAXkV4skaBfDIw0s0IzSwUuAeZGlZkLXBWafTMBqHLObTXv27ofA1Y65+7u1prvxahBOTQH29iyq+EgvaK6bkSk9+o06J1zrcB1wCt4g6lPO+eWm9k1ZnZNqNg8YC1QAjwC/Fdo+0TgSuBsM1sa+jelu08i2shB2QCsPVhTLNWiF5FeLDmRQs65eXhhHr5tRtiyA66Nc9xb9MBN4o8Z6AX9+u11fOHY/evvT4iCXkR6MV9dGdsuPzuNrNTAwbtoSrNuRKQX82XQmxkFeVkHMejVoheR3suXQQ9QmJd18KZYKuhFpBfzddBv2llPc+tBCOF9DfrtJRBs6d66iIhE8XXQtznYVNlL73lTvQXuPwXm/6ynayIiPueroM/PSdu9XJCXBXgzbw64fWnR127zHje+0711ERGJktD0ykPFgpvOoqklCEDhAC/oD8qAbHjQ/yIXfrgacgbv/Zhgq/eYlLLnMrMvg0Fj4Oyf7n8dReSw5asWfXZaMgOyvVZ9v6xU+mamHKSgj5peWbG682OCTd5jIHXPZVa/CG/8JrHXf/033pvMjk87Ly8ihxVfBX20ggEHaYpldNdNcnrnxwSbvcfAXlr0ifrkFVjwP6Hll/f/+UTEV3wd9IV5WT3TR59IeLe2B/1eWvSJqi3bc11E5LDn+6DfUtVIY6jf/oCJDlfXBm/dA09+Y8/HtITegNqDfs2rXst893OEdQe1NnVSgbC7TOxL0LcF4blpsPkDWPt6/Ct9174Oddu7/tz7qvhZryvqF7kH7zVFfMrXQb975s0Bv3AqKhiDzfDqrbBmfmi3g60fR5YpX+k9JoeC/smvwVMXd+xvCZsWWrO1C1XZh6Cv2gQf/xUe+SLMuhDefyRyf/UWb/ufv9L1595XK57vWNYtJkT2i6+D/qiDNcUyOlzDLoKa+cdfs2nhTHjo85Et9tLF3uPyv8M798c+58th38FeHSfoqzbHD8DOgr4tzv7GqO+CKV8Rf3/09q547X+gtCjx8uHn3KwvehfZH74O+vYW/T59rWDR4/DCD6Buh7deVgxv3BW/bHS4tnUE/f8pv4Mlb4cCftfGjjINuzqW58eZPvnBEx3LpYs7+vTB+zTw+9Hw/sOxx/37l14XS/1OmH9L5HFv3AW/7BfbFVQX9dWN0ftbG2Nfpyvagt7soUfPSfyYprA3n4ZKWDUPNr0fWaa5zjtPEdkrXwd9dloyedlpXf+i8Pqd8MKNUPQYvBe6G/Ofvwyv3R6/dRnVsnZRtzVIbgm9flpOR5mGyvivXb4q9Hxhz/mvn8Ht+R3dGZXrvceXfuw9WtSdoHd8Cq/9Ct75A6z4R8f21273Hpc+5T2WFsGLN8GqFyKPjw72TscIOtG8D1/U3tIAKd4bNY27YM6l8Ni5kWX+eAb8pnD/6iZyGPB10IPXfbO+qy36jYu8x0AaLPubt9x+gVP9jtjyUUG/ZulbEevpbaHX3/Q+NHmh58Jb9OH+eDq8fW/8fe897L3WezM6tsXrvmlr7fiU0VgVu/+FG73jHjsXFj/S0VJO9e7jH9ui389v6mqq6foxLQ3Q/yhveee6+GV2bdj3OokcRvwV9M318MpP4ZP5uzcV5GV2/Zum1r/lhfznvg+V66CplsqWgLcv3syTqK6bY1dG9rmnEJr1U/QYPPl1aAuS1BQngNu9emvHcka/juXkVKjeDGsXdmxb8Y/YG6OteB6SM7zllgbY+hHMvjSyTEtDR723FXuP7S3vvbXoy1fCP2/0uoEaq73xhZ1rY89h59qON5DwoA8fZN2blgYYfhokJcPWpYkdI91v7euwIvqbQ+VQ46+gn/9TePd+eOob8OlrABw7KIfttU2UduXmZuvegBGnQ/4ob71yPbXB0Nz4uC36vQ+AWng3zMZ347ey9yQ37DvXA6neDJhwf/tWbNC//xDUhMp9+m946ExYPS+yzP8O2fNrhgd7bUXkbKD5t8CSx71uoFkXej/zv3zd27d5CTx2vjf+8MjZ3ieG2oqOi7kAnr4Kdm3yllf+c/fvKUZLPWT0hfTcyDGEeN1IfpiVs3YhPHWJ98lx9mWw7s2erhE8f533O376yp6uSdfUlO3+5Cwe/wS9c96A3TFfgkEnwJzLYfMSzh/j3XPm2SWbE3uenWth2zI4+mzoV+BtW/E8w5O8sFm/MV53wd6DJkDUG8G9JydWl89cCqdN61ivKYvtp4b4XSvtLefw1n+iwlv0D5wWua/k1Y7lLR96j+1vXP/+JWxa5L12+xjEb4/xAj3cQ2d6j3+9Ap74qvdGte5NWP+2tz3YAi4IKRmQ1gc+mNVx7O0DY+vbEudNPNgKD070ZjV1hXPe9NLw7iLnoGU/B6Tj1e+Vn0JVqbf+5Dfgk5egfLl364u/Xt69r9eZZc/APSd5f2PtPgybEPD0VQfutde+Dvef5n0i7w6/GxX//8mh4AA1WvwT9K1NMO5KLxiveA6y8mD2ZQxP3sU5xw3kvtfWcO1TH/Dnd9azcUe8YGjxph4unQ2WBCde3BH0YfebWb4mTjdFJy36iYHlkRv21m0T7vM/9M7pK/d56+FdGJ/9Xsfyq7/oWL5qrlf3rhrymY7l9lZzYzU0JDCrJSl0b7y2UBfVB7Mgc8Ceyzfs9LqT2s2+xBvs/tMU79NAe1dPSmbEAPZu7Z8I2rUPkNft6JiWWb/d65Ja8ueuXei1/k2Yd5MXwu0W/hr+Z1D8IGqq8d64tizt2Fa6xLvQa9vy2PLtNhd5nz5/P8br4mq/JUZZqBvN9uG/5j9vhEfO8X5/bV24SHD7Gnj2/3pjHrMu8j61lS2LLLPiedj4nve8L96UeHfO+rc6/86FF74P21fH7wLsqvagLF8Rfypxb+UcvH4XPPudA/IdFf4J+pR0OPsWOPZ8yBkEl87x+pxnX8LdFx3NxeOH88GGSm6du5wz71rAWXct4JonlnD3/NUse+F+3G+OhgfPgKVPwpETIXeo1z8eFVjZwV2xr72ftx1Y952VLE8Zs3u99nsr4Eu3wYBjvA2nXB0Z3kedBefdDv8RdWHT9UvhqC/AlLvgiHGxLzThv7znjdZ3BO7SOR3r25bBnQXwxEWJnUBSMtSWeyEJXohFd3GddTMMHd+x3t6qh8hPCXce2TGTJq2P9y/axncjxmH4x//zZhrdexLcfRz8+UKYeb63b+0CuOtoWPSg9+byyDle2ZptXsu9PRg2vON9wmi/IV34G1H74PdHs71PHfef2nFtwcZFXtn5t3jr5Svh79Nizyvchnc76geRrc/n/8t7bKjs+FTUbuns+G8en7zidbMsedz72f/PEJg1NbbcC9+HhXd4dV/yJ68bsKEy8kK4ipXebK0Zn4s9fuZ5sKPEG8B/+krYtiL2QsBwm96HP10Ar9/Zse3V2+DxKR3TlgF2hm7El2iXZllxx8yzds55zxn+M/vrFfD01ZGfCLuiuf7gXA3uHDz3n7Dgdu/vpytv0gny1W2KIwwaA19/HGZ/k9yHxvHrwSfBMQOoScphTU0qJTUpbChNYuwnb3Ji4CNWtQ3nuKZVADwWvICv17eQm5kCJ30TFv1x99Omt8S2cF3DrvCbEOyV+49Hsee+A8C3mn/MzkAeI9+pYFpzze47Gcxe3sR/nnlj5IETb4CcwTSN/gZ3FbXS9I9ilmwYwu3f/IBxr12OO3Ii9CvAgH+vbyLznGc444mjdh/eEMghY9KvvdZv1SZ+sf1sGj5ZwKAjj+faqWdy+ZPreSb89RoqvT73cOl9eSF1EudV/Y1UC/tjrC6F347c63k/0nQu6SdcwpUFj8Pb9yT2wxp5Lqx6MXb7lg9h8aMd6yWvwh/C3tjWvR57TPgFaOFl80dB9mB4fLK33t7NVF3qXZSWO7QjgF78QcdxdwyHrIFQV+6tr38TXvpJ5Iyophq4ewxceC98usBrwV88K/FukDsLYNQF3u0ywrvgbt3lPcfKufDjdZFjKOB1e61/E5b/A8Zc5AX7qhegaKa3f+GvE3t9gIuf8H7W7T/T8K68B8/wHqe9DkecHHtsWehNoHyl10r9923emwjAXUd5nz6XPtlRPvp6jnZNtd4ntH4FXvjOmOht/+En8PEcb5rwyjifMFaH/nZW/AM+c5k3Gy1lDzccDLZ6v7vx34bUrI7zq1wPv+jCmFqi1r0J+cd5v6vfjerYfvGf91zH/WCuFw5kjR8/3hUVdeEqyr3ZuMhrvewo8ebHN+wMXazknbdLzWbTyT/g6aQpfHPxNxge3MTnm/9AZn4BY4b2obWqjPs2f5NFbceTSSNNqf059RZvANE5x/I1a9n82kOcX/YQAK0uieWugOL08Vze/DSbs8YwtK6jFXZJzix+UH0nrW2OXw64k1ML+vPEog2caquYmXU/k2pvpTwwkEtPG8HKrdWkJifx2NWnkp4S4PG313HbP2OvTr3v0rFcP9vrL//S8QN5daUXPuvTLwPgu83fp3DsOQwcMoyzjxtIdnoy42/vaG0O7ZvB5l0Nu8tH6DuC0s/fSd2AE0nP6c/v5n/CnavOI8OaY4o25Z/IN0ovZm5ax7dmuVsqeKu4hCvneH3eb153IsPf/m+Ca98i0FRJecowBraUEjzuKwRWdfTlf/z5GZQPOZsvbbwXFj2wx1/vRU2/5Nmc3xJort5jmf1y4jc6pth2t7RcuPY971MIeNNJu6P7IsTlDsPGfLUjXDtz5EQYeyUcMdYb96naTNWR59Jn3UvY367e+7Gjp8IXprOuPo0jK98h6e17vP9zXVF4pvfJNdgEq1+Gkn9F7s8dAVVhFx2mZid+jUYgFQaOhqvnegP80Yqfg2e+7XWJnne716r+ZX9v3627vJb9/J/C5Ds7ZsKtXQgfzYG+I7wG1Bd+7I1xDDjG63qr3wEb3vbGrsArd2FoRt7vR3u//2BT5JjYLeWQ3PEFSl1hZkucc+Pj7ksk6M1sEnAvEAAedc7dEbXfQvunAPXAt5xzHyRybDzdGvTxtAW9VlrjLq9VlhaaP15bDmXLeLlxDLf8oxhwVDe00hpsxZnxROY9DG3ZyLP5/8WAYAVHV73LZ9s+JNk6um6mZP+VddvruGzCUdw0tJj0Uy7HqkuZ9co7zP9oPW+1nciI/pls3FnP/5lYyLc+W8CZdy0A4JUbz+SjTbv48bORH4cH5qSRnhJg486uDVb9d/KTDLEdfK/l+oTKT056j6mBd7im5fscl9vKg8l3896YnzH9jciZLm+lXc8w206DSyXDmjm36Td8dsJE0lMCPPTGWsbaGv6ediuvBU/m8YLfsGJLNTvqOt4Y8rJT2V7bTD6VVJPFfwTeZFnfs3mo7kaGUsGP7Af8rcH7e/3ysCamNT7KCTXvkGSOD9NPZ2zjewCsbxvEWc2/J8WCrEnzZoY82Xcar5dn8XDq7wGY3vIdvpS0hLL0o7ii5VkAPs6/kEB9OWPqFsX9OfwreArnBpbE3QfwTnA0N7Zcy88Hvc3wlrWMaFnHzFEPk7R5MSXbqhmRl81Pqv93d/nSzNEsTx/HzorNXBrwftdBS+buMc8yfMRRFKx4kCfXBNiQM5bLa2fxRttJ/GfWm3z02fu48o0vkuRaE/r9LTx3HtkDhuI+mMWjxUEeSr0nbrmncqfxcU02GxozGJtTzZTBVfTNSmfbcVezZFcGW6sa2bijnpKKWjbtrKewXwpfr55FMynckPwcAGvahjIyKcEJDlGWj/9fsksXcmSZ1/12y9HPcO2GGxjSum/PB7DxW0toa2lkzbL3GLPyXl495QFGbvgrx1cuoG9j6e5yTZmD2XnGzSxrGgxlxbzRchyV9S18N/lFTtoa/w39+VP/wufL/0L/DS/TFMhi/dFX0tZUzfEbnopbvo0AlYH+DAjGfkJpyB5ORm3kGFPNwPHklBdRduRXePnYX/Gtift2EeB+Bb2ZBYBPgHOBUmAxcKlzbkVYmSnA9/CC/nTgXufc6YkcG88BD/ou2FrVwIsfb+WKCUdS9vQPKFjzp937KpPz2dHvZNrS+1J/whWcPKI/L+/I5/VPKvjheaPIy+54Z24NtvHQG2sZN6IfY0f05ZXlZZw3ejAZqQG2VTeyfnsdpx/ljQdUN7bw0rKtBJKSKKtqYOHqCnY1tDAkN53rvngMxw7KoV+WdzO0h17/lFeWl3H6UQPYXNnAkNx0+mSkcNaofIo3V1G8uZqc9GReLi7j4lOHU93QQtH6Si47fQSTThjMxp31PPT6Wq4/5xgaWoLkZ6dx/ZwP+XhTFXXNrbSF/XnccM5ISisbmDK0jmMr3+RZziE/PUhxdQZ/XbyJNgeD+6Tzh8vG8ttnXmdHMIONNQ4Dfvbl0azYWk1JeS2Vdc2sKa/lqPws1lZ4A6l90pNpbGkDg9RAErVNXrgNyErd/SaRl51GurXw08bfMTFpOX9Ov5z7686hqbWN0baekWk7eb7R65YZZRvZ6gZQTehjOI7pyXP4uK2QeW0TAMihnjaMIElMSFpJjWWT3NbCpC9/jdf/NZc/8XMAylw/ftFyNWvcUCqSBnJEfn8qapp21ys5yetzaw37Yb2ZcRN92nYxtflXrHdDdtfha4PKaanexpsNBVQSZ/whShYNJBOkimzSaeJzScVsdnlUumzKGEASbXwmeT3FwRG0uPCeWMf/C/yTo5O2ML3lOwRJ4gtJH3OCreP+4EWwl87GJIOBOemUVUfONDKDbxdWcWHdM3xt27cIEuD7yX/j7KQPub/1q3wjsJDPJH1KCkFWuRFUuSyyaeCp4Dm83TaGGjLpTw0V9AXgZ8lPsMUN4G8pF3Iyq/hc63u8HDyVPlbHZpfPibaWBtIocUP5V5p3FfjbwTF86I6hPzXUkc5FgbeocZmc3Xx33HNJo5k7Uh7h5eCptBLgsdTfdfoz74otrj9HWOcTFta3DaIgadvu9WqXST1pPBM8k3tbv0ZfatlOHwb1yWThj84iPSXQ5brsb9CfAfzCOXd+aP1mAOfcr8PKPAQsdM7NDq2vBs4CCjo7Np7eFPQRmmq8gbeUDO+TQO6w2NsP+Miu+mZqm1oZ1i+z07Ibd9RTWlnPqME5u7/lC6CtzRF0jpTAnsf9t1Y1MCArjeQko6WtjbTkyD/yDzdWkp2WzMhB3gycYJsjlK1Y6Odf19RKIMloc46axlZqGlvYWdfCScNyaXOOXfUtrCqrZnCfDMqqGzh2UA4pgSRWbq2mtqmViUfnkZKcRFlVI8cMzKamsYWidxdQ2pRJbWMz6fmFnFrQnzFH9Nn9msE2x0eluzh2UA4ZKQGSDNoc1De3kpOeQk1jC9lpybQEHa1tbWSmekHc1BpkzbZahvfP5N1Pd9DUGuTMkfm737wBaptaqWtqZd32OnbVtzC+oB952WmsLqthR10T+dlprCqrYd32OhpaggTMGH1EH7bXNlHfHOTy00fQ0BIkJy2FDTvr6JeZSkZqgOQko6qhhSQzBuak0drmKK1sYHNlAy3BNgrzskhPCTA4N7KfeEdtE1lpyTEB5JyjqqGFddvryExNpiAvk+LNVeRmpHJ0vvcm29rmqG8O8kpxGWkpSQzJzaCuqZVjB+fQ0Bzk6PwszIy2Nkfxlio+Kq0iLZBETnoyRw7Ioqk1SJJrZWf5FhqT+3DMEXnUNLWSl5XG4jWbSAkk0Ug6KcnGEbkZnDgsl6L1lTS3thEIGClJSQzOTaO8uolgXQXZS2eSnZ5CfuWHuD7DyU1PYlPWaCqPvZjchs0MyTaSXQsrKSR346u0lS2jOjmPdRkncPLoUaSu/idmjl0ZR7Ko7XjaLIXPDOtDcWklg105R+dnc3RhIaV1AZYu+5gjjxrFjvoWajd+RIqBwyhNKaR0VwMD+6QzqE862WkBWoKOc44fuPvvpKv2N+i/Dkxyzn0ntH4lcLpz7rqwMi8Adzjn3gqt/xv4CV7Q7/XYsOeYBkwDGDFixCkbNujydhGRRO0t6BOZXhmvyRr97rCnMokc62107mHn3Hjn3Pj8/PwEqiUiIolI5DNCKRB2HT7DgC0JlklN4FgRETmAEmnRLwZGmlmhmaUClwDRk1bnAleZZwJQ5ZzbmuCxIiJyAHXaonfOtZrZdcAreFMkZzrnlpvZNaH9M4B5eDNuSvCmV357b8cekDMREZG4/H/BlIjIYWB/B2NFROQQpqAXEfE5Bb2IiM/1yj56M6sA9vWKqTzgINxbtFfROR8edM7+tz/ne6RzLu5FSL0y6PeHmRXtaUDCr3TOhweds/8dqPNV142IiM8p6EVEfM6PQf9wT1egB+icDw86Z/87IOfruz56ERGJ5McWvYiIhFHQi4j4nG+C3swmmdlqMysxs+k9XZ/uYmbDzWyBma00s+VmdkNoe38z+5eZrQk99gs75ubQz2G1mZ3fc7XfP2YWMLMPQ19s4/tzNrO+ZvaMma0K/b7POAzO+fuhv+tiM5ttZul+O2czm2lm5WZWHLaty+doZqeY2bLQvvvMuvD1ds65Q/4f3p0xPwWOwrsH/kfA6J6uVzed2xBgXGg5B+87eEcDvwGmh7ZPB+4MLY8OnX8aUBj6uQR6+jz28dx/ADwFvBBa9/U5A38GvhNaTgX6+vmcgaHAOiAjtP408C2/nTNwJjAOKA7b1uVzBN4HzsD7QqeXgMmJ1sEvLfrTgBLn3FrnXDMwB5jaw3XqFs65rc65D0LLNcBKvP8gU/GCgdDjRaHlqcAc51yTc24d3q2jTzuole4GZjYMuAB4NGyzb8/ZzPrgBcJjAM65ZufcLnx8ziHJQIaZJQOZeF9M5Ktzds69AUR/g3iXztHMhgB9nHPvOi/1Z4Ud0ym/BP1QYFPYemlom6+YWQEwFngPGOS8L3ch9DgwVMwvP4t7gB8DbWHb/HzORwEVwOOh7qpHzSwLH5+zc24z8FtgI7AV7wuL5uPjcw7T1XMcGlqO3p4QvwR9wt9Ne6gys2zgWeBG51z13orG2XZI/SzM7MtAuXNuSaKHxNl2SJ0zXst2HPCgc24sUIf3kX5PDvlzDvVLT8XrojgCyDKzK/Z2SJxth9Q5J2C/v387Hr8EfSLfa3vIMrMUvJB/0jn3XGjzttDHOUKP5aHtfvhZTAQuNLP1eN1wZ5vZX/D3OZcCpc6590Lrz+AFv5/P+UvAOudchXOuBXgO+Cz+Pud2XT3H0tBy9PaE+CXoffvdtKGR9ceAlc65u8N2zQWuDi1fDTwftv0SM0szs0JgJN4gziHDOXezc26Yc64A73f5mnPuCvx9zmXAJjMbFdp0DrACH58zXpfNBDPLDP2dn4M3BuXnc27XpXMMde/UmNmE0M/qqrBjOtfTI9LdOLI9BW9GyqfAT3u6Pt14Xp/D+4j2MbA09G8KMAD4N7Am9Ng/7Jifhn4Oq+nCyHxv/AecRcesG1+fM3AyUBT6Xf8D6HcYnPNtwCqgGHgCb7aJr84ZmI03BtGC1zL/v/tyjsD40M/pU+B+Qnc2SOSfboEgIuJzfum6ERGRPVDQi4j4nIJeRMTnFPQiIj6noBcR8TkFvYiIzynoRUR87v8DQlbGBcU4bNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0263432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78604144 0.82149935 0.8319597  0.83161926 0.8359575  0.8871882\n",
      " 0.95896953 0.9344894  0.86422956 0.8804685  0.84785247 0.85085285\n",
      " 0.86211365 0.86299604 0.8879522 ]\n",
      "[0.625      0.63499999 0.64499998 0.60500002 0.60500002 0.60500002\n",
      " 0.60500002 0.59499997 0.60500002 0.59499997 0.61500001 0.59499997\n",
      " 0.60500002 0.64499998 0.63499999]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_lstm_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_pred)\n",
    "y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3] # min_max_scaler.inverse_transform(y_test_t)\n",
    "\n",
    "print(y_pred_lstm_org[0:15])\n",
    "print(y_test_t_org[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "190bdf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(np.arange(0, len(y_train)), y_train, 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test_t_org)), y_test_t_org, marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test_t_org)), y_pred_org, 'r',marker='*' ,label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26382ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "Predicted direction accuracy (Up/down):\n",
      "0.5632183908045977\n"
     ]
    }
   ],
   "source": [
    "y_pred_lstm_final = np.zeros((len(y_pred)-1,))\n",
    "y_test_t_final = np.zeros((len(y_test_t)-1,))\n",
    "for i in range(len(y_pred)-1):\n",
    "    if y_pred[i+1] >= y_pred[i]:\n",
    "        y_pred_lstm_final[i] = 1\n",
    "    else:\n",
    "        y_pred_lstm_final[i] = 0\n",
    "        \n",
    "#convert prediction into binary output (up or down movement)\n",
    "for i in range(len(y_test_t)-1):\n",
    "    if y_test_t[i+1] >= y_test_t[i]:\n",
    "        y_test_t_final[i] = 1\n",
    "    else:\n",
    "        y_test_t_final[i] = 0\n",
    "\n",
    "\n",
    "# error_lstm = mean_absolute_error(y_test_t_final, y_pred_lstm_final)\n",
    "# print(\"Error is\", error_lstm, y_pred_lstm_final.shape, y_test_t_final.shape)\n",
    "print(y_pred_lstm_final[0:15])\n",
    "print(y_test_t_final[0:15])\n",
    "print(\"Predicted direction accuracy (Up/down):\")\n",
    "print(accuracy_score(y_test_t_final,y_pred_lstm_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75fb6e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>H-L</th>\n",
       "      <th>O-C</th>\n",
       "      <th>% Change</th>\n",
       "      <th>3day MA</th>\n",
       "      <th>10day MA</th>\n",
       "      <th>30day MA</th>\n",
       "      <th>Std_dev</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-20</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2541225</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.807667</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.786041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-21</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>770188</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.042105</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.819667</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>0.821499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-24</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>417188</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.832333</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>0.831960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-25</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>517000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.844333</td>\n",
       "      <td>0.019494</td>\n",
       "      <td>0.831619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-26</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>476000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.017889</td>\n",
       "      <td>0.835958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-16</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1003000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.765667</td>\n",
       "      <td>0.079561</td>\n",
       "      <td>0.710951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-17</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1138000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>0.065038</td>\n",
       "      <td>0.754849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-20</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>6735000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>0.873333</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.039115</td>\n",
       "      <td>0.821554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-21</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>698000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.011494</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.770333</td>\n",
       "      <td>0.023452</td>\n",
       "      <td>0.844018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-23</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>573009</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.023256</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.771333</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.858382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open  High   Low  Close  Adj Close   Volume   H-L   O-C  % Change  \\\n",
       "Date                                                                            \n",
       "2021-05-20  0.87  0.94  0.86   0.91       0.91  2541225  0.08  0.04  0.010638   \n",
       "2021-05-21  0.90  0.91  0.86   0.91       0.91   770188  0.05  0.01 -0.042105   \n",
       "2021-05-24  0.87  0.91  0.87   0.91       0.91   417188  0.04  0.04  0.000000   \n",
       "2021-05-25  0.91  0.91  0.88   0.91       0.91   517000  0.03  0.00  0.000000   \n",
       "2021-05-26  0.91  0.92  0.87   0.90       0.90   476000  0.05 -0.01  0.000000   \n",
       "...          ...   ...   ...    ...        ...      ...   ...   ...       ...   \n",
       "2021-09-16  0.88  0.89  0.84   0.88       0.88  1003000  0.05  0.00  0.060976   \n",
       "2021-09-17  0.89  0.89  0.84   0.87       0.87  1138000  0.05 -0.02  0.011494   \n",
       "2021-09-20  0.87  0.90  0.81   0.86       0.86  6735000  0.09 -0.01 -0.011364   \n",
       "2021-09-21  0.86  0.89  0.81   0.84       0.84   698000  0.08 -0.02 -0.011494   \n",
       "2021-09-23  0.86  0.86  0.77   0.86       0.86   573009  0.09  0.00 -0.023256   \n",
       "\n",
       "             3day MA  10day MA  30day MA   Std_dev    y_pred  \n",
       "Date                                                          \n",
       "2021-05-20  0.940000     0.944  0.807667  0.008367  0.786041  \n",
       "2021-05-21  0.933333     0.940  0.819667  0.014832  0.821499  \n",
       "2021-05-24  0.923333     0.932  0.832333  0.017889  0.831960  \n",
       "2021-05-25  0.910000     0.929  0.844333  0.019494  0.831619  \n",
       "2021-05-26  0.910000     0.926  0.856000  0.017889  0.835958  \n",
       "...              ...       ...       ...       ...       ...  \n",
       "2021-09-16  0.826667     0.742  0.765667  0.079561  0.710951  \n",
       "2021-09-17  0.856667     0.758  0.767000  0.065038  0.754849  \n",
       "2021-09-20  0.873333     0.771  0.769333  0.039115  0.821554  \n",
       "2021-09-21  0.870000     0.785  0.770333  0.023452  0.844018  \n",
       "2021-09-23  0.856667     0.800  0.771333  0.015166  0.858382  \n",
       "\n",
       "[88 rows x 14 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y_pred'] = np.NaN\n",
    "data.iloc[(len(data) - len(y_pred)):,-1:] = y_pred_org\n",
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d42689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_pred_org,y_test_t_org)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_pred_org,y_test_t_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67457a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
