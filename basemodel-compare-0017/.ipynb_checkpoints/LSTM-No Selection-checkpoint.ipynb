{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9ae2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score, mean_squared_error,mean_absolute_percentage_error,r2_score\n",
    "import tensorflow as tf\n",
    "import talib\n",
    "from tensorflow import keras\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad5f74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data=yf.download('0017.hk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781ab9b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['6day MA'] = data['Close'].rolling(window = 6).mean()\n",
    "data['12day MA'] = data['Close'].rolling(window = 12).mean()\n",
    "data['RSI'] = talib.RSI(data['Close'].values, timeperiod = 7)\n",
    "data['%R5'] = talib.WILLR(data['High'].values, data['Low'].values, data['Close'].values, 5)\n",
    "data['%R10'] = talib.WILLR(data['High'].values, data['Low'].values, data['Close'].values, 10)\n",
    "data['MI6']=talib.MOM(data['Close'],timeperiod=6)\n",
    "data['MI12']=talib.MOM(data['Close'],timeperiod=12)\n",
    "macd, macdsignal, macdhist = talib.MACD(data['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "data['EMA12']=talib.EMA(data['Close'], timeperiod=12)\n",
    "data['EMA26']=talib.EMA(data['Close'],timeperiod=26)\n",
    "data['MACD']=macd\n",
    "data['TR']=talib.TRANGE(data['High'],data['Low'],data['Close'])\n",
    "data['OSC6']=talib.CMO(data['Close'], timeperiod=6)\n",
    "data['OSC12']=talib.CMO(data['Close'], timeperiod=12)\n",
    "data['Prediction']=data['Close'].shift(-1)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1036fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>6day MA</th>\n",
       "      <th>12day MA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>%R5</th>\n",
       "      <th>%R10</th>\n",
       "      <th>MI6</th>\n",
       "      <th>MI12</th>\n",
       "      <th>EMA12</th>\n",
       "      <th>EMA26</th>\n",
       "      <th>MACD</th>\n",
       "      <th>TR</th>\n",
       "      <th>OSC6</th>\n",
       "      <th>OSC12</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-03-25</th>\n",
       "      <td>51.959129</td>\n",
       "      <td>52.710182</td>\n",
       "      <td>51.344631</td>\n",
       "      <td>52.300514</td>\n",
       "      <td>29.860744</td>\n",
       "      <td>2536219.0</td>\n",
       "      <td>52.493969</td>\n",
       "      <td>52.328966</td>\n",
       "      <td>55.096356</td>\n",
       "      <td>-57.575865</td>\n",
       "      <td>-59.459566</td>\n",
       "      <td>-0.751053</td>\n",
       "      <td>-0.477943</td>\n",
       "      <td>52.058910</td>\n",
       "      <td>51.053067</td>\n",
       "      <td>1.005843</td>\n",
       "      <td>1.365551</td>\n",
       "      <td>6.821374</td>\n",
       "      <td>16.425878</td>\n",
       "      <td>53.392956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-26</th>\n",
       "      <td>52.095684</td>\n",
       "      <td>53.802620</td>\n",
       "      <td>52.027409</td>\n",
       "      <td>53.392956</td>\n",
       "      <td>30.484463</td>\n",
       "      <td>2510249.0</td>\n",
       "      <td>52.653283</td>\n",
       "      <td>52.425692</td>\n",
       "      <td>66.728957</td>\n",
       "      <td>-16.666641</td>\n",
       "      <td>-16.666641</td>\n",
       "      <td>0.955883</td>\n",
       "      <td>1.160717</td>\n",
       "      <td>52.264148</td>\n",
       "      <td>51.226392</td>\n",
       "      <td>1.037756</td>\n",
       "      <td>1.775211</td>\n",
       "      <td>35.279811</td>\n",
       "      <td>28.350674</td>\n",
       "      <td>53.666065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-29</th>\n",
       "      <td>53.461231</td>\n",
       "      <td>53.939175</td>\n",
       "      <td>53.461231</td>\n",
       "      <td>53.666065</td>\n",
       "      <td>30.640388</td>\n",
       "      <td>2631978.0</td>\n",
       "      <td>52.664662</td>\n",
       "      <td>52.590696</td>\n",
       "      <td>69.066249</td>\n",
       "      <td>-10.526300</td>\n",
       "      <td>-10.526300</td>\n",
       "      <td>0.068275</td>\n",
       "      <td>1.980045</td>\n",
       "      <td>52.479827</td>\n",
       "      <td>51.407108</td>\n",
       "      <td>1.072719</td>\n",
       "      <td>0.546219</td>\n",
       "      <td>40.712074</td>\n",
       "      <td>31.034403</td>\n",
       "      <td>53.188122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-30</th>\n",
       "      <td>53.256401</td>\n",
       "      <td>54.075729</td>\n",
       "      <td>52.915012</td>\n",
       "      <td>53.188122</td>\n",
       "      <td>30.367510</td>\n",
       "      <td>3142411.0</td>\n",
       "      <td>52.823976</td>\n",
       "      <td>52.698801</td>\n",
       "      <td>60.402809</td>\n",
       "      <td>-32.500024</td>\n",
       "      <td>-32.500024</td>\n",
       "      <td>0.955883</td>\n",
       "      <td>1.297268</td>\n",
       "      <td>52.588796</td>\n",
       "      <td>51.539035</td>\n",
       "      <td>1.049760</td>\n",
       "      <td>1.160717</td>\n",
       "      <td>19.626336</td>\n",
       "      <td>22.289705</td>\n",
       "      <td>51.890854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>52.641903</td>\n",
       "      <td>53.256401</td>\n",
       "      <td>51.686020</td>\n",
       "      <td>51.890854</td>\n",
       "      <td>29.626839</td>\n",
       "      <td>3351421.0</td>\n",
       "      <td>52.789838</td>\n",
       "      <td>52.693112</td>\n",
       "      <td>43.230895</td>\n",
       "      <td>-79.999888</td>\n",
       "      <td>-79.999888</td>\n",
       "      <td>-0.204830</td>\n",
       "      <td>-0.068275</td>\n",
       "      <td>52.481420</td>\n",
       "      <td>51.565096</td>\n",
       "      <td>0.916324</td>\n",
       "      <td>1.570381</td>\n",
       "      <td>-19.610331</td>\n",
       "      <td>2.111758</td>\n",
       "      <td>52.163963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume  \\\n",
       "Date                                                                           \n",
       "2010-03-25  51.959129  52.710182  51.344631  52.300514  29.860744  2536219.0   \n",
       "2010-03-26  52.095684  53.802620  52.027409  53.392956  30.484463  2510249.0   \n",
       "2010-03-29  53.461231  53.939175  53.461231  53.666065  30.640388  2631978.0   \n",
       "2010-03-30  53.256401  54.075729  52.915012  53.188122  30.367510  3142411.0   \n",
       "2010-03-31  52.641903  53.256401  51.686020  51.890854  29.626839  3351421.0   \n",
       "\n",
       "              6day MA   12day MA        RSI        %R5       %R10       MI6  \\\n",
       "Date                                                                          \n",
       "2010-03-25  52.493969  52.328966  55.096356 -57.575865 -59.459566 -0.751053   \n",
       "2010-03-26  52.653283  52.425692  66.728957 -16.666641 -16.666641  0.955883   \n",
       "2010-03-29  52.664662  52.590696  69.066249 -10.526300 -10.526300  0.068275   \n",
       "2010-03-30  52.823976  52.698801  60.402809 -32.500024 -32.500024  0.955883   \n",
       "2010-03-31  52.789838  52.693112  43.230895 -79.999888 -79.999888 -0.204830   \n",
       "\n",
       "                MI12      EMA12      EMA26      MACD        TR       OSC6  \\\n",
       "Date                                                                        \n",
       "2010-03-25 -0.477943  52.058910  51.053067  1.005843  1.365551   6.821374   \n",
       "2010-03-26  1.160717  52.264148  51.226392  1.037756  1.775211  35.279811   \n",
       "2010-03-29  1.980045  52.479827  51.407108  1.072719  0.546219  40.712074   \n",
       "2010-03-30  1.297268  52.588796  51.539035  1.049760  1.160717  19.626336   \n",
       "2010-03-31 -0.068275  52.481420  51.565096  0.916324  1.570381 -19.610331   \n",
       "\n",
       "                OSC12  Prediction  \n",
       "Date                               \n",
       "2010-03-25  16.425878   53.392956  \n",
       "2010-03-26  28.350674   53.666065  \n",
       "2010-03-29  31.034403   53.188122  \n",
       "2010-03-30  22.289705   51.890854  \n",
       "2010-03-31   2.111758   52.163963  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val=data[-100:]\n",
    "data=data[:-100]\n",
    "data_val.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b49c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range = (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb6680b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2221, 1, 19) (2221, 1) (247, 1, 19) (247, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/w0jn89bj2w5g85gj4ck7w0t00000gn/T/ipykernel_51106/1557544658.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X=sc.fit_transform(data.drop('Prediction',1))\n"
     ]
    }
   ],
   "source": [
    "X=sc.fit_transform(data.drop('Prediction',1))\n",
    "Y = data[\"Prediction\"].values.reshape(-1,1)\n",
    "# Y=np.array(data[\"Close\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1,shuffle=False)\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8c5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 18:55:16.156773: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-10 18:55:16.156888: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model_tech = keras.Sequential()\n",
    "model_tech.add(keras.layers.LSTM(\n",
    "  units=128,\n",
    "  input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "    return_sequences=True\n",
    "   \n",
    "))\n",
    "model_tech.add(keras.layers.LSTM(units=64))\n",
    "model_tech.add(keras.layers.Dense(units=64))\n",
    "model_tech.add(keras.layers.Dense(units=1))\n",
    "model_tech.compile(\n",
    "  loss='mean_squared_error',\n",
    "  optimizer=keras.optimizers.Adam(0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d66a4",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 18:55:17.165624: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-04-10 18:55:18.427896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-10 18:55:18.687448: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-10 18:55:19.180631: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-10 18:55:20.638103: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/200 [..............................] - ETA: 2s - loss: 1352.1461   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 18:55:21.153411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - ETA: 0s - loss: 466.8582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 18:55:23.939959: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-10 18:55:24.013982: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-04-10 18:55:24.035269: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 7s 16ms/step - loss: 466.8582 - val_loss: 2962.0774\n",
      "Epoch 2/300\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 443.7371 - val_loss: 606.3029\n",
      "Epoch 3/300\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 118.2880 - val_loss: 199.1167\n",
      "Epoch 4/300\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 51.7688 - val_loss: 81.0123\n",
      "Epoch 5/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 24.0903 - val_loss: 48.9853\n",
      "Epoch 6/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 14.6860 - val_loss: 38.2955\n",
      "Epoch 7/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 11.7748 - val_loss: 31.7378\n",
      "Epoch 8/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 10.8753 - val_loss: 26.1269\n",
      "Epoch 9/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 10.3845 - val_loss: 21.6349\n",
      "Epoch 10/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 9.9680 - val_loss: 18.4298\n",
      "Epoch 11/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 9.5760 - val_loss: 16.2835\n",
      "Epoch 12/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 9.1734 - val_loss: 14.8235\n",
      "Epoch 13/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 8.7304 - val_loss: 13.7766\n",
      "Epoch 14/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 8.2435 - val_loss: 13.0632\n",
      "Epoch 15/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 7.7333 - val_loss: 12.7437\n",
      "Epoch 16/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 7.2271 - val_loss: 12.9214\n",
      "Epoch 17/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 6.7455 - val_loss: 13.6698\n",
      "Epoch 18/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 6.2994 - val_loss: 14.9719\n",
      "Epoch 19/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 5.8922 - val_loss: 16.6802\n",
      "Epoch 20/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 5.5251 - val_loss: 18.5442\n",
      "Epoch 21/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 5.1992 - val_loss: 20.2855\n",
      "Epoch 22/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 4.9145 - val_loss: 21.6709\n",
      "Epoch 23/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 4.6685 - val_loss: 22.5627\n",
      "Epoch 24/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 4.4557 - val_loss: 22.9356\n",
      "Epoch 25/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 4.2687 - val_loss: 22.8640\n",
      "Epoch 26/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 4.0996 - val_loss: 22.4866\n",
      "Epoch 27/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 3.9411 - val_loss: 21.9645\n",
      "Epoch 28/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 3.7872 - val_loss: 21.4431\n",
      "Epoch 29/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 3.6341 - val_loss: 21.0324\n",
      "Epoch 30/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 3.4805 - val_loss: 20.8033\n",
      "Epoch 31/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 3.3278 - val_loss: 20.7956\n",
      "Epoch 32/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 3.1795 - val_loss: 21.0285\n",
      "Epoch 33/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 3.0398 - val_loss: 21.5086\n",
      "Epoch 34/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.9131 - val_loss: 22.2356\n",
      "Epoch 35/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.8024 - val_loss: 23.2021\n",
      "Epoch 36/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.7100 - val_loss: 24.3868\n",
      "Epoch 37/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.6370 - val_loss: 25.7466\n",
      "Epoch 38/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5840 - val_loss: 27.2112\n",
      "Epoch 39/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5509 - val_loss: 28.6849\n",
      "Epoch 40/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5373 - val_loss: 30.0585\n",
      "Epoch 41/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5420 - val_loss: 31.2267\n",
      "Epoch 42/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5633 - val_loss: 32.1155\n",
      "Epoch 43/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5976 - val_loss: 32.7090\n",
      "Epoch 44/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.6385 - val_loss: 33.0750\n",
      "Epoch 45/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.6765 - val_loss: 33.3672\n",
      "Epoch 46/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.7002 - val_loss: 33.8032\n",
      "Epoch 47/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.7000 - val_loss: 34.6180\n",
      "Epoch 48/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.6732 - val_loss: 36.0062\n",
      "Epoch 49/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.6266 - val_loss: 38.0687\n",
      "Epoch 50/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5727 - val_loss: 40.8145\n",
      "Epoch 51/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.5239 - val_loss: 44.2462\n",
      "Epoch 52/300\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 2.4886 - val_loss: 48.3031\n",
      "Epoch 53/300\n",
      "104/200 [==============>...............] - ETA: 0s - loss: 2.3304"
     ]
    }
   ],
   "source": [
    "history_tech=model_tech.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=10,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "y_pred = model_tech.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_tech.history['loss'], label='train')\n",
    "plt.plot(history_tech.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, len(y_train)), y_train, 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test, marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134553b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_test = sc.inverse_transform(y_test)\n",
    "# y_pred = sc.inverse_transform(y_pred)\n",
    "plt.plot(y_test, marker='.', label=\"true\")\n",
    "plt.plot(y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf212a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd9d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test,y_pred,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=data_val.drop('Prediction',1)\n",
    "y_val=data_val['Prediction']\n",
    "x_val=sc.transform(x_val).reshape(x_val.shape[0],1,x_val.shape[1])\n",
    "y_val_pred=model_tech.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529aefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_val.values, marker='.', label=\"true\")\n",
    "plt.plot(y_val_pred, 'r', marker='*',label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.title('LSTM-AllFeatures-0017')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9ce3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_val,y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(y_val,y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_val.values,y_val_pred,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab65e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
