{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b000030b-9f40-4918-9891-66343158b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score, mean_squared_error,mean_absolute_percentage_error,r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM,Dropout, BatchNormalization, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.optimizer_v2.rmsprop import RMSprop\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7248a5a2-9689-4a20-81e8-7eb58be1114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-06-16</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.830</td>\n",
       "      <td>2198875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-06-17</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.845</td>\n",
       "      <td>419007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-06-18</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.805</td>\n",
       "      <td>182990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-06-21</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.800</td>\n",
       "      <td>114085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-06-22</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close      Volume\n",
       "Date                                              \n",
       "2004-06-16  0.875  0.925  0.815  0.830  2198875000\n",
       "2004-06-17  0.830  0.875  0.825  0.845   419007500\n",
       "2004-06-18  0.840  0.850  0.790  0.805   182990000\n",
       "2004-06-21  0.820  0.825  0.790  0.800   114085000\n",
       "2004-06-22  0.800  0.800  0.800  0.800           0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the data for the SPY ETF by specifying the stock ticker, start date, and end date\n",
    "data = yf.download('0700.hk')\n",
    "data.drop(\"Adj Close\",axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e63dba-ac05-4d70-985f-992504db0bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Open     High      Low    Close      Volume  Prediction\n",
      "Date                                                                  \n",
      "2004-06-16    0.875    0.925    0.815    0.830  2198875000       0.845\n",
      "2004-06-17    0.830    0.875    0.825    0.845   419007500       0.805\n",
      "2004-06-18    0.840    0.850    0.790    0.805   182990000       0.800\n",
      "2004-06-21    0.820    0.825    0.790    0.800   114085000       0.800\n",
      "2004-06-22    0.800    0.800    0.800    0.800           0       0.885\n",
      "...             ...      ...      ...      ...         ...         ...\n",
      "2021-03-01  692.000  697.000  679.000  697.000    27079038     698.000\n",
      "2021-03-02  712.000  722.000  692.500  698.000    23080003     723.000\n",
      "2021-03-03  698.000  723.000  690.000  723.000    18285294     690.000\n",
      "2021-03-04  702.000  709.500  690.000  690.000    24497606     679.000\n",
      "2021-03-05  668.500  695.000  667.000  679.000    27137066     642.500\n",
      "\n",
      "[4133 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create one more column Prediction shifted 15 days up. \n",
    "data['Prediction'] = data[['Close']].shift(-1)\n",
    "data.dropna(inplace=True)\n",
    "df=data[:-200]\n",
    "#print data set\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72b1d2a-5e4a-41cf-b4c3-b48761d9c282",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.75000000e-01 9.25000012e-01 8.14999998e-01 8.29999983e-01\n",
      "  2.19887500e+09]\n",
      " [8.29999983e-01 8.75000000e-01 8.24999988e-01 8.45000029e-01\n",
      "  4.19007500e+08]\n",
      " [8.39999974e-01 8.50000024e-01 7.90000021e-01 8.05000007e-01\n",
      "  1.82990000e+08]\n",
      " ...\n",
      " [6.98000000e+02 7.23000000e+02 6.90000000e+02 7.23000000e+02\n",
      "  1.82852940e+07]\n",
      " [7.02000000e+02 7.09500000e+02 6.90000000e+02 6.90000000e+02\n",
      "  2.44976060e+07]\n",
      " [6.68500000e+02 6.95000000e+02 6.67000000e+02 6.79000000e+02\n",
      "  2.71370660e+07]]\n",
      "[  0.84500003   0.80500001   0.80000001 ... 690.         679.\n",
      " 642.5       ]\n"
     ]
    }
   ],
   "source": [
    "#Create a data set X and convert it into numpy array , which will be having actual values\n",
    "X = df.drop(['Prediction'],1).values.astype(float)\n",
    "print(X)\n",
    "# Create a dataset y which will be having Predicted values and convert into numpy array\n",
    "y = df['Prediction'].values.astype(float)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3843654c-e29a-41ce-8605-f59321a62ca7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "# X = sc_X.fit_transform(X)\n",
    "# y = sc_y.fit_transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7692cc47-e720-499b-a243-68dd3245ad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test with 90 & 10 % respectively\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceef7e72-9fca-4800-9ec6-5a15683cd043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM Model\n",
    "svr = SVR()\n",
    "# Train the model \n",
    "svr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c7c01ab-fdcb-409c-a002-025aa0d78a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm confidence:  -0.29238417630104463\n"
     ]
    }
   ],
   "source": [
    "# The best possible score is 1.0\n",
    "svm_confidence = svr.score(x_test, y_test)\n",
    "print(\"svm confidence: \", svm_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60f0c648-b5d7-4f53-9e08-27b199ed3608",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-bbd5c91e19f3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msvr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msc_y\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minverse_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msc_y\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minverse_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001B[0m in \u001B[0;36minverse_transform\u001B[0;34m(self, X, copy)\u001B[0m\n\u001B[1;32m   1011\u001B[0m             \u001B[0mTransformed\u001B[0m \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1012\u001B[0m         \"\"\"\n\u001B[0;32m-> 1013\u001B[0;31m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1014\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1015\u001B[0m         \u001B[0mcopy\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_is_fitted\u001B[0;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[1;32m   1207\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1208\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mfitted\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1209\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mNotFittedError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m\"name\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1210\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNotFittedError\u001B[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred=svr.predict(x_test).reshape(-1,1)\n",
    "y_pred = sc_y.inverse_transform(y_pred) \n",
    "y_test=sc_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, marker='.', label=\"true\")\n",
    "plt.plot(y_pred, 'r',marker='*', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003bcaf-706c-44d1-8911-12b7bf36c66a",
   "metadata": {},
   "source": [
    "# Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c524144-ffbf-40d1-a896-16a412209aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data = np.array(data.drop(['Prediction'],1))[-200:]\n",
    "forecast = np.array(data['Close'])[-200:].reshape(-1,1)\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e9a4c-90c3-4fcb-b2c4-64ce7edcd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector model predictions for the next ‘15’ days\n",
    "svm_prediction = svr.predict(forecast_data).reshape(-1,1)\n",
    "svm_prediction = sc_y.inverse_transform(svm_prediction) \n",
    "print(svm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21112d0-56b8-4d87-95de-9857abd1f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_percentage_error(forecast,svm_prediction)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913f476-fd53-4a42-aa59-daf679373e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}