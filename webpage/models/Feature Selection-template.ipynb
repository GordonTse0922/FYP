{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7194ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries first\n",
    "from sklearn.feature_selection import SelectKBest, RFE\n",
    "from sklearn.feature_selection import chi2, r_regression\n",
    "from sklearn.linear_model import LinearRegression,Ridge\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
    "import yfinance as yf\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import LSTM,Dropout, BatchNormalization, Dense, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Sequential\n",
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.regularizers import L1L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36706065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-28</th>\n",
       "      <td>76.400002</td>\n",
       "      <td>77.099998</td>\n",
       "      <td>76.050003</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>64.386993</td>\n",
       "      <td>22520013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>76.500000</td>\n",
       "      <td>76.900002</td>\n",
       "      <td>76.300003</td>\n",
       "      <td>76.550003</td>\n",
       "      <td>64.682732</td>\n",
       "      <td>16766252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>76.800003</td>\n",
       "      <td>77.449997</td>\n",
       "      <td>76.699997</td>\n",
       "      <td>77.449997</td>\n",
       "      <td>65.443199</td>\n",
       "      <td>24369212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>77.500000</td>\n",
       "      <td>77.949997</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>77.849998</td>\n",
       "      <td>65.781204</td>\n",
       "      <td>21197563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-06</th>\n",
       "      <td>77.599998</td>\n",
       "      <td>77.800003</td>\n",
       "      <td>77.199997</td>\n",
       "      <td>77.349998</td>\n",
       "      <td>65.358711</td>\n",
       "      <td>23715110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close    Volume\n",
       "Date                                                                       \n",
       "2017-09-28  76.400002  77.099998  76.050003  76.199997  64.386993  22520013\n",
       "2017-09-29  76.500000  76.900002  76.300003  76.550003  64.682732  16766252\n",
       "2017-10-03  76.800003  77.449997  76.699997  77.449997  65.443199  24369212\n",
       "2017-10-04  77.500000  77.949997  77.500000  77.849998  65.781204  21197563\n",
       "2017-10-06  77.599998  77.800003  77.199997  77.349998  65.358711  23715110"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=yf.download('0005.hk',\"2017-09-28\",\"2021-09-24\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28250d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-28</th>\n",
       "      <td>76.400002</td>\n",
       "      <td>77.099998</td>\n",
       "      <td>76.050003</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>64.386993</td>\n",
       "      <td>22520013</td>\n",
       "      <td>76.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>76.500000</td>\n",
       "      <td>76.900002</td>\n",
       "      <td>76.300003</td>\n",
       "      <td>76.550003</td>\n",
       "      <td>64.682732</td>\n",
       "      <td>16766252</td>\n",
       "      <td>77.449997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>76.800003</td>\n",
       "      <td>77.449997</td>\n",
       "      <td>76.699997</td>\n",
       "      <td>77.449997</td>\n",
       "      <td>65.443199</td>\n",
       "      <td>24369212</td>\n",
       "      <td>77.849998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>77.500000</td>\n",
       "      <td>77.949997</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>77.849998</td>\n",
       "      <td>65.781204</td>\n",
       "      <td>21197563</td>\n",
       "      <td>77.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-06</th>\n",
       "      <td>77.599998</td>\n",
       "      <td>77.800003</td>\n",
       "      <td>77.199997</td>\n",
       "      <td>77.349998</td>\n",
       "      <td>65.358711</td>\n",
       "      <td>23715110</td>\n",
       "      <td>77.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close    Volume  \\\n",
       "Date                                                                          \n",
       "2017-09-28  76.400002  77.099998  76.050003  76.199997  64.386993  22520013   \n",
       "2017-09-29  76.500000  76.900002  76.300003  76.550003  64.682732  16766252   \n",
       "2017-10-03  76.800003  77.449997  76.699997  77.449997  65.443199  24369212   \n",
       "2017-10-04  77.500000  77.949997  77.500000  77.849998  65.781204  21197563   \n",
       "2017-10-06  77.599998  77.800003  77.199997  77.349998  65.358711  23715110   \n",
       "\n",
       "            Prediction  \n",
       "Date                    \n",
       "2017-09-28   76.550003  \n",
       "2017-09-29   77.449997  \n",
       "2017-10-03   77.849998  \n",
       "2017-10-04   77.349998  \n",
       "2017-10-06   77.500000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Prediction']=data['Close'].shift(-1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f4f0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>H-L</th>\n",
       "      <th>O-C</th>\n",
       "      <th>% Change</th>\n",
       "      <th>3day MA</th>\n",
       "      <th>10day MA</th>\n",
       "      <th>30day MA</th>\n",
       "      <th>Std_dev</th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-28</th>\n",
       "      <td>76.400002</td>\n",
       "      <td>77.099998</td>\n",
       "      <td>76.050003</td>\n",
       "      <td>76.199997</td>\n",
       "      <td>64.386993</td>\n",
       "      <td>22520013</td>\n",
       "      <td>76.550003</td>\n",
       "      <td>1.049995</td>\n",
       "      <td>-0.200005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>76.500000</td>\n",
       "      <td>76.900002</td>\n",
       "      <td>76.300003</td>\n",
       "      <td>76.550003</td>\n",
       "      <td>64.682732</td>\n",
       "      <td>16766252</td>\n",
       "      <td>77.449997</td>\n",
       "      <td>0.599998</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>76.800003</td>\n",
       "      <td>77.449997</td>\n",
       "      <td>76.699997</td>\n",
       "      <td>77.449997</td>\n",
       "      <td>65.443199</td>\n",
       "      <td>24369212</td>\n",
       "      <td>77.849998</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.649994</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>77.500000</td>\n",
       "      <td>77.949997</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>77.849998</td>\n",
       "      <td>65.781204</td>\n",
       "      <td>21197563</td>\n",
       "      <td>77.349998</td>\n",
       "      <td>0.449997</td>\n",
       "      <td>0.349998</td>\n",
       "      <td>0.011757</td>\n",
       "      <td>76.733332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-06</th>\n",
       "      <td>77.599998</td>\n",
       "      <td>77.800003</td>\n",
       "      <td>77.199997</td>\n",
       "      <td>77.349998</td>\n",
       "      <td>65.358711</td>\n",
       "      <td>23715110</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>0.600006</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>77.283333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close    Volume  \\\n",
       "Date                                                                          \n",
       "2017-09-28  76.400002  77.099998  76.050003  76.199997  64.386993  22520013   \n",
       "2017-09-29  76.500000  76.900002  76.300003  76.550003  64.682732  16766252   \n",
       "2017-10-03  76.800003  77.449997  76.699997  77.449997  65.443199  24369212   \n",
       "2017-10-04  77.500000  77.949997  77.500000  77.849998  65.781204  21197563   \n",
       "2017-10-06  77.599998  77.800003  77.199997  77.349998  65.358711  23715110   \n",
       "\n",
       "            Prediction       H-L       O-C  % Change    3day MA  10day MA  \\\n",
       "Date                                                                        \n",
       "2017-09-28   76.550003  1.049995 -0.200005       NaN        NaN       NaN   \n",
       "2017-09-29   77.449997  0.599998  0.050003       NaN        NaN       NaN   \n",
       "2017-10-03   77.849998  0.750000  0.649994  0.004593        NaN       NaN   \n",
       "2017-10-04   77.349998  0.449997  0.349998  0.011757  76.733332       NaN   \n",
       "2017-10-06   77.500000  0.600006 -0.250000  0.005165  77.283333       NaN   \n",
       "\n",
       "            30day MA  Std_dev  RSI  \n",
       "Date                                \n",
       "2017-09-28       NaN      NaN  NaN  \n",
       "2017-09-29       NaN      NaN  NaN  \n",
       "2017-10-03       NaN      NaN  NaN  \n",
       "2017-10-04       NaN      NaN  NaN  \n",
       "2017-10-06       NaN      NaN  NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['H-L'] = data['High'] - data['Low']\n",
    "data['O-C'] = data['Close'] - data['Open']\n",
    "data[\"% Change\"]=data[\"Close\"].shift(1).pct_change()\n",
    "data['3day MA'] = data['Close'].shift(1).rolling(window = 3).mean()\n",
    "data['10day MA'] = data['Close'].shift(1).rolling(window = 10).mean()\n",
    "data['30day MA'] = data['Close'].shift(1).rolling(window = 30).mean()\n",
    "data['Std_dev']= data['Close'].shift(1).rolling(5).std()\n",
    "data['RSI'] = talib.RSI(data['Close'].values, timeperiod = 9)\n",
    "# data['Williams %R'] = talib.WILLR(data['High'].values, data['Low'].values, data['Close'].values, 7)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f02c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8f5222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.998  0.998  0.999  0.999  0.99  -0.295 -0.102  0.031  0.026  0.997\n",
      "  0.994  0.983 -0.08   0.129]\n",
      "[[75.9   76.25  75.6   75.65  75.717]\n",
      " [75.2   75.45  75.05  75.15  75.817]\n",
      " [75.15  75.3   75.05  75.1   75.583]\n",
      " [75.5   75.7   75.25  75.35  75.3  ]\n",
      " [75.35  75.65  75.1   75.25  75.2  ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/anaconda3/envs/FYP/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "X=data.drop('Prediction',1)\n",
    "Y=data['Prediction'].values.reshape(-1,1)\n",
    "test = SelectKBest(score_func=r_regression, k=5)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# Summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "\n",
    "features = fit.transform(X)\n",
    "# Summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be63fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 7\n",
      "Selected Features: [ True False  True  True False False  True  True  True False False False\n",
      "  True False]\n",
      "Feature Ranking: [1 7 1 1 3 8 1 1 1 2 4 5 1 6]\n",
      "Index(['Open', 'Low', 'Close', 'H-L', 'O-C', '% Change', 'Std_dev'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model)\n",
    "fit = rfe.fit(X, Y)\n",
    "temp = pd.Series(fit.support_,index = cols)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67c8084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/anaconda3/envs/FYP/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:156: LinAlgWarning: Ill-conditioned matrix (rcond=2.3464e-18): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d49fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 14\n",
      "Score with 14 features: 0.997778\n"
     ]
    }
   ],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,16)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,n_features_to_select=nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2558c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Open', 'Low', 'Close', 'H-L', 'O-C', '% Change'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "model = LinearRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, n_features_to_select=6)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,Y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,Y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de3754a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha using built-in LassoCV: 91024.672644\n",
      "Best score using built-in LassoCV: 0.087253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/anaconda3/envs/FYP/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:1572: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "reg = LassoCV()\n",
    "reg.fit(X, Y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,Y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740fa3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'H-L', 'O-C',\n",
       "       '% Change', '3day MA', '10day MA', '30day MA', 'Std_dev', 'RSI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ff0110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso picked 1 variables and eliminated the other 13 variables\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38b33d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature importance using Lasso Model')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAJcCAYAAABHWPagAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAys0lEQVR4nO3deZhkVX3/8fdHdkRFwqCDMIwL4kJghMYNxRV3BY0EiEYxJsQsP5dIjNuTYIxbjCbuilFAVEAUkLgTDIKKQg8MA6MogigIMuMCigoKfH9/3DtaNL2e6Zmunn6/nqeerrr33HO/p5buT517qytVhSRJ0kzdYa4LkCRJ85MhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4Q0B5K8Osl/z3UdG6Mkq5I8eq7rmO+SHJPk36bZ9ookj1/fNWn4GCI07/S/sH6T5IaBy46z0OcG+yVYVW+sqr/cUPubTJIjk3x0ruuYLVX1wKo6c7b7TXJYkq/Odr/rqq+rkrx9zPID++XHzFFpWgAMEZqvnl5V2wxcrp7LYpJsOpf7bzVf69btXAYcPObxfB7w3TmqRwuEIUIbjSR3SfKhJNck+VGSf0uySb/u3km+nOSnSX6S5GNJtu3XHQcsAf6nn9V4RZJHJ7lqTP+/n63o371/MslHk/wCOGyy/Y9T6+/f/SdZ2r9jfEGSK5P8PMmLkuyTZGWS65K8e2Dbw5J8Lcm7klyf5JIkjxtYv2OS05L8LMn3kvzVmP0O1v0i4NV0f4BuSHJh3+4FSb6d5JdJLk/y1wN9PDrJVUlenmR1P94XDKzfKsnbkvygr++rSbbq1z00ydf7MV042WGH/j65z8Dt30+vJ9k+yWf6fn6W5Owkd5jgcfpEko/0Y1mVZGSgz72SXNCvOynJiZnmFP6YWie7vyar9Z/658ovk3xn7eOYZIsk/5Xk6v7yX0m2mKSEHwMXAU/st98OeDhw2pg6n9HfB9clOTPJ/QfWPSjJ+X0tJwJbjtn2aUlW9Nt+PckeM72ftPExRGhjcixwM3Af4EHAE4C1hwwCvAnYEbg/sDNwJEBV/TnwQ/4wu/Hv09zfAcAngW2Bj02x/+l4CLArcDDwX8BrgMcDDwT+NMmjxrS9HNge+Bfg5P4PB8DxwFX9WJ8NvHEwZIyp+0PAG4ET+7Hv2bdZDTwNuDPwAuA/k+w10MfdgbsA9wBeCLwnyV37df8B7E33R2w74BXArUnuAXwW+Ld++RHAp5IsmsF9tNbL+zEuAu5GF4Qm+h/+zwBO6Md7GvBugCSbA6cAx/T1HA88s6EWmPz+GrfWJLsBfw/sU1V3ogsAV/TbvAZ4KLAM2BN4MPDaKWr4CN3sA8AhwKeBm9auTHLffowv7Wv5HF1w3ry/L04FjqO7L04C/mRg272ADwN/DfwR8AHgtCmCjRYAQ4Tmq1P7d0TXJTk1yd2AJwMvrapfVdVq4D/pfplSVd+rqtOr6qaqWgO8HXjUxN1PyzlVdWpV3Ur3x2PC/U/T66vqxqr6EvAr4PiqWl1VPwLOpgsma60G/quqfldVJwLfAZ6aZGfgEcA/9X2tAP4b+PPx6q6q34xXSFV9tqouq85XgC8Bjxxo8jvgX/v9fw64Aditf4f9F8BLqupHVXVLVX29qm4Cngt8rqo+1+/7dGAUeMoM7qPB/S8GdulrOLsm/iKgr/b7vIXuj+TaoPRQYFPgnX0fJwPnNtQy1f01Ua23AFsAD0iyWVVdUVWX9ds8h+7+Xd0/X1/HbR/D8ZwCPDrJXejCxEfGrD8Y+Gz/OvgdXdjbii7sPRTYjD88pz4JnDew7V8BH6iqb/aP6bF0AeWhM7qjtNExRGi+OrCqtu0vBwK70P0SvGZtuKB7t7QDQJIdkpzQTx3/Avgo3bv4dXHlwPVJ9z9N1w5c/804t7cZuP2jMX80f0A387Aj8LOq+uWYdfeYoO5xJXlykm/00+/X0f2hH7y/flpVNw/c/nVf3/Z00+CXcXu7AAcNhL/r6ALP4qnqGcdbge8BX+oPH7xykrY/HlPnlunOHdiR29+PU94345ni/hq31qr6Ht2swJHA6v75ufYE4R3pHre11j6+E+oD4WfpZiy2r6qvjWlymz778Hsl3XNjvPticP+7AC8f89jtPFVN2vgZIrSxuJLundH2A+HizlX1wH79m+imu/eoqjvTvSvOwPZj38X+Cth67Y105zaMnXYf+8dnsv3PtnskGax/CXB1f9kuyZ3GrPvRBHXf7nY/Rf0puneqd6uqbemmvsPUfgLcCNx7nHVXAscN3D/bVtUdq+rNE/T1awYeA7pDKF3BVb+sqpdX1b2ApwP/MOaQzXRcw+3vx51n2MeU99dktVbVx6vqEXR/pAt4S9/t1f2ytdY+vlP5CN3hk+PGWXebPvtx70z33BjvvlgycP1K4A1jHrutq+r4adSkjZghQhuFqrqGbgr5bUnunOQO6U6mXHvI4k50U+7X9cfm/3FMF9cC9xq4/V26d6xPTbIZ3bu7CY//TmP/s20H4MVJNktyEN15Hp+rqiuBrwNvSrJlf/LbC+nO2ZjItcDStSf7AZvTjXUNcHOSJ9Od3zGl/t3th4G3pzvBc5MkD+v/0H4UeHqSJ/bLt0x3kuZOE3S3Avizvu2TGDj81J/kd5/+j94v6A4N3DKdGgec02/z90k2TXIA3bkHk0lf9+8vTHF/TVRrkt2SPLa/b26km21aO4bjgdcmWZRke+Cf6e6/qXwF2B941zjrPkF3yOtx/XP65XTB9+v9fXEz3XNq0yTPGnNffBB4UZKHpHPH/rVxp7E70cJiiNDG5Hl0v9C/Bfyc7uTBtVPlrwP2Aq6nm/I9ecy2b6L7pX1dkiOq6nrgb+nOJ/gR3czEVUxusv3Ptm/SnYT5E+ANwLOr6qf9ukOBpXTvPE8B/qU//2AiJ/U/f5rk/P5QyIvp/uj8HPgzxpzlP4Uj6D4pcB7wM7p313foA84BdCcWrqF7d/uPTPx76CV079yvoztH4NSBdbsC/0sXDM8B3lsz/N8QVfVb4Fl0Ies6utmpzzBwMuI4Hk73x37sZbL7a6JatwDeTPcY/pguGL663+bf6M4XWUl3X57fL5tqTFVVZ1TVz8ZZ951+jO/q9/l0upOJfztwXxzWj+FgBl4jVTVKd17Eu/v13+vbaoHLxOciSRpGSQ4D/rKfBtcsSvJN4P1VdfRc1yLNB85ESFqwkjwqyd37KfznA3sAX5jruqT5wv9WJ2kh243uMMQ2dJ8oeXZ/foukafBwhiRJauLhDEmS1MQQIUmSmnhOBLD99tvX0qVL57oMSZI2iOXLl/+kqlq+t+Y2DBHA0qVLGR0dnesyJEnaIJL8YOpWU/NwhiRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktRkXoWIJLckWZHk4iT/k2TbfvkdkryzX35RkvOS3LNfd0WS7ee0cEmSNkLzKkQAv6mqZVW1O/Az4O/65QcDOwJ7VNUfA88ErpubEiVJWhg2nesC1sE5wB799cXANVV1K0BVXTVnVUmStEDMt5kIAJJsAjwOOK1f9Ang6f2hjrcledDcVSdJ0sIw30LEVklWAD8FtgNOh9/PPOwGvAq4FTgjyeMm6yjJ4UlGk4yuWbNm/VYtSdJGaL6FiN9U1TJgF2Bz/nBOBFV1U1V9vqr+EXgjcOBkHVXVUVU1UlUjixYtWo8lS5K0cZpvIQKAqroeeDFwRJLNkuyVZEfoPqlBd67ED+ayRkmSNnbz9sTKqrogyYXAIcAa4INJtuhXnwu8e86KkyRpAZhXIaKqthlz++kDN78wwTZL12dNkiQtVPPycIYkSZp7hghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTWY9RCR5TZJVSVYmWZHkIUlemmTrCdofluTdM+j/htmrVpIktdp0NjtL8jDgacBeVXVTku2BzYETgY8Cv57N/UmSpLkz2zMRi4GfVNVNAFX1E+DZwI7A/yX5P4AkL0jy3SRfAfadrMMk90xyTpLzkrx+zLp/7JevTPK6ftlbkvztQJsjk7x8VkcpSZJmPUR8Cdi5DwjvTfKoqnoncDXwmKp6TJLFwOvowsP+wAOm6PMdwPuqah/gx2sXJnkCsCvwYGAZsHeS/YATgIMHtv9T4KSxnSY5PMloktE1a9Y0DleSpIVrVkNEVd0A7A0cDqwBTkxy2JhmDwHOrKo1VfVbukMdk9kXOL6/ftzA8if0lwuA84H7AbtW1QXADkl2TLIn8POq+uE4tR5VVSNVNbJo0aIZjVOSJM3yOREAVXULcCZwZpKLgOeP12ym3Y6zLMCbquoD46z7JN1hlLvTzUxIkqRZNqszEUl2S7LrwKJlwA+AXwJ36pd9E3h0kj9Kshlw0BTdfg04pL/+nIHlXwT+Isk2/b7vkWSHft0J/TbPpgsUkiRpls32TMQ2wLuSbAvcDHyP7tDGocDnk1zTnxdxJHAOcA3doYhNJunzJcDHk7wE+NTahVX1pST3B85JAnAD8FxgdVWtSnIn4EdVdc0sj1GSJAGpmumRhY3PyMhIjY6OznUZkiRtEEmWV9XIuvbjf6yUJElNZv3EylZJXsPtz484qareMBf1SJKkyQ1NiOjDgoFBkqR5wsMZkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1mTJEJNkyyblJLkyyKsnrBtZtl+T0JJf2P+86QR9nJhlZ12L7fn6YJAPLTk1yw5h2L0tyY5K7rOs+JUnS+KYzE3ET8Niq2hNYBjwpyUP7da8EzqiqXYEz+tvr23XAvgBJtgUWj9PmUOA84JkboB5JkhakKUNEdda+09+sv1R/+wDg2P76scCBAEm2SnJCkpVJTgS2WttfkvclGR2c1UjyuCSnDLTZP8nJE5R0AnBIf/1ZwG3aJbk3sA3wWrowIUmS1oNpnRORZJMkK4DVwOlV9c1+1d2q6hqA/ucO/fK/AX5dVXsAbwD2HujuNVU1AuwBPCrJHsCXgfsnWdS3eQFw9ATlnAHsl2QTujBx4pj1hwLHA2cDuyXZAUmSNOumFSKq6paqWgbsBDw4ye5TbLIf8NF+25XAyoF1f5rkfOAC4IHAA6qqgOOA5/aHKB4GfH6Cvm8BvgocDGxVVVeMWX8IcEJV3Uo3S3HQeJ0kObyfERlds2bNFMORJEljbTqTxlV1XZIzgScBFwPXJllcVdckWUw3U/H75mO3T3JP4Ahgn6r6eZJjgC371UcD/wPcCJxUVTdPUsoJwCnAkWP63wPYFTi9P/dyc+By4D3jjOUo4CiAkZGR29UqSZImN51PZyzqZwdIshXweOCSfvVpwPP7688HPt1fPwt4Tr/N7nSHLgDuDPwKuD7J3YAnr91PVV0NXE13LsMxU5R1NvAmusMWgw4Fjqyqpf1lR+AeSXaZapySJGlmpjMTsRg4tj8H4Q7AJ6rqM/26NwOfSPJC4If84dDB+4Cjk6wEVgDnAlTVhUkuAFbRzRB8bcy+PgYsqqpvTVZQf/jjP8ZZdQgDwaR3Sr/8LVOMU5IkzUC6v8fDIcm7gQuq6kMbcr8jIyM1Ojq6IXcpSdKcSbK8/5DDOpnRORHrU5LldIc6Xj7XtUiSpKkNTYioqr2nbiVJkoaF350hSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU2mFSKSfDjJ6iQXj1m+XZLTk1za/7zrBNufmWRkXYvt+/lhkgwsOzXJDWPavSzJjUnusq77lCRJ45vuTMQxwJPGWf5K4Iyq2hU4o7+9vl0H7AuQZFtg8ThtDgXOA565AeqRJGlBmlaIqKqzgJ+Ns+oA4Nj++rHAgQBJtkpyQpKVSU4Etlq7QZL3JRlNsirJ6/plj0tyykCb/ZOcPEE5JwCH9NefBdymXZJ7A9sAr6ULE5IkaT1Y13Mi7lZV1wD0P3fol/8N8Ouq2gN4A7D3wDavqaoRYA/gUUn2AL4M3D/Jor7NC4CjJ9jnGcB+STahCxMnjll/KHA8cDawW5IdkCRJs259nVi5H/BRgKpaCawcWPenSc4HLgAeCDygqgo4Dnhuf4jiYcDnJ+j7FuCrwMHAVlV1xZj1hwAnVNWtdLMUB43XSZLD+xmR0TVr1sx8hJIkLXCbruP21yZZXFXXJFkMrB5YV2MbJ7kncASwT1X9PMkxwJb96qOB/wFuBE6qqpsn2e8JwCnAkWP63wPYFTi9P/dyc+By4D1jO6iqo4CjAEZGRm5XqyRJmty6zkScBjy/v/584NP99bOA5wAk2Z3u0AXAnYFfAdcnuRvw5LUdVdXVwNV05zIcM8V+zwbeRHfYYtChwJFVtbS/7AjcI8kuMx+aJEmazHQ/4nk8cA7dOQZXJXlhv+rNwP5JLgX2728DvA/YJslK4BXAuQBVdSHdYYxVwIeBr43Z1ceAK6vqW5PVU53/qKqfjFl1CN0MxaBT+MOJmJIkaZakOx1hOCR5N3BBVX1oQ+53ZGSkRkdHN+QuJUmaM0mW9x9yWCfrek7ErEmynO5Qx8vnuhZJkjS1oQkRVbX31K0kSdKw8LszJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKnJOoWIJFsmOTfJhUlWJXndBO2WJrl4XfY10E8lef3Asu2T/C7Ju8e0vTDJ8eu6T0mSNL51nYm4CXhsVe0JLAOelOSh61zV5C4HnjZw+yBg1WCDJPenG9t+Se64nuuRJGlBWqcQUZ0b+pub9ZcCSLJ3PxtwDvB3a7fpZxPOTnJ+f3l4v/y4JAcMtPtYkmeMs9vfAN9OMtLfPhj4xJg2fwYcB3wJGK8PSZK0jtb5nIgkmyRZAawGTq+qb/arjgZeXFUPG7PJamD/qtqLLgC8s1/+38AL+j7vAjwc+NwEuz0BOCTJTsAtwNVj1h8MnAgcDxzaODRJkjSJdQ4RVXVLVS0DdgIenGT3PgRsW1Vf6ZsdN7DJZsAHk1wEnAQ8oO/nK8B9kuxA94f/U1V18wS7/QKwf9/uxMEVSfYB1lTVD4AzgL2S3HVsB0kOTzKaZHTNmjVNY5ckaSGbtU9nVNV1wJnAk4DQH9YYx8uAa4E9gRFg84F1xwHPoZuROHqSff0WWA68HPjUmNWHAvdLcgVwGXBn4E/G6eOoqhqpqpFFixZNPjhJknQ76/rpjEVJtu2vbwU8HrikDxTXJ3lE3/Q5A5vdBbimqm4F/hzYZGDdMcBLAarqNidLjuNtwD9V1U8H6rkD3YmWe1TV0qpaChyAhzQkSZp1m67j9ouBY5NsQhdIPlFVn+nXvQD4cJJfA18c2Oa9wKeSHAT8H/CrtSuq6tok3wZOnWrHfcgYGzT2A35UVT8aWHYW8IAki6vqmhmNTpIkTShVEx112PCSbA1cBOxVVddvqP2OjIzU6OjohtqdJElzKsnyqhqZuuXkhuY/ViZ5PHAJ8K4NGSAkSVKbdT2cMWuq6n+BJXNdhyRJmp6hmYmQJEnziyFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktRk0hCRZFGSrya5OMmBA8s/nWTHSbZ7Xr/NqiTfSnJEv/zMJCOzVr0kSZozU81EHAocCzwM+EeAJE8Hzq+qq8fbIMmTgZcCT6iqBwJ7AdfPVsGSJGk4TBUifgdsBWwB3JpkU7qA8NZJtnkVcMTakFFVN1bVBwfWH5Tk3CTfTfJIgCRLk5yd5Pz+8vB++aP72YtPJrkkyceSpF/3lH7ZV5O8M8ln+uV3TPLhJOcluSDJATO/WyRJ0lSmChEfB54IfAE4Evhb4CNV9etJttkdWD7J+k2r6sF0YeRf+mWrgf2rai/gYOCdA+0f1Ld9AHAvYN8kWwIfAJ5cVY8AFg20fw3w5araB3gM8NYkd5xinJIkaYYmDRFVdX1VPbWqRoDzgacBn0rywX524GEN+zy5/7kcWNpf3wz4YJKLgJPoAsNa51bVVVV1K7Ci3+Z+wOVV9f2+zfED7Z8AvDLJCuBMYEtgydgikhyeZDTJ6Jo1axqGIUnSwrbpDNr+M/AGuvMkltPNUnya7t3+oFXA3sCXJ+jnpv7nLQP7fxlwLbAnXbC5cZz2g9tkkjoD/ElVfWeSNlTVUcBRACMjIzVZW0mSdHvT+ohnkl2BHavqK8DWwK1A0b3LH+tNwL8nuXu/7RZJXjzFLu4CXNPPNvw5sMkU7S8B7pVkaX/74IF1XwT+38C5Ew+aoi9JktRguv8n4g3Aa/vrxwOHAd8A/mNsw6r6HPAe4H+TrKKbtZhqxuO9wPOTfAO4L/CryRpX1W/ozs/4QpKv0s1irP0EyOvpDo+sTHJxf1uSJM2yVM3Pmfwk21TVDf2Mw3uAS6vqP1v6GhkZqdHR0dktUJKkIZVkeX++4zqZz/+x8q/6kydX0R0O+cDcliNJ0sIykxMrh0o/69A08yBJktbdfJ6JkCRJc8gQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqMi9CRJKdknw6yaVJLkvyjiSbT9D2yUlGk3w7ySVJ/mND1ytJ0kIw9CEiSYCTgVOralfgvsA2wBvGabs78G7guVV1f2B34PINWK4kSQvG0IcI4LHAjVV1NEBV3QK8DPiLJFuPafsK4A1VdUnf9uaqeu8GrVaSpAViPoSIBwLLBxdU1S+AHwL3GdN297FtJUnS+jEfQkSAmsHy6XWaHN6fOzG6Zs2a5uIkSVqo5kOIWAWMDC5IcmdgZ2C/JCv6y459272n02lVHVVVI1U1smjRolkvWpKkjd18CBFnAFsneR5Akk2AtwHHVNV7qmpZf7kaeCvw6iT37dveIck/zFnlkiRtxIY+RFRVAc8EDkpyKfBd4Ebg1eO0XQm8FDg+ybeBi4HFG65aSZIWjk3nuoDpqKorgadPs+1ngM+s34okSdLQz0RIkqThZIiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCbzJkQkuWHM7cOSvHuCtlck2X7DVCZJ0sI0b0KEJEkaLoYISZLUZNO5LmAGtkqyYuD2dsBpc1SLJEkL3nwKEb+pqmVrbyQ5DBhp7SzJ4cDhAEuWLFnX2iRJWnDm/eGMJJskWdFf/nW621XVUVU1UlUjixYtWp8lSpK0UZpPMxHjqqpbgGVzXYckSQvNvJ+JmMTKJFf1l7fPdTGSJG1s5s1MRFVtM+b2McAxE7Rduv4rkiRpYduYZyIkSdJ6ZIiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1KQ5RCR5ZpJKcr9J2pyZZKS//rkk247TZpskH0hyWZJVSc5K8pB+3Q2t9UmSpPVrXWYiDgW+ChwyncZV9ZSqum6cVf8N/AzYtaoeCBwGbL8OdUmSpA2gKUQk2QbYF3ghAyEiyVZJTkiyMsmJwFYD665Isv2Yfu4NPAR4bVXdClBVl1fVZ8e0S5K3Jrk4yUVJDu6XL+5nLlb06x7ZL39CknOSnJ/kpL5eSZI0i1pnIg4EvlBV3wV+lmSvfvnfAL+uqj2ANwB7T9HPA4EVVXXLFO2eBSwD9gQeD7w1yWLgz4AvVtXadSv6oPJa4PFVtRcwCvzDzIYnSZKmsmnjdocC/9VfP6G/fT6wH/BOgKpamWTluhbYewRwfB82rk3yFWAf4Dzgw0k2A06tqhVJHgU8APhaEoDNgXPGdpjkcOBwgCVLlsxSmZIkLRwzDhFJ/gh4LLB7kgI2ASrJK/omNYPuVgF7JrnD2sMZE+12vIVVdVaS/YCnAscleSvwc+D0qjp0sh1X1VHAUQAjIyMzqVmSJNF2OOPZwEeqapeqWlpVOwPfp5stOAt4DkCS3YE9Juuoqi6jO9zwuvTTBkl2TXLAmKZnAQcn2STJIroZj3OT7AKsrqoPAh8C9gK+Aeyb5D59f1snuW/DOCVJ0iRaQsShwCljln2K7vyE9wHb9IcxXgGcO6bdeO/4/xK4O/C9JBcBHwSuHtPmFGAlcCHwZeAVVfVj4NF050FcAPwJ8I6qWkP3CY/j+zq+AUz4MVRJktQmVet/Jj/JJsBq4O5V9bv1vsMZGhkZqdHR0bkuQ5KkDSLJ8qoaWdd+NtR/rFwF/PcwBghJktSm9dMZM1JVHk6QJGkj43dnSJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVKTOQ8RSe6e5IQklyX5VpLPJblvkovnujZJkjSxTedy50kCnAIcW1WH9MuWAXeby7okSdLU5nom4jHA76rq/WsXVNUK4Mq1t5NsmeToJBcluSDJY/rlD0xybpIVSVYm2bVf/tyB5R9IsskGHpMkSQvCXIeI3YHlU7T5O4Cq+mPgUODYJFsCLwLeUVXLgBHgqiT3Bw4G9u2X3wI8Z/2ULknSwjanhzOm6RHAuwCq6pIkPwDuC5wDvCbJTsDJVXVpkscBewPndUdK2ApYPV6nSQ4HDgdYsmTJeh+EJEkbm7meiVhF90d/MhlvYVV9HHgG8Bvgi0ke27c9tqqW9ZfdqurICbY/qqpGqmpk0aJF7SOQJGmBmusQ8WVgiyR/tXZBkn2AXQbanEV/SCLJfYElwHeS3Au4vKreCZwG7AGcATw7yQ59++2SDPYlSZJmyZyGiKoq4JnA/v1HPFcBRwJXDzR7L7BJkouAE4HDquomunMfLk6yArgf8JGq+hbwWuBLSVYCpwOLN9R4JElaSNL9HV/YRkZGanR0dK7LkCRpg0iyvKpG1rWfuT6cIUmS5ilDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmQx0iktww1zVIkqTxDXWIkCRJw2vehYgky5J8I8nKJKckuWuSHZIs79fvmaSSLOlvX5Zk67mtWpKkjc+8CxHAR4B/qqo9gIuAf6mq1cCWSe4MPBIYBR6ZZBdgdVX9eu7KlSRp47TpXBcwE0nuAmxbVV/pFx0LnNRf/zqwL7Af8EbgSUCAsyfo63DgcIAlS5asx6olSdo4zceZiImcTTcLsQvwaWBP4BHAWeM1rqqjqmqkqkYWLVq04aqUJGkjMa9CRFVdD/w8ySP7RX8OrJ2VOAt4LnBpVd0K/Ax4CvC1DV6oJEkLwLAfztg6yVUDt98OPB94f3+y5OXACwCq6ook8IeZh68CO1XVzzdgvZIkLRhDHSKqaqKZkodO0H7JwPU30p0bIUmS1oN5dThDkiQND0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCZDFyKS3DDm9mFJ3t1ff1GS502x/e/bS5Kk9WfTuS5gJqrq/XNdgyRJ6gzdTMRkkhyZ5Ij++j5JViY5J8lbk1w80HTHJF9IcmmSf5+jciVJ2qgN40zEVklWDNzeDjhtnHZHA4dX1deTvHnMumXAg4CbgO8keVdVXbk+ipUkaaEaxpmI31TVsrUX4J/HNkiyLXCnqvp6v+jjY5qcUVXXV9WNwLeAXcbp4/Ako0lG16xZM7sjkCRpARjGEDEdmWL9TQPXb2GcGZeqOqqqRqpqZNGiRbNanCRJC8G8DBFV9XPgl0ke2i86ZC7rkSRpIZqXIaL3QuCoJOfQzUxcP8f1SJK0oKSq5rqGJkm2qaob+uuvBBZX1Uta+hoZGanR0dFZrU+SpGGVZHlVjaxrP8P46YzpemqSV9GN4QfAYXNbjiRJC8u8DRFVdSJw4lzXIUnSQjWfz4mQJElzyBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWoyFCEiyU5JPp3k0iSXJXlHks3nui5JkjSxOQ8RSQKcDJxaVbsC9wW2Ad4wp4VJkqRJbTrXBQCPBW6sqqMBquqWJC8Dvp/k+8ATgS2AewIfr6rXASR5LvBiYHPgm8Df9tveALwDeBrwG+CAqrp2Qw9KkqSN3ZzPRAAPBJYPLqiqXwA/pAs5DwaeAywDDkoykuT+wMHAvlW1DLilbwNwR+AbVbUncBbwVxtgDJIkLTjDMBMRoCZZfnpV/RQgycnAI4Cbgb2B87qjIWwFrO63+y3wmf76cmD/cXeaHA4cDrBkyZLZGIckSQvKMISIVcCfDC5IcmdgZ7oZhrEBo+gCxrFV9apx+vtdVa3d5hYmGGNVHQUcBTAyMjJeiJEkSZMYhsMZZwBbJ3keQJJNgLcBxwC/BvZPsl2SrYADga/12zw7yQ79Ntsl2WUOapckacGa8xDRzxo8k+58h0uB7wI3Aq/um3wVOA5YAXyqqkar6lvAa4EvJVkJnA4s3tC1S5K0kA3D4Qyq6krg6WOX9+c7rK6qvx9nmxOBE8dZvs3A9U8Cn5zVYiVJEjAEMxGSJGl+GoqZiIlU1TF050ZIkqQh40yEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1MQQIUmSmhgiJElSE0OEJElqYoiQJElNDBGSJKmJIUKSJDUxREiSpCaGCEmS1GTTuS5gY7X0lZ+d6xIkSVqvnImQJElNDBGSJKmJIUKSJDUxREiSpCbrJUQkOTPJE8cse2mS907Q/ook26+PWiRJ0vqxvmYijgcOGbPskH65JEnaCKyvEPFJ4GlJtgBIshTYEdgpyUVJLk7ylrEbJVma5OKB20ckObK/fmaS/0xyVpJvJ9knyclJLk3ybwPbPDfJuUlWJPlAkk3W0xglSVrQ1kuIqKqfAucCT+oXHQJ8EXgL8FhgGbBPkgNn2PVvq2o/4P3Ap4G/A3YHDkvyR0nuDxwM7FtVy4BbgOes02AkSdK41ueJlYOHNA4BrgLOrKo1VXUz8DFgvxn2eVr/8yJgVVVdU1U3AZcDOwOPA/YGzkuyor99r/E6SnJ4ktEko2vWrJlhGZIkaX2GiFOBxyXZC9gKuHAa29w8pqYtx6y/qf9568D1tbc3BQIcW1XL+stuVXXkeDuqqqOqaqSqRhYtWjSN0iRJ0qD1FiKq6gbgTODDdLMS3wQelWT7/jyFQ4GvjNnsWmCH/tDEFsDTZrjbM4BnJ9kBIMl2SXZZh2FIkqQJrO/vzjgeOBk4pKquSfIq4P/oZgw+V1WfHmxcVb9L8q90geP7wCUz2VlVfSvJa4EvJbkD8Du68yZ+sO5DkSRJg1JVc13DnBsZGanR0dFZ7dMv4JIkDasfvOVpy6tqZF378T9WSpKkJoYISZLUxBAhSZKaGCIkSVITQ4QkSWqyvj/iuWBd8eanznUJkiSN6/bfXtXGmQhJktTEECFJkpoYIiRJUhNDhCRJamKIkCRJTQwRkiSpiSFCkiQ1MURIkqQmhghJktQkVTXXNcy5JGuAH8x1HVPYHvjJXBcxSzaWsWws4wDHMow2lnGAYxlGu1XVnda1E//tNVBVi+a6hqkkGa2qkbmuYzZsLGPZWMYBjmUYbSzjAMcyjJKMzkY/Hs6QJElNDBGSJKmJIWL+OGquC5hFG8tYNpZxgGMZRhvLOMCxDKNZGYcnVkqSpCbOREiSpCaGiCGS5K1JLkmyMskpSbadoN2TknwnyfeSvHJg+XZJTk9yaf/zrhus+NvWd1CSVUluTTLuWcxJdkuyYuDyiyQv7dcdmeRHA+ueskEHcNs6pxxL3+6KJBf19Y4OLB+Kx6SvZTqPy85J/i/Jt/u2LxlYNxSPywwek6F+nUy3lnn0WpnW/Trsr5VpPiZD/TqZ6Lk/sD5J3tmvX5lkr+lueztV5WVILsATgE37628B3jJOm02Ay4B7AZsDFwIP6Nf9O/DK/vorx9t+A43j/sBuwJnAyDTabwL8GNilv30kcMRcPx4zGQtwBbD9OMuH4jGZ7liAxcBe/fU7Ad8deH4NxeMyzXEM/eukpZYhf61MayzD/lqZTh3D/DqZ7Lk/0OYpwOeBAA8FvjndbcdenIkYIlX1paq6ub/5DWCncZo9GPheVV1eVb8FTgAO6NcdABzbXz8WOHA9ljuhqvp2VX1nBps8DrisqobuH341jGWsoXhMYHpjqaprqur8/vovgW8D99gQ9U3XNB+ToX+d9GZay9C+Vlj3+3VYHpcp6xjy18lkz/21DgA+Up1vANsmWTzNbW/DEDG8/oIuKY51D+DKgdtX8Ycn792q6hronuTADuu1wtlzCHD8mGV/30+zfXgup5tnoIAvJVme5PCB5fP1MSHJUuBBwDcHFs+Xx2W+vE5mWsswv1amO5Zhf63MqI4hfJ1M9tyfqs10tr0N/2PlBpbkf4G7j7PqNVX16b7Na4CbgY+N18U4yzb4R2ymM45p9rM58AzgVQOL3we8nm5crwfeRheq1otZGsu+VXV1kh2A05NcUlVnzV6V0zOLj8s2wKeAl1bVL/rFG+xxmYVxDMXrBCYfywz7GerXygy6mfPXyiw+JnP6OpmorHGWjX3uT9Rmxq8bQ8QGVlWPn2x9kucDTwMeV/1BqjGuAnYeuL0TcHV//doki6vqmn5qavVs1DyeqcYxA08Gzq+qawf6/v31JB8EPjNL+xrXbIylqq7uf65OcgrdtOBZbMDHpN//Oo8lyWZ0vxg/VlUnD/S9wR6XWRjHULxOYPKxJJlJLUP9WpnuWIbhtTIb4xiG18kEJnvuT9Vm82lsexsezhgiSZ4E/BPwjKr69QTNzgN2TXLP/p3JIcBp/brTgOf3158PTPud5xw6lDHTs/0Ld61nAhdv0IpmKMkdk9xp7XW6E2TX1jyvHpMkAT4EfLuq3j5m3Xx6XObL62QmtQz7a2XKscyT18p0xjHMr5PJnvtrnQY8r/+UxkOB6/tDN9PZ9rY29JmjXiY9q/Z7dMejVvSX9/fLdwQ+N9DuKXRnA19GN727dvkfAWcAl/Y/t5ujcTyTLuneBFwLfHGCcWwN/BS4y5jtjwMuAlb2T+DFc/iYTDkWujOZL+wvq4bxMZnBWB5BN325cuB5+JRhelxm8Pwa6tfJZLXM09fKlGOZD6+VaY5jqF8n4z33gRcBL+qvB3hPv/4iBj7lNNHrZqKL/7FSkiQ18XCGJElqYoiQJElNDBGSJKmJIUKSJDUxREiSNCT6/3K5Osk6fzQ0yWNy2y9vuzHJgbNQ5h/24aczJEkaDkn2A26g+26L3Wex3+3o/o3ATjXx/yGaMWciJEkaEtX9C/CfDS5Lcu8kX+i/b+TsJPdr6PrZwOdnM0CAIUKSpGF3FPD/qmpv4AjgvQ19jPflbevM786QJGlI9V/y9XDgpO6/bQOwRb/uWcC/jrPZj6rqiQN9LAb+GPjibNdniJAkaXjdAbiuqpaNXVHdF3+dfLstbu9PgVOq6nezXJuHMyRJGlbVfcX495McBN2XfyXZc4bd3O7L22aLIUKSpCGR5HjgHGC3JFcleSHwHOCFSdZ+cdkBM+hvKd3Xe39lPZTrRzwlSVIbZyIkSVITQ4QkSWpiiJAkSU0MEZIkqYkhQpIkNTFESJKkJoYISZLUxBAhSZKa/H8mi32ZCPGyZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e52a9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlated columns: {'Low', '10day MA', 'Close', 'Adj Close', '30day MA', 'High', '3day MA'}\n"
     ]
    }
   ],
   "source": [
    "def correlation(dataset,threshold):\n",
    "    col_corr=set() # set will contains unique values.\n",
    "    corr_matrix=dataset.corr() #finding the correlation between columns.\n",
    "    for i in range(len(corr_matrix.columns)): #number of columns\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j])>threshold: #checking the correlation between columns.\n",
    "                colName=corr_matrix.columns[i] #getting the column name\n",
    "                col_corr.add(colName) #adding the correlated column name heigher than threshold value.\n",
    "    return col_corr #returning set of column names\n",
    "col=correlation(X,0.8)\n",
    "print('Correlated columns:',col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "153a5455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    1.6s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    1.8s finished\n",
      "\n",
      "[2021-12-26 05:09:39] Features: 1/10 -- score: 0.9959404693371496[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  13 | elapsed:    1.2s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    1.4s finished\n",
      "\n",
      "[2021-12-26 05:09:40] Features: 2/10 -- score: 0.9964817454826285[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.9s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.2s finished\n",
      "\n",
      "[2021-12-26 05:09:41] Features: 3/10 -- score: 0.996734186501613[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    1.0s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    1.2s finished\n",
      "\n",
      "[2021-12-26 05:09:43] Features: 4/10 -- score: 0.9967968303120038[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    1.1s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.2s finished\n",
      "\n",
      "[2021-12-26 05:09:44] Features: 5/10 -- score: 0.996822499559487[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    1.0s remaining:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:    1.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.2s finished\n",
      "\n",
      "[2021-12-26 05:09:45] Features: 6/10 -- score: 0.9968590843968379[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    1.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.3s finished\n",
      "\n",
      "[2021-12-26 05:09:46] Features: 7/10 -- score: 0.996891912553196[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    1.2s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.3s finished\n",
      "\n",
      "[2021-12-26 05:09:48] Features: 8/10 -- score: 0.9968472457363242[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    1.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.4s finished\n",
      "\n",
      "[2021-12-26 05:09:49] Features: 9/10 -- score: 0.996849564501772[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    1.3s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "\n",
      "[2021-12-26 05:09:50] Features: 10/10 -- score: 0.9968415594017985"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(estimator=RandomForestRegressor(), k_features=10,\n",
       "                          n_jobs=-1, scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "#I am going to use RandomForestRegressor algoritham as an estimator. Your can select other regression alogritham as well.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#k_features=10 (It will get top 10 features best suited for prediction)\n",
    "#forward=True (Forward feature selection model)\n",
    "#verbose=2 (It will show details output as shown below.)\n",
    "#cv=5 (Kfold cross valiation: it will split the training set in 5 set and 4 will be using for training the model and 1 will using as validation)\n",
    "#n_jobs=-1 (Number of cores it will use for execution.-1 means it will use all the cores of CPU for execution.)\n",
    "#scoring='r2'(R-squared is a statistical measure of how close the data are to the fitted regression line)\n",
    "forward_model=sfs(RandomForestRegressor(),k_features=10,forward=True,verbose=2,cv=5,n_jobs=-1,scoring='r2')\n",
    "forward_model.fit(X_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863e501b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 3, 6, 7, 8, 10, 11, 12, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the selected feature index.\n",
    "forward_model.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb7b9cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Open',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'H-L',\n",
       " 'O-C',\n",
       " '% Change',\n",
       " '10day MA',\n",
       " '30day MA',\n",
       " 'Std_dev',\n",
       " 'RSI')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the column name for the selected feature.\n",
    "forward_model.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5f4f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  14 | elapsed:    1.9s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    2.1s finished\n",
      "\n",
      "[2021-12-26 05:09:54] Features: 13/10 -- score: 0.9967517808285635[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  13 | elapsed:    1.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    1.9s finished\n",
      "\n",
      "[2021-12-26 05:09:56] Features: 12/10 -- score: 0.9967946273932263[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    1.6s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.7s finished\n",
      "\n",
      "[2021-12-26 05:09:58] Features: 11/10 -- score: 0.9967749253251279[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    1.2s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    1.3s finished\n",
      "\n",
      "[2021-12-26 05:09:59] Features: 10/10 -- score: 0.9967992109233398"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(estimator=RandomForestRegressor(), forward=False,\n",
       "                          k_features=10, n_jobs=-1, scoring='r2', verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#k_features=10 (It will get top 10 features best suited for prediction)\n",
    "#forward=False (Backward feature selection model)\n",
    "#verbose=2 (It will show details output as shown below.)\n",
    "#cv=5 (Kfold cross valiation: it will split the training set in 5 set and 4 will be using for training the model and 1 will using as validation)\n",
    "#n_jobs=-1 (Number of cores it will use for execution.-1 means it will use all the cores of CPU for execution.)\n",
    "#scoring='r2'(R-squared is a statistical measure of how close the data are to the fitted regression line)\n",
    "backwardModel=sfs(RandomForestRegressor(),k_features=10,forward=False,verbose=2,cv=5,n_jobs=-1,scoring='r2')\n",
    "#We will convert our training data into numpy array. If we will not convert it, model is not able to read some of the column names. \n",
    "backwardModel.fit(np.array(X_train),y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dfd2fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 3, 4, 6, 7, 8, 10, 12, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the selected feature index.\n",
    "backwardModel.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de0b39de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Close', 'Adj Close', 'H-L', 'O-C', '% Change',\n",
       "       '10day MA', 'Std_dev', 'RSI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the column name for the selected feature.\n",
    "X_train.columns[list(backwardModel.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe709ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 637/637"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExhaustiveFeatureSelector(estimator=RandomForestRegressor(), max_features=5,\n",
       "                          n_jobs=-1, scoring='r2')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as efs\n",
    "#min_features=1 (minimum number of feature)\n",
    "#max_features=5 (maximum number of feature)\n",
    "#n_jobs=-1 (Number of cores it will use for execution.-1 means it will use all the cores of CPU for execution.)\n",
    "#scoring='r2'(R-squared is a statistical measure of how close the data are to the fitted regression line)\n",
    "emodel=efs(RandomForestRegressor(),min_features=1,max_features=5,scoring='r2',n_jobs=-1)\n",
    "#Lets take only 10 features which we got from backward feature selection.\n",
    "miniData=X_train[X_train.columns[list(backwardModel.k_feature_idx_)]]\n",
    "\n",
    "emodel.fit(np.array(miniData),y_train.ravel())\n",
    "#If you see below the model creates 637 feature combinations from 10 features.Thats why its computationally very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d816d3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 7, 8, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the selected feature index.\n",
    "emodel.best_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41f3080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Close', '10day MA', 'Std_dev', 'RSI'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the column name for the selected feature.\n",
    "miniData.columns[list(emodel.best_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a827dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 967/967"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExhaustiveFeatureSelector(estimator=RandomForestRegressor(), max_features=7,\n",
       "                          n_jobs=-1, scoring='r2')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emodel=efs(RandomForestRegressor(),min_features=1,max_features=7,scoring='r2',n_jobs=-1)\n",
    "#Lets take only 10 features which we got from backward feature selection.\n",
    "miniData_forward=X_train[X_train.columns[list(forward_model.k_feature_idx_)]]\n",
    "\n",
    "emodel.fit(np.array(miniData_forward),y_train.ravel())\n",
    "#If you see below the model creates 637 feature comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13ffe4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 4, 7, 8, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the selected feature index.\n",
    "emodel.best_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91946d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Close', 'O-C', '30day MA', 'Std_dev', 'RSI'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the column name for the selected feature.\n",
    "miniData_forward.columns[list(emodel.best_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37549448",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected=data[miniData_forward.columns[list(emodel.best_idx_)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30f49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-b909f1970ec0>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected['Prediction']=data['Prediction']\n"
     ]
    }
   ],
   "source": [
    "data_selected['Prediction']=data['Prediction']\n",
    "data_selected=data_selected[:-5]\n",
    "data_unseen=data_selected[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4537209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/anaconda3/envs/FYP/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:357: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.288e-01]\n",
      " [ 6.271e-01]\n",
      " [ 6.357e-01]\n",
      " [ 6.323e-01]\n",
      " [ 6.271e-01]\n",
      " [ 6.444e-01]\n",
      " [ 6.912e-01]\n",
      " [ 6.635e-01]\n",
      " [ 6.687e-01]\n",
      " [ 6.860e-01]\n",
      " [ 6.912e-01]\n",
      " [ 7.277e-01]\n",
      " [ 7.277e-01]\n",
      " [ 7.242e-01]\n",
      " [ 7.173e-01]\n",
      " [ 7.051e-01]\n",
      " [ 6.618e-01]\n",
      " [ 6.670e-01]\n",
      " [ 6.860e-01]\n",
      " [ 7.381e-01]\n",
      " [ 7.398e-01]\n",
      " [ 7.953e-01]\n",
      " [ 7.814e-01]\n",
      " [ 7.467e-01]\n",
      " [ 7.572e-01]\n",
      " [ 7.745e-01]\n",
      " [ 7.728e-01]\n",
      " [ 7.814e-01]\n",
      " [ 7.971e-01]\n",
      " [ 7.901e-01]\n",
      " [ 7.971e-01]\n",
      " [ 7.953e-01]\n",
      " [ 8.422e-01]\n",
      " [ 8.300e-01]\n",
      " [ 8.144e-01]\n",
      " [ 8.248e-01]\n",
      " [ 8.144e-01]\n",
      " [ 8.300e-01]\n",
      " [ 8.699e-01]\n",
      " [ 9.376e-01]\n",
      " [ 9.254e-01]\n",
      " [ 9.393e-01]\n",
      " [ 9.636e-01]\n",
      " [ 9.722e-01]\n",
      " [ 9.861e-01]\n",
      " [ 9.844e-01]\n",
      " [ 9.705e-01]\n",
      " [ 9.948e-01]\n",
      " [ 1.000e+00]\n",
      " [ 9.879e-01]\n",
      " [ 9.948e-01]\n",
      " [ 9.722e-01]\n",
      " [ 9.393e-01]\n",
      " [ 9.428e-01]\n",
      " [ 9.376e-01]\n",
      " [ 9.254e-01]\n",
      " [ 8.959e-01]\n",
      " [ 8.005e-01]\n",
      " [ 7.971e-01]\n",
      " [ 8.144e-01]\n",
      " [ 7.901e-01]\n",
      " [ 7.762e-01]\n",
      " [ 7.901e-01]\n",
      " [ 8.630e-01]\n",
      " [ 9.202e-01]\n",
      " [ 8.300e-01]\n",
      " [ 8.526e-01]\n",
      " [ 7.814e-01]\n",
      " [ 7.849e-01]\n",
      " [ 7.814e-01]\n",
      " [ 7.485e-01]\n",
      " [ 7.277e-01]\n",
      " [ 7.242e-01]\n",
      " [ 6.999e-01]\n",
      " [ 6.565e-01]\n",
      " [ 6.791e-01]\n",
      " [ 6.565e-01]\n",
      " [ 6.687e-01]\n",
      " [ 6.791e-01]\n",
      " [ 7.069e-01]\n",
      " [ 6.964e-01]\n",
      " [ 6.756e-01]\n",
      " [ 6.722e-01]\n",
      " [ 6.912e-01]\n",
      " [ 6.982e-01]\n",
      " [ 6.912e-01]\n",
      " [ 6.878e-01]\n",
      " [ 6.687e-01]\n",
      " [ 6.114e-01]\n",
      " [ 6.236e-01]\n",
      " [ 6.271e-01]\n",
      " [ 5.889e-01]\n",
      " [ 5.889e-01]\n",
      " [ 5.733e-01]\n",
      " [ 5.334e-01]\n",
      " [ 5.559e-01]\n",
      " [ 5.958e-01]\n",
      " [ 6.132e-01]\n",
      " [ 6.323e-01]\n",
      " [ 6.375e-01]\n",
      " [ 6.687e-01]\n",
      " [ 6.565e-01]\n",
      " [ 6.392e-01]\n",
      " [ 6.461e-01]\n",
      " [ 6.687e-01]\n",
      " [ 6.860e-01]\n",
      " [ 6.930e-01]\n",
      " [ 7.155e-01]\n",
      " [ 7.103e-01]\n",
      " [ 6.947e-01]\n",
      " [ 7.069e-01]\n",
      " [ 7.520e-01]\n",
      " [ 7.433e-01]\n",
      " [ 7.173e-01]\n",
      " [ 6.219e-01]\n",
      " [ 6.271e-01]\n",
      " [ 6.548e-01]\n",
      " [ 6.618e-01]\n",
      " [ 6.964e-01]\n",
      " [ 7.121e-01]\n",
      " [ 7.415e-01]\n",
      " [ 7.259e-01]\n",
      " [ 7.294e-01]\n",
      " [ 6.930e-01]\n",
      " [ 7.016e-01]\n",
      " [ 7.207e-01]\n",
      " [ 7.103e-01]\n",
      " [ 7.121e-01]\n",
      " [ 6.947e-01]\n",
      " [ 6.878e-01]\n",
      " [ 6.548e-01]\n",
      " [ 6.219e-01]\n",
      " [ 6.565e-01]\n",
      " [ 6.565e-01]\n",
      " [ 6.791e-01]\n",
      " [ 6.756e-01]\n",
      " [ 6.756e-01]\n",
      " [ 7.016e-01]\n",
      " [ 6.774e-01]\n",
      " [ 6.912e-01]\n",
      " [ 6.843e-01]\n",
      " [ 6.808e-01]\n",
      " [ 6.722e-01]\n",
      " [ 6.704e-01]\n",
      " [ 6.097e-01]\n",
      " [ 6.305e-01]\n",
      " [ 6.028e-01]\n",
      " [ 6.028e-01]\n",
      " [ 5.802e-01]\n",
      " [ 5.716e-01]\n",
      " [ 5.369e-01]\n",
      " [ 5.507e-01]\n",
      " [ 5.750e-01]\n",
      " [ 5.317e-01]\n",
      " [ 5.265e-01]\n",
      " [ 5.369e-01]\n",
      " [ 5.403e-01]\n",
      " [ 5.663e-01]\n",
      " [ 5.854e-01]\n",
      " [ 5.525e-01]\n",
      " [ 5.577e-01]\n",
      " [ 5.646e-01]\n",
      " [ 5.646e-01]\n",
      " [ 5.594e-01]\n",
      " [ 5.403e-01]\n",
      " [ 5.611e-01]\n",
      " [ 5.611e-01]\n",
      " [ 5.681e-01]\n",
      " [ 6.114e-01]\n",
      " [ 6.253e-01]\n",
      " [ 6.149e-01]\n",
      " [ 6.184e-01]\n",
      " [ 6.132e-01]\n",
      " [ 6.097e-01]\n",
      " [ 5.976e-01]\n",
      " [ 5.473e-01]\n",
      " [ 5.299e-01]\n",
      " [ 5.421e-01]\n",
      " [ 5.490e-01]\n",
      " [ 5.507e-01]\n",
      " [ 5.663e-01]\n",
      " [ 5.403e-01]\n",
      " [ 5.230e-01]\n",
      " [ 5.317e-01]\n",
      " [ 5.039e-01]\n",
      " [ 4.553e-01]\n",
      " [ 4.536e-01]\n",
      " [ 4.692e-01]\n",
      " [ 4.605e-01]\n",
      " [ 4.519e-01]\n",
      " [ 4.380e-01]\n",
      " [ 4.293e-01]\n",
      " [ 4.536e-01]\n",
      " [ 4.571e-01]\n",
      " [ 4.553e-01]\n",
      " [ 4.328e-01]\n",
      " [ 4.102e-01]\n",
      " [ 3.929e-01]\n",
      " [ 4.085e-01]\n",
      " [ 3.738e-01]\n",
      " [ 3.634e-01]\n",
      " [ 3.530e-01]\n",
      " [ 3.235e-01]\n",
      " [ 3.218e-01]\n",
      " [ 3.339e-01]\n",
      " [ 3.651e-01]\n",
      " [ 3.773e-01]\n",
      " [ 3.651e-01]\n",
      " [ 3.721e-01]\n",
      " [ 3.790e-01]\n",
      " [ 4.033e-01]\n",
      " [ 4.415e-01]\n",
      " [ 4.137e-01]\n",
      " [ 4.380e-01]\n",
      " [ 4.293e-01]\n",
      " [ 4.224e-01]\n",
      " [ 3.721e-01]\n",
      " [ 3.790e-01]\n",
      " [ 3.825e-01]\n",
      " [ 3.964e-01]\n",
      " [ 3.825e-01]\n",
      " [ 3.686e-01]\n",
      " [ 3.842e-01]\n",
      " [ 3.131e-01]\n",
      " [ 3.131e-01]\n",
      " [ 2.680e-01]\n",
      " [ 2.697e-01]\n",
      " [ 2.611e-01]\n",
      " [ 2.368e-01]\n",
      " [ 2.541e-01]\n",
      " [ 1.865e-01]\n",
      " [ 1.587e-01]\n",
      " [ 1.396e-01]\n",
      " [ 1.206e-01]\n",
      " [ 2.264e-01]\n",
      " [ 2.125e-01]\n",
      " [ 2.559e-01]\n",
      " [ 2.784e-01]\n",
      " [ 3.252e-01]\n",
      " [ 2.940e-01]\n",
      " [ 3.131e-01]\n",
      " [ 3.096e-01]\n",
      " [ 3.079e-01]\n",
      " [ 2.645e-01]\n",
      " [ 2.784e-01]\n",
      " [ 2.680e-01]\n",
      " [ 2.853e-01]\n",
      " [ 3.114e-01]\n",
      " [ 3.183e-01]\n",
      " [ 3.131e-01]\n",
      " [ 2.801e-01]\n",
      " [ 2.871e-01]\n",
      " [ 3.096e-01]\n",
      " [ 3.079e-01]\n",
      " [ 3.408e-01]\n",
      " [ 3.495e-01]\n",
      " [ 3.686e-01]\n",
      " [ 3.339e-01]\n",
      " [ 3.426e-01]\n",
      " [ 3.877e-01]\n",
      " [ 3.842e-01]\n",
      " [ 3.218e-01]\n",
      " [ 2.749e-01]\n",
      " [ 2.316e-01]\n",
      " [ 2.333e-01]\n",
      " [ 2.194e-01]\n",
      " [ 2.420e-01]\n",
      " [ 2.836e-01]\n",
      " [ 2.454e-01]\n",
      " [ 2.507e-01]\n",
      " [ 2.350e-01]\n",
      " [ 2.454e-01]\n",
      " [ 2.264e-01]\n",
      " [ 2.611e-01]\n",
      " [ 2.472e-01]\n",
      " [ 2.420e-01]\n",
      " [ 2.333e-01]\n",
      " [ 2.697e-01]\n",
      " [ 2.177e-01]\n",
      " [ 2.160e-01]\n",
      " [ 2.541e-01]\n",
      " [ 2.732e-01]\n",
      " [ 2.680e-01]\n",
      " [ 2.940e-01]\n",
      " [ 2.697e-01]\n",
      " [ 2.905e-01]\n",
      " [ 2.611e-01]\n",
      " [ 2.801e-01]\n",
      " [ 2.819e-01]\n",
      " [ 2.819e-01]\n",
      " [ 2.888e-01]\n",
      " [ 2.888e-01]\n",
      " [ 2.801e-01]\n",
      " [ 2.749e-01]\n",
      " [ 2.871e-01]\n",
      " [ 3.079e-01]\n",
      " [ 3.062e-01]\n",
      " [ 3.096e-01]\n",
      " [ 3.218e-01]\n",
      " [ 3.356e-01]\n",
      " [ 3.148e-01]\n",
      " [ 3.096e-01]\n",
      " [ 3.062e-01]\n",
      " [ 3.114e-01]\n",
      " [ 3.200e-01]\n",
      " [ 3.495e-01]\n",
      " [ 3.530e-01]\n",
      " [ 3.235e-01]\n",
      " [ 3.703e-01]\n",
      " [ 3.166e-01]\n",
      " [ 3.131e-01]\n",
      " [ 2.732e-01]\n",
      " [ 2.559e-01]\n",
      " [ 2.489e-01]\n",
      " [ 2.402e-01]\n",
      " [ 2.454e-01]\n",
      " [ 2.472e-01]\n",
      " [ 2.489e-01]\n",
      " [ 2.489e-01]\n",
      " [ 2.541e-01]\n",
      " [ 2.663e-01]\n",
      " [ 2.715e-01]\n",
      " [ 2.507e-01]\n",
      " [ 2.576e-01]\n",
      " [ 2.715e-01]\n",
      " [ 2.559e-01]\n",
      " [ 2.645e-01]\n",
      " [ 2.715e-01]\n",
      " [ 2.801e-01]\n",
      " [ 2.888e-01]\n",
      " [ 2.784e-01]\n",
      " [ 2.697e-01]\n",
      " [ 2.680e-01]\n",
      " [ 2.316e-01]\n",
      " [ 2.385e-01]\n",
      " [ 2.368e-01]\n",
      " [ 2.316e-01]\n",
      " [ 2.385e-01]\n",
      " [ 2.680e-01]\n",
      " [ 2.923e-01]\n",
      " [ 3.252e-01]\n",
      " [ 3.287e-01]\n",
      " [ 3.356e-01]\n",
      " [ 3.461e-01]\n",
      " [ 3.443e-01]\n",
      " [ 3.322e-01]\n",
      " [ 3.426e-01]\n",
      " [ 3.495e-01]\n",
      " [ 3.669e-01]\n",
      " [ 3.755e-01]\n",
      " [ 3.669e-01]\n",
      " [ 3.703e-01]\n",
      " [ 3.530e-01]\n",
      " [ 3.426e-01]\n",
      " [ 3.461e-01]\n",
      " [ 3.617e-01]\n",
      " [ 3.703e-01]\n",
      " [ 3.894e-01]\n",
      " [ 4.397e-01]\n",
      " [ 3.842e-01]\n",
      " [ 4.050e-01]\n",
      " [ 3.617e-01]\n",
      " [ 3.270e-01]\n",
      " [ 3.426e-01]\n",
      " [ 3.218e-01]\n",
      " [ 3.356e-01]\n",
      " [ 3.148e-01]\n",
      " [ 2.958e-01]\n",
      " [ 2.836e-01]\n",
      " [ 2.801e-01]\n",
      " [ 2.871e-01]\n",
      " [ 2.853e-01]\n",
      " [ 2.905e-01]\n",
      " [ 2.923e-01]\n",
      " [ 2.923e-01]\n",
      " [ 2.715e-01]\n",
      " [ 2.593e-01]\n",
      " [ 2.437e-01]\n",
      " [ 2.177e-01]\n",
      " [ 2.316e-01]\n",
      " [ 2.507e-01]\n",
      " [ 2.524e-01]\n",
      " [ 2.853e-01]\n",
      " [ 2.923e-01]\n",
      " [ 2.663e-01]\n",
      " [ 2.524e-01]\n",
      " [ 2.350e-01]\n",
      " [ 2.489e-01]\n",
      " [ 2.437e-01]\n",
      " [ 2.819e-01]\n",
      " [ 2.836e-01]\n",
      " [ 2.645e-01]\n",
      " [ 2.541e-01]\n",
      " [ 2.454e-01]\n",
      " [ 2.472e-01]\n",
      " [ 2.784e-01]\n",
      " [ 2.697e-01]\n",
      " [ 2.888e-01]\n",
      " [ 2.940e-01]\n",
      " [ 2.975e-01]\n",
      " [ 2.923e-01]\n",
      " [ 2.767e-01]\n",
      " [ 2.732e-01]\n",
      " [ 2.732e-01]\n",
      " [ 2.836e-01]\n",
      " [ 2.836e-01]\n",
      " [ 2.767e-01]\n",
      " [ 2.801e-01]\n",
      " [ 2.767e-01]\n",
      " [ 2.680e-01]\n",
      " [ 2.784e-01]\n",
      " [ 2.576e-01]\n",
      " [ 2.680e-01]\n",
      " [ 2.663e-01]\n",
      " [ 2.645e-01]\n",
      " [ 2.507e-01]\n",
      " [ 2.385e-01]\n",
      " [ 2.350e-01]\n",
      " [ 2.194e-01]\n",
      " [ 2.090e-01]\n",
      " [ 1.778e-01]\n",
      " [ 1.379e-01]\n",
      " [ 1.136e-01]\n",
      " [ 1.101e-01]\n",
      " [ 1.101e-01]\n",
      " [ 1.032e-01]\n",
      " [ 7.025e-02]\n",
      " [ 2.342e-02]\n",
      " [ 3.382e-02]\n",
      " [-7.806e-03]\n",
      " [-1.821e-02]\n",
      " [ 3.209e-02]\n",
      " [ 1.301e-02]\n",
      " [ 6.071e-03]\n",
      " [-6.071e-03]\n",
      " [ 2.602e-03]\n",
      " [-2.862e-02]\n",
      " [-3.382e-02]\n",
      " [-3.382e-02]\n",
      " [-3.036e-02]\n",
      " [-2.515e-02]\n",
      " [-3.382e-02]\n",
      " [-3.729e-02]\n",
      " [ 3.036e-02]\n",
      " [ 1.648e-02]\n",
      " [ 3.036e-02]\n",
      " [ 4.076e-02]\n",
      " [ 6.505e-02]\n",
      " [ 1.292e-01]\n",
      " [ 1.119e-01]\n",
      " [ 1.275e-01]\n",
      " [ 1.240e-01]\n",
      " [ 9.454e-02]\n",
      " [ 9.801e-02]\n",
      " [ 9.280e-02]\n",
      " [ 1.032e-01]\n",
      " [ 8.586e-02]\n",
      " [ 1.015e-01]\n",
      " [ 8.239e-02]\n",
      " [ 9.454e-02]\n",
      " [ 9.974e-02]\n",
      " [ 1.171e-01]\n",
      " [ 9.107e-02]\n",
      " [ 6.331e-02]\n",
      " [ 4.250e-02]\n",
      " [ 4.944e-02]\n",
      " [ 3.729e-02]\n",
      " [ 1.474e-02]\n",
      " [ 6.678e-02]\n",
      " [ 1.015e-01]\n",
      " [ 1.015e-01]\n",
      " [ 1.067e-01]\n",
      " [ 1.344e-01]\n",
      " [ 1.344e-01]\n",
      " [ 1.431e-01]\n",
      " [ 1.518e-01]\n",
      " [ 1.448e-01]\n",
      " [ 1.674e-01]\n",
      " [ 1.605e-01]\n",
      " [ 1.119e-01]\n",
      " [ 8.413e-02]\n",
      " [ 7.546e-02]\n",
      " [ 8.586e-02]\n",
      " [ 8.933e-02]\n",
      " [ 1.067e-01]\n",
      " [ 1.067e-01]\n",
      " [ 1.154e-01]\n",
      " [ 1.101e-01]\n",
      " [ 1.049e-01]\n",
      " [ 6.852e-02]\n",
      " [ 7.025e-02]\n",
      " [ 4.250e-02]\n",
      " [ 3.036e-02]\n",
      " [ 2.342e-02]\n",
      " [ 4.076e-02]\n",
      " [ 6.331e-02]\n",
      " [ 5.117e-02]\n",
      " [ 3.036e-02]\n",
      " [ 3.903e-02]\n",
      " [ 6.852e-02]\n",
      " [ 6.158e-02]\n",
      " [ 6.678e-02]\n",
      " [ 6.158e-02]\n",
      " [ 3.729e-02]\n",
      " [ 4.770e-02]\n",
      " [ 3.209e-02]\n",
      " [-8.673e-04]\n",
      " [ 6.071e-03]\n",
      " [ 1.474e-02]\n",
      " [ 2.342e-02]\n",
      " [ 1.995e-02]\n",
      " [ 3.556e-02]\n",
      " [ 5.464e-02]\n",
      " [ 1.154e-01]\n",
      " [ 1.032e-01]\n",
      " [ 1.275e-01]\n",
      " [ 1.240e-01]\n",
      " [ 1.310e-01]\n",
      " [ 1.292e-01]\n",
      " [ 1.223e-01]\n",
      " [ 1.206e-01]\n",
      " [ 1.327e-01]\n",
      " [ 1.344e-01]\n",
      " [ 1.327e-01]\n",
      " [ 1.344e-01]\n",
      " [ 1.171e-01]\n",
      " [ 1.032e-01]\n",
      " [ 9.974e-02]\n",
      " [ 7.892e-02]\n",
      " [ 9.801e-02]\n",
      " [ 9.801e-02]\n",
      " [ 1.015e-01]\n",
      " [ 9.454e-02]\n",
      " [ 9.627e-02]\n",
      " [ 9.974e-02]\n",
      " [ 1.084e-01]\n",
      " [ 1.015e-01]\n",
      " [ 7.372e-02]\n",
      " [ 7.892e-02]\n",
      " [ 6.678e-02]\n",
      " [ 5.984e-02]\n",
      " [ 1.821e-02]\n",
      " [-1.127e-02]\n",
      " [-6.071e-03]\n",
      " [-1.821e-02]\n",
      " [-1.474e-02]\n",
      " [-7.806e-03]\n",
      " [ 3.036e-02]\n",
      " [ 2.689e-02]\n",
      " [ 3.729e-02]\n",
      " [ 5.637e-02]\n",
      " [ 8.066e-02]\n",
      " [ 8.413e-02]\n",
      " [ 9.107e-02]\n",
      " [ 8.239e-02]\n",
      " [ 2.515e-02]\n",
      " [-8.673e-04]\n",
      " [-7.806e-03]\n",
      " [-1.301e-02]\n",
      " [-1.821e-02]\n",
      " [-3.382e-02]\n",
      " [-4.944e-02]\n",
      " [-9.107e-02]\n",
      " [-1.344e-01]\n",
      " [-1.466e-01]\n",
      " [-1.552e-01]\n",
      " [-1.969e-01]\n",
      " [-1.813e-01]\n",
      " [-2.212e-01]\n",
      " [-2.871e-01]\n",
      " [-2.819e-01]\n",
      " [-2.905e-01]\n",
      " [-3.599e-01]\n",
      " [-3.929e-01]\n",
      " [-4.588e-01]\n",
      " [-4.189e-01]\n",
      " [-4.328e-01]\n",
      " [-4.310e-01]\n",
      " [-3.478e-01]\n",
      " [-4.449e-01]\n",
      " [-4.137e-01]\n",
      " [-3.721e-01]\n",
      " [-3.929e-01]\n",
      " [-4.033e-01]\n",
      " [-4.345e-01]\n",
      " [-4.467e-01]\n",
      " [-5.924e-01]\n",
      " [-6.288e-01]\n",
      " [-6.635e-01]\n",
      " [-6.271e-01]\n",
      " [-5.854e-01]\n",
      " [-5.941e-01]\n",
      " [-5.559e-01]\n",
      " [-5.403e-01]\n",
      " [-5.698e-01]\n",
      " [-6.010e-01]\n",
      " [-6.080e-01]\n",
      " [-5.889e-01]\n",
      " [-6.201e-01]\n",
      " [-6.305e-01]\n",
      " [-6.357e-01]\n",
      " [-6.340e-01]\n",
      " [-6.080e-01]\n",
      " [-5.924e-01]\n",
      " [-5.820e-01]\n",
      " [-6.392e-01]\n",
      " [-6.253e-01]\n",
      " [-6.253e-01]\n",
      " [-6.305e-01]\n",
      " [-6.062e-01]\n",
      " [-5.889e-01]\n",
      " [-6.149e-01]\n",
      " [-6.288e-01]\n",
      " [-6.531e-01]\n",
      " [-6.565e-01]\n",
      " [-6.531e-01]\n",
      " [-6.097e-01]\n",
      " [-6.444e-01]\n",
      " [-6.427e-01]\n",
      " [-7.346e-01]\n",
      " [-7.398e-01]\n",
      " [-6.982e-01]\n",
      " [-6.826e-01]\n",
      " [-6.947e-01]\n",
      " [-7.346e-01]\n",
      " [-7.086e-01]\n",
      " [-6.878e-01]\n",
      " [-6.548e-01]\n",
      " [-6.305e-01]\n",
      " [-5.733e-01]\n",
      " [-5.559e-01]\n",
      " [-5.785e-01]\n",
      " [-5.993e-01]\n",
      " [-6.652e-01]\n",
      " [-6.843e-01]\n",
      " [-7.121e-01]\n",
      " [-6.808e-01]\n",
      " [-6.704e-01]\n",
      " [-6.912e-01]\n",
      " [-6.826e-01]\n",
      " [-7.051e-01]\n",
      " [-6.791e-01]\n",
      " [-6.947e-01]\n",
      " [-7.051e-01]\n",
      " [-7.277e-01]\n",
      " [-7.225e-01]\n",
      " [-6.843e-01]\n",
      " [-6.791e-01]\n",
      " [-6.149e-01]\n",
      " [-6.375e-01]\n",
      " [-6.947e-01]\n",
      " [-6.912e-01]\n",
      " [-7.155e-01]\n",
      " [-6.860e-01]\n",
      " [-6.999e-01]\n",
      " [-6.878e-01]\n",
      " [-6.878e-01]\n",
      " [-6.964e-01]\n",
      " [-7.086e-01]\n",
      " [-6.774e-01]\n",
      " [-7.086e-01]\n",
      " [-7.103e-01]\n",
      " [-7.294e-01]\n",
      " [-7.520e-01]\n",
      " [-7.710e-01]\n",
      " [-7.381e-01]\n",
      " [-7.415e-01]\n",
      " [-7.658e-01]\n",
      " [-8.196e-01]\n",
      " [-8.109e-01]\n",
      " [-8.005e-01]\n",
      " [-8.161e-01]\n",
      " [-8.404e-01]\n",
      " [-8.300e-01]\n",
      " [-7.953e-01]\n",
      " [-7.381e-01]\n",
      " [-7.502e-01]\n",
      " [-7.745e-01]\n",
      " [-7.780e-01]\n",
      " [-7.901e-01]\n",
      " [-7.936e-01]\n",
      " [-8.109e-01]\n",
      " [-8.109e-01]\n",
      " [-8.023e-01]\n",
      " [-7.866e-01]\n",
      " [-8.005e-01]\n",
      " [-8.231e-01]\n",
      " [-7.988e-01]\n",
      " [-8.057e-01]\n",
      " [-8.161e-01]\n",
      " [-8.283e-01]\n",
      " [-8.179e-01]\n",
      " [-8.300e-01]\n",
      " [-8.387e-01]\n",
      " [-8.335e-01]\n",
      " [-8.439e-01]\n",
      " [-8.543e-01]\n",
      " [-8.595e-01]\n",
      " [-8.612e-01]\n",
      " [-8.664e-01]\n",
      " [-8.768e-01]\n",
      " [-9.063e-01]\n",
      " [-9.046e-01]\n",
      " [-9.618e-01]\n",
      " [-9.827e-01]\n",
      " [-9.809e-01]\n",
      " [-9.861e-01]\n",
      " [-1.000e+00]\n",
      " [-9.098e-01]\n",
      " [-9.376e-01]\n",
      " [-9.445e-01]\n",
      " [-9.029e-01]\n",
      " [-9.011e-01]\n",
      " [-8.838e-01]\n",
      " [-8.890e-01]\n",
      " [-8.873e-01]\n",
      " [-8.873e-01]\n",
      " [-9.202e-01]\n",
      " [-9.410e-01]\n",
      " [-9.324e-01]\n",
      " [-9.063e-01]\n",
      " [-9.098e-01]\n",
      " [-9.011e-01]\n",
      " [-8.942e-01]\n",
      " [-8.595e-01]\n",
      " [-8.057e-01]\n",
      " [-8.456e-01]\n",
      " [-8.578e-01]\n",
      " [-8.647e-01]\n",
      " [-8.404e-01]\n",
      " [-8.057e-01]\n",
      " [-8.057e-01]\n",
      " [-7.936e-01]\n",
      " [-7.745e-01]\n",
      " [-7.693e-01]\n",
      " [-6.704e-01]\n",
      " [-6.167e-01]\n",
      " [-6.479e-01]\n",
      " [-6.860e-01]\n",
      " [-6.323e-01]\n",
      " [-6.167e-01]\n",
      " [-6.184e-01]\n",
      " [-6.219e-01]\n",
      " [-6.288e-01]\n",
      " [-6.132e-01]\n",
      " [-5.993e-01]\n",
      " [-5.091e-01]\n",
      " [-5.212e-01]\n",
      " [-5.212e-01]\n",
      " [-5.386e-01]\n",
      " [-5.559e-01]\n",
      " [-5.039e-01]\n",
      " [-4.727e-01]\n",
      " [-4.605e-01]\n",
      " [-4.900e-01]\n",
      " [-5.438e-01]\n",
      " [-5.299e-01]\n",
      " [-5.247e-01]\n",
      " [-5.334e-01]\n",
      " [-5.438e-01]\n",
      " [-5.559e-01]\n",
      " [-5.455e-01]\n",
      " [-5.317e-01]\n",
      " [-5.507e-01]\n",
      " [-6.080e-01]\n",
      " [-6.097e-01]\n",
      " [-6.062e-01]\n",
      " [-5.837e-01]\n",
      " [-5.906e-01]\n",
      " [-5.820e-01]\n",
      " [-5.698e-01]\n",
      " [-5.681e-01]\n",
      " [-5.750e-01]\n",
      " [-5.854e-01]\n",
      " [-5.386e-01]\n",
      " [-4.727e-01]\n",
      " [-4.727e-01]\n",
      " [-4.866e-01]\n",
      " [-4.779e-01]\n",
      " [-4.952e-01]\n",
      " [-4.866e-01]\n",
      " [-4.883e-01]\n",
      " [-5.195e-01]\n",
      " [-4.588e-01]\n",
      " [-4.779e-01]\n",
      " [-4.397e-01]\n",
      " [-4.796e-01]\n",
      " [-4.935e-01]\n",
      " [-5.143e-01]\n",
      " [-4.952e-01]\n",
      " [-5.369e-01]\n",
      " [-5.577e-01]\n",
      " [-5.646e-01]\n",
      " [-5.577e-01]\n",
      " [-5.438e-01]\n",
      " [-5.559e-01]\n",
      " [-5.317e-01]\n",
      " [-5.438e-01]\n",
      " [-5.317e-01]\n",
      " [-5.004e-01]\n",
      " [-4.987e-01]\n",
      " [-3.912e-01]\n",
      " [-3.807e-01]\n",
      " [-3.686e-01]\n",
      " [-3.981e-01]\n",
      " [-3.651e-01]\n",
      " [-3.582e-01]\n",
      " [-3.790e-01]\n",
      " [-3.252e-01]\n",
      " [-3.374e-01]\n",
      " [-3.790e-01]\n",
      " [-4.154e-01]\n",
      " [-3.738e-01]\n",
      " [-3.634e-01]\n",
      " [-3.790e-01]\n",
      " [-3.218e-01]\n",
      " [-2.871e-01]\n",
      " [-3.218e-01]\n",
      " [-3.513e-01]\n",
      " [-3.912e-01]\n",
      " [-3.651e-01]\n",
      " [-3.894e-01]\n",
      " [-3.912e-01]\n",
      " [-3.547e-01]\n",
      " [-3.547e-01]\n",
      " [-3.825e-01]\n",
      " [-4.050e-01]\n",
      " [-4.397e-01]\n",
      " [-4.258e-01]\n",
      " [-4.224e-01]\n",
      " [-4.137e-01]\n",
      " [-4.016e-01]\n",
      " [-3.998e-01]\n",
      " [-4.050e-01]\n",
      " [-3.859e-01]\n",
      " [-3.530e-01]\n",
      " [-3.634e-01]\n",
      " [-3.894e-01]\n",
      " [-3.825e-01]\n",
      " [-3.773e-01]\n",
      " [-3.946e-01]\n",
      " [-4.102e-01]\n",
      " [-3.825e-01]\n",
      " [-3.790e-01]\n",
      " [-4.102e-01]\n",
      " [-4.224e-01]\n",
      " [-4.241e-01]\n",
      " [-4.137e-01]\n",
      " [-3.825e-01]\n",
      " [-3.322e-01]\n",
      " [-3.027e-01]\n",
      " [-2.836e-01]\n",
      " [-3.374e-01]\n",
      " [-3.079e-01]\n",
      " [-2.992e-01]\n",
      " [-2.732e-01]\n",
      " [-2.749e-01]\n",
      " [-2.732e-01]\n",
      " [-3.010e-01]\n",
      " [-3.148e-01]\n",
      " [-3.200e-01]\n",
      " [-2.871e-01]\n",
      " [-2.940e-01]\n",
      " [-2.715e-01]\n",
      " [-2.975e-01]\n",
      " [-2.940e-01]\n",
      " [-2.819e-01]\n",
      " [-2.715e-01]\n",
      " [-2.749e-01]\n",
      " [-2.801e-01]\n",
      " [-2.160e-01]\n",
      " [-2.680e-01]\n",
      " [-2.524e-01]\n",
      " [-2.732e-01]\n",
      " [-2.853e-01]\n",
      " [-2.940e-01]\n",
      " [-2.888e-01]\n",
      " [-2.819e-01]\n",
      " [-2.992e-01]\n",
      " [-3.252e-01]\n",
      " [-3.270e-01]\n",
      " [-3.356e-01]\n",
      " [-3.096e-01]\n",
      " [-3.027e-01]\n",
      " [-3.408e-01]\n",
      " [-3.981e-01]\n",
      " [-3.912e-01]\n",
      " [-3.807e-01]\n",
      " [-3.859e-01]\n",
      " [-3.790e-01]\n",
      " [-3.859e-01]\n",
      " [-4.085e-01]\n",
      " [-4.224e-01]\n",
      " [-4.224e-01]\n",
      " [-4.120e-01]\n",
      " [-4.085e-01]\n",
      " [-4.310e-01]\n",
      " [-4.536e-01]\n",
      " [-4.675e-01]\n",
      " [-4.553e-01]\n",
      " [-4.154e-01]\n",
      " [-4.397e-01]\n",
      " [-4.467e-01]\n",
      " [-4.605e-01]\n",
      " [-4.952e-01]\n",
      " [-5.195e-01]\n",
      " [-5.091e-01]\n",
      " [-4.761e-01]\n",
      " [-4.883e-01]\n",
      " [-5.091e-01]\n",
      " [-4.831e-01]\n",
      " [-4.952e-01]\n",
      " [-4.900e-01]\n",
      " [-4.848e-01]\n",
      " [-4.709e-01]\n",
      " [-4.900e-01]\n",
      " [-4.814e-01]\n",
      " [-4.761e-01]\n",
      " [-4.796e-01]\n",
      " [-4.588e-01]\n",
      " [-4.588e-01]\n",
      " [-4.501e-01]\n",
      " [-4.415e-01]\n",
      " [-4.449e-01]\n",
      " [-4.397e-01]\n",
      " [-4.571e-01]\n",
      " [-4.727e-01]\n",
      " [-5.091e-01]\n",
      " [-5.195e-01]\n",
      " [-5.074e-01]\n",
      " [-5.299e-01]\n",
      " [-5.212e-01]\n",
      " [-5.160e-01]\n",
      " [-5.212e-01]\n",
      " [-5.334e-01]\n",
      " [-5.403e-01]\n",
      " [-5.282e-01]\n",
      " [-5.438e-01]\n",
      " [-5.403e-01]\n",
      " [-5.421e-01]\n",
      " [-5.559e-01]\n",
      " [-5.750e-01]\n",
      " [-5.768e-01]\n",
      " [-5.594e-01]\n",
      " [-5.663e-01]\n",
      " [-5.837e-01]\n",
      " [-5.872e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "adam = Adam(lr=0.001)\n",
    "reg=L1L2(l1=0.00, l2=0.1)\n",
    "BATCH_SIZE=20\n",
    "X=data_selected.drop('Prediction',1).values\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "sc_y = MinMaxScaler(feature_range=(-1,1))\n",
    "X=sc.fit_transform(X)\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "y=data_selected['Prediction'].values.reshape(-1,1)\n",
    "y=sc_y.fit_transform(y)\n",
    "print(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, batch_input_shape=(BATCH_SIZE, 1,X_train.shape[2]),\n",
    "                        dropout=0.0, recurrent_dropout=0.0,\n",
    "                        stateful=True, return_sequences=True,\n",
    "                        kernel_initializer='random_uniform',\n",
    "                        bias_regularizer=reg))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(LSTM(64, dropout=0.0))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "# model.add(LSTM(7,input_shape=(1, X.shape[2]),bias_regularizer=reg,dropout=0.4,unit_forget_bias=False,return_sequences=True))\n",
    "# model.add(Dense(1))\n",
    "model.compile(\n",
    "  loss=\"mean_squared_error\",\n",
    "  optimizer=adam\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24b171b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (20, 1, 128)              69120     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (20, 1, 128)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (20, 64)                  49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (20, 64)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (20, 32)                  2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (20, 1)                   33        \n",
      "=================================================================\n",
      "Total params: 120,641\n",
      "Trainable params: 120,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "584b5045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1200\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 12.9028  "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "   Specified a list with shape [20,6] from a tensor with shape [2,6]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_4694]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-63a29be15bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Fit model with history to check for overfitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/FYP/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [20,6] from a tensor with shape [2,6]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_4694]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "#Fit model with history to check for overfitting\n",
    "es = EarlyStopping(monitor='val_loss', mode='min',patience=3)\n",
    "history = model.fit(X_train,y_train,epochs=1200,batch_size=BATCH_SIZE,validation_data=(X_test,y_test),shuffle=False, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=sc_y.inverse_transform(y_test)\n",
    "y_pred=sc_y.inverse_transform(y_pred)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449bc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, len(y_train)), y_train, 'g', label=\"history\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_test, marker='.', label=\"true\")\n",
    "plt.plot(np.arange(len(y_train), len(y_train) + len(y_test)), y_pred, 'r', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, marker='.', label=\"true\")\n",
    "plt.plot(y_pred, 'r',marker='*', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0abaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525efe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ea17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9506b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('HSBC_FeatureSelected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be14f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eae564",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data=sc.fit_transform(data_unseen.drop('Prediction',1).values)\n",
    "unseen_data=unseen_data.reshape(unseen_data.shape[0],1,unseen_data.shape[1])\n",
    "unseen_pred=model.predict(unseen_data)\n",
    "unseen_pred=sc_y.inverse_transform(unseen_pred)\n",
    "unseen_test=data_unseen['Prediction'].values.reshape(-1,1)\n",
    "print(unseen_pred)\n",
    "print(unseen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f210726",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_unseen['Prediction'].values, marker='.', label=\"true\")\n",
    "plt.plot(unseen_pred, 'r',marker='*', label=\"prediction\")\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Time Step')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(data_unseen['Prediction'].values,unseen_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aedee7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a08d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
